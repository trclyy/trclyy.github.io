<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[解决有关爬虫Python编码的错误]]></title>
    <url>%2F2019%2F03%2F17%2F%E8%A7%A3%E5%86%B3%E6%9C%89%E5%85%B3%E7%88%AC%E8%99%ABPython%E7%BC%96%E7%A0%81%E7%9A%84%E9%94%99%E8%AF%AF%2F</url>
    <content type="text"><![CDATA[Python Solve UnicodeEncodeError ‘gbk’ / ‘ascii’ / ‘utf8’ codec can’t encode character ‘\x??’ in position ? 解决有关Python编码的错误在Python中，处理中文字符一直是很令人头痛的问题，一言不合就乱码，而且引起乱码的原因也不尽相同，有时候是python本身默认的编码器设置的不对，有时候是使用的IDE的解码器不对，还有的时候是终端terminal的解码器不对，有时候同一份代码在Python2上正常运行，Python3上就不行了，反正产生乱码的原因很多，这里就列举一些博主遇到过的一些错误及其解决方案： Error 1: UnicodeEncodeError: ‘gbk’ codec can’t encode character ‘\x??’ in position ?: illegal multibyte sequence 这个是在Win7上用Python3编译的时候遇到的，原因是win7的python3的默认编码不是utf8，我们只需要将默认编码改为utf8就能解决这个问题，参见下面的代码： 12import sys, iosys.stdout = io.TextIOWrapper(sys.stdout.buffer,encoding=&apos;utf8&apos;) # Change default encoding to utf8 Error 2： UnicodeDecodeError: ‘ascii’ codec can’t decode byte 0x?? in position: ordinal not in range(128) 这个是Mac上使用Python2编译的时候遇到的，原因是也是由于python2的默认编码不是utf8，我们只需要将默认编码改为utf8就能解决这个问题，参见下面的代码： 123import sysreload(sys)sys.setdefaultencoding(&apos;utf-8&apos;) 像其他的产生错误的原因，比如IDE显示乱码，或者终端Terminal显示乱码，可以通过Google搜索快速的找出解决方法，这里就不赘述了。 Error3: 1python抓取网页内容时出错，UnicodeEncodeError: &apos;gbk&apos; codec can&apos;t encode character &apos;\ue4bf..... 网页的数据应该是’utf-8’编码,这个可以在网页的head上面看得到,然后你爬网页的时候会把它转化成Unicode,出问题的是在print()这儿,对于print()这个函数,他需要把内容转化为’gbk‘编码才能显示出来. 然后解决办法是这样,你在转化后的Unicode编码的string后面,加上 .encode(‘GBK‘,’ignore’).decode(‘GBk‘) 也就是先用gbk编码,忽略掉非法字符,然后再译码,是不是很有道理 应该是这样的,因为我和你遇到同样的问题,现在解决了]]></content>
      <tags>
        <tag>爬虫</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx介绍]]></title>
    <url>%2F2019%2F03%2F15%2Fnginx%E4%BB%8B%E7%BB%8D%2F</url>
    <content type="text"><![CDATA[Nginx是什么？Nginx介绍及Nginx的优点 Nginx是俄罗斯人编写的十分轻量级的HTTP服务器,Nginx，它的发音为“engine X”，是一个高性能的HTTP和反向代理服务器，同时也是一个IMAP/POP3/SMTP 代理服务器。Nginx是由俄罗斯人 Igor Sysoev为俄罗斯访问量第二的 Rambler.ru站点开发的，它已经在该站点运行超过两年半了。Igor Sysoev在建立的项目时,使用基于BSD许可。 英文主页：http://nginx.net 。 到2013年，目前有很多国内网站采用Nginx作为Web服务器，如国内知名的新浪、163、腾讯、Discuz、豆瓣等。据netcraft统计，Nginx排名第3，约占15%的份额(参见：http://news.netcraft.com/archives/category/web-server-survey/ ) Nginx以事件驱动的方式编写，所以有非常好的性能，同时也是一个非常高效的反向代理、负载平衡。其拥有匹配Lighttpd的性能，同时还没有Lighttpd的内存泄漏问题，而且Lighttpd的mod_proxy也有一些问题并且很久没有更新。 现在，Igor将源代码以类BSD许可证的形式发布。Nginx因为它的稳定性、丰富的模块库、灵活的配置和低系统资源的消耗而闻名．业界一致认为它是Apache2.2＋mod_proxy_balancer的轻量级代替者，不仅是因为响应静态页面的速度非常快，而且它的模块数量达到Apache的近2/3。对proxy和rewrite模块的支持很彻底，还支持mod_fcgi、ssl、vhosts ，适合用来做mongrel clusters的前端HTTP响应。 nginx做为HTTP服务器，有以下几项基本特性： 处理静态文件，索引文件以及自动索引；打开文件描述符缓冲． 无缓存的反向代理加速，简单的负载均衡和容错． FastCGI，简单的负载均衡和容错． 模块化的结构。包括gzipping, byte ranges, chunked responses,以及 SSI-filter等filter。如果由FastCGI或其它代理服务器处理单页中存在的多个SSI，则这项处理可以并行运行，而不需要相互等待。 支持SSL 和 TLSSNI． Nginx专为性能优化而开发，性能是其最重要的考量,实现上非常注重效率 。它支持内核Poll模型，能经受高负载的考验,有报告表明能支持高达 50,000个并发连接数。 Nginx具有很高的稳定性。其它HTTP服务器，当遇到访问的峰值，或者有人恶意发起慢速连接时，也很可能会导致服务器物理内存耗尽频繁交换，失去响应，只能重启服务器。例如当前apache一旦上到200个以上进程，web响应速度就明显非常缓慢了。而Nginx采取了分阶段资源分配技术，使得它的CPU与内存占用率非常低。nginx官方表示保持10,000个没有活动的连接，它只占2.5M内存，所以类似DOS这样的攻击对nginx来说基本上是毫无用处的。就稳定性而言,nginx比lighthttpd更胜一筹。 Nginx支持热部署。它的启动特别容易, 并且几乎可以做到7*24不间断运行，即使运行数个月也不需要重新启动。你还能够在不间断服务的情况下，对软件版本进行进行升级。 Nginx采用master-slave模型,能够充分利用SMP的优势，且能够减少工作进程在磁盘I/O的阻塞延迟。当采用select()/poll()调用时，还可以限制每个进程的连接数。 Nginx代码质量非常高，代码很规范，手法成熟， 模块扩展也很容易。特别值得一提的是强大的Upstream与Filter链。Upstream为诸如reverse proxy,与其他服务器通信模块的编写奠定了很好的基础。而Filter链最酷的部分就是各个filter不必等待前一个filter执行完毕。它可以把前一个filter的输出做为当前filter的输入，这有点像Unix的管线。这意味着，一个模块可以开始压缩从后端服务器发送过来的请求，且可以在模块接收完后端服务器的整个请求之前把压缩流转向客户端。 Nginx采用了一些os提供的最新特性如对sendfile (Linux2.2+)，accept-filter (FreeBSD4.1+)，TCP_DEFER_ACCEPT (Linux 2.4+)的支持，从而大大提高了性能。 当然，nginx还很年轻，多多少少存在一些问题，比如：Nginx是俄罗斯人创建，虽然前几年文档比较少，但是目前文档方面比较全面，英文资料居多，中文的资料也比较多，而且有专门的书籍和资料可供查找。 nginx的作者和社区都在不断的努力完善，我们有理由相信nginx将继续以高速的增长率来分享轻量级HTTP服务器市场，会有一个更美好的未来。]]></content>
      <tags>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[vue介绍]]></title>
    <url>%2F2019%2F03%2F15%2Fvue%E4%BB%8B%E7%BB%8D%2F</url>
    <content type="text"><![CDATA[一.MVX框架模式了解 MVX框架模式：MVC+MVP+MVVM 1.MVC：Model(模型)+View(视图)+controller(控制器)，主要是基于分层的目的，让彼此的职责分开。​ View通过Controller来和Model联系，Controller是View和Model的协调者，View和Model不直接联系，基本联系都是单向的。用户User通过控制器Controller来操作模板Model从而达到视图View的变化。 2.MVP：是从MVC模式演变而来的，都是通过Controller/Presenter负责逻辑的处理+Model提供数据+View负责显示。​ 在MVP中，Presenter完全把View和Model进行了分离，主要的程序逻辑在Presenter里实现。并且，Presenter和View是没有直接关联的，是通过定义好的接口进行交互，从而使得在变更View的时候可以保持Presenter不变。 MVP模式的框架：Riot,js。 3.MVVM：MVVM是把MVC里的Controller和MVP里的Presenter改成了ViewModel。Model+View+ViewModel。​ View的变化会自动更新到ViewModel,ViewModel的变化也会自动同步到View上显示。​ 这种自动同步是因为ViewModel中的属性实现了Observer，当属性变更时都能触发对应的操作。 MVVM模式的框架有：AngularJS+Vue.js和Knockout+Ember.js后两种知名度较低以及是早起的框架模式。 View 是HTML文本的js模板ViewModel是业务逻辑层（一切js可视业务逻辑，比如表单按钮提交，自定义事件的注册和处理逻辑都在viewmodel里面负责监控俩边的数据）Model 数据层 对数据的处理（比如增删改查） 二.Vue.js 是什么 Vue.js是一个轻巧、高性能、可组件化的MVVM库，同时拥有非常容易上手的API； Vue.js是一个构建数据驱动的Web界面的库。 Vue.js是一套构建用户界面的 渐进式框架。与其他重量级框架不同的是，Vue 采用自底向上增量开发的设计。Vue 的核心库只关注视图层，并且非常容易学习，非常容易与其它库或已有项目整合。另一方面，Vue 完全有能力驱动采用单文件组件和 Vue 生态系统支持的库开发的复杂单页应用。数据驱动+组件化的前端开发。 简而言之：Vue.js是一个构建数据驱动的 web 界面的渐进式框架。Vue.js 的目标是通过尽可能简单的 API 实现响应的数据绑定和组合的视图组件。核心是一个响应的数据绑定系统。 Vue.js的特性如下： 1.轻量级的框架 2.双向数据绑定 3.指令 4.插件化作者：面条请不要欺负汉堡来源：CSDN原文：https://blog.csdn.net/gao_xu_520/article/details/76020365]]></content>
      <tags>
        <tag>vue</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux查看端口]]></title>
    <url>%2F2019%2F03%2F15%2Flinux%E6%9F%A5%E7%9C%8B%E7%AB%AF%E5%8F%A3%2F</url>
    <content type="text"><![CDATA[netstat命令各个参数说明如下： -t : 指明显示TCP端口 -u : 指明显示UDP端口 -l : 仅显示监听套接字(所谓套接字就是使应用程序能够读写与收发通讯协议(protocol)与资料的程序) -p : 显示进程标识符和程序名称，每一个套接字/端口都属于一个程序。 -n : 不进行DNS轮询，显示IP(可以加速操作) 即可显示当前服务器上所有端口及进程服务，于grep结合可查看某个具体端口及服务情况·· netstat -ntlp //查看当前所有tcp端口· netstat -ntulp |grep 80 //查看所有80端口使用情况· netstat -an | grep 3306 //查看所有3306端口使用情况· 查看一台服务器上面哪些服务及端口 netstat -lanp 查看一个服务有几个端口。比如要查看mysqld ps -ef |grep mysqld 查看某一端口的连接数量,比如3306端口 netstat -pnt |grep :3306 |wc 查看某一端口的连接客户端IP 比如3306端口 netstat -anp |grep 3306 12345678netstat -an 查看网络端口 lsof -i :port，使用lsof -i :port就能看见所指定端口运行的程序，同时还有当前连接。 nmap 端口扫描netstat -nupl (UDP类型的端口)netstat -ntpl (TCP类型的端口)netstat -anp 显示系统端口使用情况]]></content>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[django从输入url的响应过程]]></title>
    <url>%2F2019%2F03%2F06%2Fdjango%E4%BB%8E%E8%BE%93%E5%85%A5url%E7%9A%84%E5%93%8D%E5%BA%94%E8%BF%87%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[目前使用的主要开发语言还是python，有部分会用到网站开发，顺便看了一下《web接口开发与自动化测试基于python语言》，里面有Django的一些简单介绍，必要可以基于这个来开发个简单的web界面。首先一个是搞明白Django的访问逻辑次序。 以下是根据书上的学习和实践，拷贝自网络： 1、服务端响应url请求的执行顺序 1）项目结构 django_web init.py settings.py urls.py wsgi.py django_web_app init.py admin.py models.py tests.py views.py templates home_page.html latest_books.html manage.py 2）执行顺序 a）启动服务端——python manage.py runserver 获取setting.py文件中的配置，主要包括： url映射关系文件路径： ROOT_URLCONF = ‘django_web.urls’ 页面文件模板路径： TEMPLATE_DIRS = ( os.path.join(BASE_DIR, &apos;templates&apos;), ) 数据库配置： DATABASES = { &apos;default&apos;: { &apos;ENGINE&apos;: &apos;django.db.backends.mysql&apos;, &apos;NAME&apos;: &apos;django_db&apos;, &apos;USER&apos;: &apos;root&apos;, &apos;PASSWORD&apos;: &apos;feng&apos;, &apos;HOST&apos;: &apos;127.0.0.1&apos;, &apos;PORT&apos;: &apos;3306&apos;, } } b）响应顺序 说明： 第一步：浏览器提交请求 http://127.0.0.1:8000/latest_books/ 第二步：服务端根据请求的url在urls.py中进行匹配，并找到对应的“视图函数” 第三步：调用对应的“视图函数” 返回一个HttpResponse对象 第四步：django转换HttpResponse对象为一个适合的HTTP response，并返回给页面进行显示 2、url匹配模式 基本结构： &apos;^需要匹配的url字符串$&apos; PS:实际上最终完整的url串是http://根路径：端口号/需要匹配的url字符串 系统自动添加的部分&apos;http://根路径：端口号/&apos; eg：url匹配模式：&apos;^latest_books/$&apos; 最终完整的url字符串：&apos;http://127.0.0.1:8000/latest_books/&apos; 1）^：匹配“子串头”。 eg: ‘^latest_books/‘ ‘http://127.0.0.1:8000/latest_books/&#39;， ‘http://127.0.0.1:8000/latest_books/test1/&#39;, 都会被匹配上。 2）$：匹配“子串结尾”。 eg： ‘latest_books/$’ ‘http://127.0.0.1:8000/latest_books/&#39;， ‘http://127.0.0.1:8000/updir_1/latest_books/&#39;， ‘http://127.0.0.1:8000/updir_2/latest_books/&#39; 都会被匹配上。 3）子串末尾是否包含&apos;/&apos; 默认情况下必须添加（django开发者的基本习惯），如果不添加将会出现如下情况： from django.conf.urls import patterns, url, include urlpatterns = patterns(‘’, (r’^latest_books$’, ‘django_web_app.views.latest_books’), ) 如果子串末尾不想包含&apos;/&apos;，可在setting.py中添加设置：APPEND_SLASH=False 但是必须安装了CommonMiddleware才会起作用。 4）手动配置网站“根目录” 在不手动配置网站“根目录”对应“视图函数”的情况下，会出现如下情况： 手动配置“根目录”对应“视图函数”： a)urls.py from django.conf.urls import patterns, url, include urlpatterns = patterns(‘’, (r&apos;^$&apos;,&apos;django_web_app.views.home_page&apos;), (r&apos;^latest_books/$&apos;, &apos;django_web_app.views.latest_books&apos;), ) b)views.py def home_page(request): return render_to_response(&apos;home_page.html&apos;) c)home_page.html &lt;!DOCTYPE html&gt; my home page This is home page, welcome !L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"debug":false,"model":{"jsonPath":"/live2dw/assets/assets/shizuku.model.json"},"display":{"position":"right","width":130,"height":260},"mobile":{"show":false},"log":false}); 运行结果： 0、基本过程 1）创建 Django 工程 执行 django-admin.py startproject mysite 这样会在目录下建立一个 mysite： 文件如下： init.py ：让 Python 把该目录当成一个开发包 (即一组模块)所需的文件。 这是一个空文件，一般你不需要修改它。 manage.py ：一种命令行工具，允许你以多种方式与该 Django 项目进行交互。 键入 python manage.py help ，看一下它能做什么。 你应当不需要编辑这个文件；在这个目录下生成它纯是为了方便。 settings.py ：该 Django 项目的设置或配置。 查看并理解这个文件中可用的设置类型及其默认值。 urls.py ：Django项目的URL设置。 可视其为你的django网站的目录。 目前，它是空的。 尽管这些的文件很小，但这些文件已经构成了一个可运行的Django应用。 python manage.py runserver port 可以运行刚才建立的空服务端 2）设置数据库，自带的是sqlite 3）开始一个新的Appspython manage.py startapp books这个命令并没有输出什么，它只在 mysite 的目录里创建了一个 books 目录。 让我们来看看这个目录的内容： books/​ init.py​ models.py​ tests.py​ views.py这个目录包含了这个app的模型和视图。 4）模型安装在 Django 项目中 激活 这些模型。 将 books app 添加到配置文件的已安装应用列表中即可完成此步骤。 再次编辑 settings.py 文件， 找到 INSTALLED_APPS 设置。 INSTALLED_APPS 告诉 Django 项目哪些 app 处于激活状态。 5）db的产生（尚未验证） python manage.py validate #validate 命令检查你的模型的语法和逻辑是否正确python manage.py sqlall books #把产生数据库表的SQL语句段打印出来 python manage.py syncdb #运行上面产生的SQL语句，实际生成数据库表作者：Leo笑来源：CSDN原文：https://blog.csdn.net/hgstclyh/article/details/71107002]]></content>
      <tags>
        <tag>django</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[django中model用法详解]]></title>
    <url>%2F2019%2F03%2F06%2Fdjango%E4%B8%ADmodel%E7%94%A8%E6%B3%95%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[标签： 12345678910111213141516171819202122232425262728293031323334353637383940414243 D jango 模型是与数据库相关的，与数据库相关的代码一般写在 models.py 中，Django 支持 sqlite3, MySQL, PostgreSQL等数据库，只需要在settings.py中配置即可，不用更改models.py中的代码，丰富的API极大的方便了使用。1、数据库的连接方式以及设置：在Django中默认使用的数据库类型是sqlite3，如果想要使用其他数据库就需要在settings中设置数据库的连接方式：# Database# https://docs.djangoproject.com/en/1.10/ref/settings/#databases# sqlite3数据库连接方式# DATABASES = &#123;# ‘default‘: &#123;# ‘ENGINE‘: ‘django.db.backends.sqlite3‘,# ‘NAME‘: os.path.join(BASE_DIR, ‘db.sqlite3‘),# &#125;# &#125;# MySQL数据库连接方式DATABASES = &#123; ‘default‘: &#123; ‘ENGINE‘: ‘django.db.backends.mysql‘, ‘NAME‘:‘dbname‘, ‘USER‘: ‘root‘, ‘PASSWORD‘: ‘xxx‘, ‘HOST‘: ‘‘, ‘PORT‘: ‘‘, &#125;&#125;2、开始创建表数据需要在models.py文件中创建class UserInfo(models.Model): # CharField类型不能为空,最少要指定一个长度 user = models.CharField(max_length=32) email = models.EmailField(max_length=32) pwd = models.CharField(max_length=32) user_type = models.ForeignKey(‘UserType‘)class UserType(models.Model): nid = models.AutoField(primary_key=True) caption = models.CharField(max_length=16)注:在创建外键的时候直接写上UserType和‘UserType‘的区别就是python程序从上到下解释的顺序问题,如果把UserType这个类写到下面就会没事了运行Djando项目程序，执行命令创建数据：python3 manage.py makemigrationspython3 manage.py migrate创建表的的参数： 1234567891011121314151617181920212223242526272829303132333435363738394041421、models.AutoField 自增列 = int(11) 如果没有的话，默认会生成一个名称为 id 的列，如果要显示的自定义一个自增列，必须将给列设置为主键 primary_key=True。2、models.CharField 字符串字段 必须 max_length 参数3、models.BooleanField 布尔类型=tinyint(1) 不能为空，Blank=True4、models.ComaSeparatedIntegerField 用逗号分割的数字=varchar 继承CharField，所以必须 max_lenght 参数5、models.DateField 日期类型 date 对于参数，auto_now = True 则每次更新都会更新这个时间；auto_now_add 则只是第一次创建添加，之后的更新不再改变。6、models.DateTimeField 日期类型 datetime 同DateField的参数7、models.Decimal 十进制小数类型 = decimal 必须指定整数位max_digits和小数位decimal_places8、models.EmailField 字符串类型（正则表达式邮箱） =varchar 对字符串进行正则表达式9、models.FloatField 浮点类型 = double10、models.IntegerField 整形11、models.BigIntegerField 长整形 integer_field_ranges = &#123; ‘SmallIntegerField‘: (-32768, 32767), ‘IntegerField‘: (-2147483648, 2147483647), ‘BigIntegerField‘: (-9223372036854775808, 9223372036854775807), ‘PositiveSmallIntegerField‘: (0, 32767), ‘PositiveIntegerField‘: (0, 2147483647), &#125;12、models.IPAddressField 字符串类型（ip4正则表达式）13、models.GenericIPAddressField 字符串类型（ip4和ip6是可选的） 参数protocol可以是：both、ipv4、ipv6 验证时，会根据设置报错14、models.NullBooleanField 允许为空的布尔类型15、models.PositiveIntegerFiel 正Integer16、models.PositiveSmallIntegerField 正smallInteger17、models.SlugField 减号、下划线、字母、数字18、models.SmallIntegerField 数字 数据库中的字段有：tinyint、smallint、int、bigint19、models.TextField 字符串=longtext20、models.TimeField 时间 HH:MM[:ss[.uuuuuu]]21、models.URLField 字符串，地址正则表达式22、models.BinaryField 二进制23、models.ImageField 图片24、models.FilePathField 文件 更多字段 1234567891011121314151617181920212223242526271、null=True 数据库中字段是否可以为空2、blank=True django的 Admin 中添加数据时是否可允许空值3、primary_key = False 主键，对AutoField设置主键后，就会代替原来的自增 id 列4、auto_now 和 auto_now_add auto_now 自动创建---无论添加或修改，都是当前操作的时间 auto_now_add 自动创建---永远是创建时的时间5、choicesGENDER_CHOICE = ( (u‘M‘, u‘Male‘), (u‘F‘, u‘Female‘), )gender = models.CharField(max_length=2,choices = GENDER_CHOICE)6、max_length7、default 默认值8、verbose_name Admin中字段的显示名称9、name|db_column 数据库中的字段名称10、unique=True 不允许重复11、db_index = True 数据库索引12、editable=True 在Admin里是否可编辑13、error_messages=None 错误提示14、auto_created=False 自动创建15、help_text 在Admin中提示帮助信息16、validators=[]17、upload-to 更多参数 1执行成功状态： 12345678910111213141516171819202122232425 1 bogon:django_modes01 zk$ python3 manage.py makemigrations 2 Migrations for ‘app01‘: 3 app01/migrations/0001_initial.py: 4 - Create model UserInfo 5 - Create model UserType 6 - Add field user_type to userinfo 7 bogon:django_modes01 zk$ python3 manage.py migrate 8 Operations to perform: 9 Apply all migrations: admin, app01, auth, contenttypes, sessions10 Running migrations:11 Rendering model states... DONE12 Applying contenttypes.0001_initial... OK13 Applying auth.0001_initial... OK14 Applying admin.0001_initial... OK15 Applying admin.0002_logentry_remove_auto_add... OK16 Applying app01.0001_initial... OK17 Applying contenttypes.0002_remove_content_type_name... OK18 Applying auth.0002_alter_permission_name_max_length... OK19 Applying auth.0003_alter_user_email_max_length... OK20 Applying auth.0004_alter_user_username_opts... OK21 Applying auth.0005_alter_user_last_login_null... OK22 Applying auth.0006_require_contenttypes_0002... OK23 Applying auth.0007_alter_validators_add_error_messages... OK24 Applying auth.0008_alter_user_username_max_length... OK25 Applying sessions.0001_initial... OK 状态 12如果提示：No changes detected需要在settings.py的配置文件检测一下有没有注册app 1在MySQL中就可以看到生成的表： 外键关系： 3.开始创建数据 创建数据的时候有两种方式： 第一种方式： 12obj = models.表名(字段名=‘***‘)obj.save() 第二种方式： 1models.表名.objects.create(字段名=‘***‘) 在views.py中写入数据： 1234567891011121314151617181920212223242526272829from django.shortcuts import render,HttpResponsefrom app01 import models# Create your views here.def index(request): # 创建用户类型表 models.UserType.objects.create(caption=‘管路员‘) models.UserType.objects.create(caption=‘普通用户‘) models.UserType.objects.create(caption=‘超级管理员‘) # 创建用户信息表 user_info_dict_1 = &#123;‘user‘: ‘ales‘, ‘email‘: ‘alex@qq.com‘, ‘pwd‘: 123, ‘user_type‘: models.UserType.objects.get(nid=1), &#125; user_info_dict_2 = &#123;‘user‘: ‘eric‘, ‘email‘: ‘eric@qq.com‘, ‘pwd‘: 123, ‘user_type_id‘: 2, &#125; models.UserInfo.objects.create(**user_info_dict_1) models.UserInfo.objects.create(**user_info_dict_2) print(‘yes‘) return HttpResponse(‘ok‘) 运行Django 项目访问指定文件创建数据： 4、了不起的双下划线之外键正向查找和基本操作 12345678910111213141516171819202122 1 # 增 2 # 3 # models.Tb1.objects.create(c1=‘xx‘, c2=‘oo‘) 增加一条数据，可以接受字典类型数据 **kwargs 4 5 # obj = models.Tb1(c1=‘xx‘, c2=‘oo‘) 6 # obj.save() 7 8 # 查 9 #10 # models.Tb1.objects.get(id=123) # 获取单条数据，不存在则报错（不建议）11 # models.Tb1.objects.all() # 获取全部12 # models.Tb1.objects.filter(name=‘seven‘) # 获取指定条件的数据13 14 # 删15 #16 # models.Tb1.objects.filter(name=‘seven‘).delete() # 删除指定条件的数据17 18 # 改19 # models.Tb1.objects.filter(name=‘seven‘).update(gender=‘0‘) # 将指定条件的数据更新，均支持 **kwargs20 # obj = models.Tb1.objects.get(id=1)21 # obj.c1 = ‘111‘22 # obj.save() # 修改单条数据 基本操作 123456789101112131415161718192021222324252627282930313233343536373839404142 1 # 获取个数 2 # 3 # models.Tb1.objects.filter(name=‘seven‘).count() 4 5 # 大于，小于 6 # 7 # models.Tb1.objects.filter(id__gt=1) # 获取id大于1的值 8 # models.Tb1.objects.filter(id__lt=10) # 获取id小于10的值 9 # models.Tb1.objects.filter(id__lt=10, id__gt=1) # 获取id大于1 且 小于10的值10 11 # in12 #13 # models.Tb1.objects.filter(id__in=[11, 22, 33]) # 获取id等于11、22、33的数据14 # models.Tb1.objects.exclude(id__in=[11, 22, 33]) # not in15 16 # contains17 #18 # models.Tb1.objects.filter(name__contains=&quot;ven&quot;)19 # models.Tb1.objects.filter(name__icontains=&quot;ven&quot;) # icontains大小写不敏感20 # models.Tb1.objects.exclude(name__icontains=&quot;ven&quot;)21 22 # range23 #24 # models.Tb1.objects.filter(id__range=[1, 2]) # 范围bettwen and25 26 # 其他类似27 #28 # startswith，istartswith, endswith, iendswith,29 30 # order by31 #32 # models.Tb1.objects.filter(name=‘seven‘).order_by(‘id‘) # asc33 # models.Tb1.objects.filter(name=‘seven‘).order_by(‘-id‘) # desc34 35 # limit 、offset36 #37 # models.Tb1.objects.all()[10:20]38 39 # group by40 from django.db.models import Count, Min, Max, Sum41 # models.Tb1.objects.filter(c1=1).values(‘id‘).annotate(c=Count(‘num‘))42 # SELECT &quot;app01_tb1&quot;.&quot;id&quot;, COUNT(&quot;app01_tb1&quot;.&quot;num&quot;) AS &quot;c&quot; FROM &quot;app01_tb1&quot; WHERE &quot;app01_tb1&quot;.&quot;c1&quot; = 1 GROUP BY &quot;app01_tb1&quot;.&quot;id&quot; 进阶操作（双下划线） 查 单表查询： 123# ret = models.UserType.objects.all()# print(ret.query) # ret.query后台返回的是查询的sql语句 结果： 1SELECT `app01_usertype`.`nid`, `app01_usertype`.`caption` FROM `app01_usertype` 获取查询结果的类型： 12ret = models.UserType.objects.all()print(type(ret), ret) 结果： 1&lt;class ‘django.db.models.query.QuerySet‘&gt; &lt;QuerySet [&lt;UserType: UserType object&gt;, &lt;UserType: UserType object&gt;, &lt;UserType: UserType object&gt;]&gt; 可以看到类型是一个QuerySet类型，后面是所有的对象，每一个元素就是一个对象，可以循环拿出每一次的数据： 12345ret = models.UserType.objects.all() print(type(ret), ret) for item in ret: print(item) 其结果就是每一次循环出来的结果的对象： 123UserType objectUserType objectUserType object 每一个对象都代表一个数据，要出去这些数据如下： 12345ret = models.UserType.objects.all() print(type(ret), ret) for item in ret: print(item, item.nid, item.caption) 取出的结果： 123UserType object 1 管路员UserType object 2 普通用户UserType object 3 超级管理员 从结果看出每次输出item的时候都是一个对象(一行数据中所有的对象，对象中封装了所有的数据)，在modes中有str方法（返回什么，就输出什么，就是查看方便）， 在python2.7中叫unicode如果在UserType这个类里面使用这个方法： 123456class UserType(models.Model): nid = models.AutoField(primary_key=True) caption = models.CharField(max_length=16) def __str__(self): return ‘%s-%s‘ % (self.nid, self.caption) 然后重新访问下： 1231-管路员 1 管路员2-普通用户 2 普通用户3-超级管理员 3 超级管理员 就可以看到每一个对象都看到了返回的相对应的参数了。 查询单个字段： 12ret = models.UserType.objects.all().values(‘nid‘) print(type(ret), ret) 结果查询出nid字段对应的所有的数据 ： 1&lt;class ‘django.db.models.query.QuerySet‘&gt; &lt;QuerySet [&#123;‘nid‘: 1&#125;, &#123;‘nid‘: 2&#125;, &#123;‘nid‘: 3&#125;]&gt; 可以看查询的sql语句，用query方法： 12ret = models.UserType.objects.all().values(‘nid‘)print(type(ret), ret.query) 查询的结果： 1&lt;class ‘django.db.models.query.QuerySet‘&gt; SELECT `app01_usertype`.`nid` FROM `app01_usertype` 当通过values循环取值的时候，如下： 1234ret = models.UserType.objects.all().values(‘nid‘) print(type(ret), ret.query) for item in ret: print(item, type(item)) 结果： 1234&lt;class ‘django.db.models.query.QuerySet‘&gt; SELECT `app01_usertype`.`nid` FROM `app01_usertype`&#123;‘nid‘: 1&#125; &lt;class ‘dict‘&gt;&#123;‘nid‘: 2&#125; &lt;class ‘dict‘&gt;&#123;‘nid‘: 3&#125; &lt;class ‘dict‘&gt; 通过结果可以看出，最外部是QuerySet，内部元素封装了一个是封装了这一行所有数据的对象，另外只拿到了某几列的字典！ 当通过values_list循环取值的时候，如下： 12ret = models.UserType.objects.all().values_list(‘nid‘) print(type(ret), ret) 查询结果： 1&lt;class ‘django.db.models.query.QuerySet‘&gt; &lt;QuerySet [(1,), (2,), (3,)]&gt; 依然是queryset，但是结果就是列表中包含的元组，values和values_list的区别就是：values取的是字典类型，values_list把内部元素变成元组了。通过for循环更直观，如下： 1234ret = models.UserType.objects.all().values_list(‘nid‘) print(type(ret), ret) for item in ret: print(type(item), item) 结果： 1234&lt;class ‘django.db.models.query.QuerySet‘&gt; &lt;QuerySet [(1,), (2,), (3,)]&gt;&lt;class ‘tuple‘&gt; (1,)&lt;class ‘tuple‘&gt; (2,)&lt;class ‘tuple‘&gt; (3,) 连表查询： 连表查询的时候和sqlachemy有多不同，django没有join这个方法： 通过UserInfo做连表查询 1234ret = models.UserInfo.objects.all() print(type(ret), ret) for item in ret: print(item, item.user_type, item.id, item.email, item.user, item.pwd) 查询结果： 123&lt;class ‘django.db.models.query.QuerySet‘&gt; &lt;QuerySet [&lt;UserInfo: UserInfo object&gt;, &lt;UserInfo: UserInfo object&gt;]&gt;UserInfo object UserType object 1 alex@qq.com ales 123UserInfo object UserType object 2 eric@qq.com eric 123 首先输出的是查找出来的UserInfo用户信息表，封装了用户所有的信息，而UserType就是一个对象，这个对象里封装的就是一行信息对应的字段(nid和caption)，取出UserType对应的信息，例如： 12345ret = models.UserInfo.objects.all()print(type(ret), ret)for item in ret: print(item, item.user_type, item.id, item.email, item.user, item.pwd) print(item.user_type.nid, item.user_type.caption) 取出的UserType对应的信息结果： 12345&lt;class ‘django.db.models.query.QuerySet‘&gt; &lt;QuerySet [&lt;UserInfo: UserInfo object&gt;, &lt;UserInfo: UserInfo object&gt;]&gt;UserInfo object UserType object 1 alex@qq.com ales 123UserInfo object UserType object 2 eric@qq.com eric 1231 管路员2 普通用户 可以直接取出对应外键的那一列user_type_id： 12345ret = models.UserInfo.objects.all()print(type(ret), ret)for item in ret: print(item, item.user_type, item.id, item.email, item.user, item.pwd) print(item.user_type.nid, item.user_type.caption, item.user_type_id) 结果： 12345&lt;class ‘django.db.models.query.QuerySet‘&gt; &lt;QuerySet [&lt;UserInfo: UserInfo object&gt;, &lt;UserInfo: UserInfo object&gt;]&gt;UserInfo object UserType object 1 alex@qq.com ales 1231 管路员 1UserInfo object UserType object 2 eric@qq.com eric 1232 普通用户 2 如果只想看到数据对应的名称，就需要加映射values： 12ret = models.UserInfo.objects.all().values(‘user‘, ‘user_type__caption‘)print(ret, ret.query) 结果： 1&lt;QuerySet [&#123;‘user‘: ‘ales‘, ‘user_type__caption‘: ‘管路员‘&#125;, &#123;‘user‘: ‘eric‘, ‘user_type__caption‘: ‘普通用户‘&#125;]&gt; SELECT `app01_userinfo`.`user`, `app01_usertype`.`caption` FROM `app01_userinfo` INNER JOIN `app01_usertype` ON (`app01_userinfo`.`user_type_id` = `app01_usertype`.`nid`) 通过结果可以看到user_type__caption可以跨表直接获取相应的结果，再看sql语句中django本身加上了一个join。 如果在models中在加上一个表”P”,然后在UserType中增加一条外键指向”平”P”，需求：要查找UserInfo表中的name和UserType表中的caption和P表中的neme的方法就是在找下一个对象的时候继续加双下划线： 增加的表结构： 查询语法： 12ret = models.UserInfo.objects.all().values(‘user‘, ‘user_type__caption‘, ‘user_type__p__name‘)print(ret, ret.query) 查询的结果： 1&lt;QuerySet [&#123;‘user_type__p__name‘: ‘allan‘, ‘user_type__caption‘: ‘管路员‘, ‘user‘: ‘ales‘&#125;, &#123;‘user_type__p__name‘: ‘allan‘, ‘user_type__caption‘: ‘普通用户‘, ‘user‘: ‘eric‘&#125;]&gt; SELECT `app01_userinfo`.`user`, `app01_usertype`.`caption`, `app01_p`.`name` FROM `app01_userinfo` INNER JOIN `app01_usertype` ON (`app01_userinfo`.`user_type_id` = `app01_usertype`.`nid`) INNER JOIN `app01_p` ON (`app01_usertype`.`p_id` = `app01_p`.`id`) 如果要拿用户类型是管理员的所有用户： 12ret = models.UserInfo.objects.filter(user_type__caption=&quot;管路员&quot;).values(‘user‘, ‘user_type__caption‘) print(ret) 结果： 1&lt;QuerySet [&#123;‘user‘: ‘ales‘, ‘user_type__caption‘: ‘管路员‘&#125;]&gt; 5、了不起的上下划线值外键反向查找 找到管理员相关联的信息： 12obj = models.UserType.objects.filter(caption=‘管理员‘).first()print(obj.nid, obj.caption) 输出结果： 11 管理员 这里查找的是usertype中的数据，如果通过usertype表查找到userinfo表中的信息就得用***_set: 123456obj = models.UserType.objects.filter(caption=‘管理员‘).first()print(obj.nid, obj.caption)print(obj.userinfo_set.all())ret = models.UserType.objects.all().values(‘nid‘, ‘caption‘, ‘userinfo__user‘)print(ret) 查询结果： 12341 管理员&lt;QuerySet [&lt;UserInfo: UserInfo object&gt;]&gt;&lt;QuerySet [&#123;‘caption‘: ‘管理员‘, ‘userinfo__user‘: ‘alex‘, ‘nid‘: 1&#125;, &#123;‘caption‘: ‘普通用户‘, ‘userinfo__user‘: ‘eric‘, ‘nid‘: 2&#125;, &#123;‘caption‘: ‘超级管理员‘, ‘userinfo__user‘: None, ‘nid‘: 3&#125;]&gt;[27/Aug/2016 15:35:31] &quot;GET /index/ HTTP/1.1&quot; 200 2 如果需要固定字段查找： 12obj = models.UserType.objects.all().values(‘nid‘, ‘userinfo__user‘) print(obj) 结果： 1&lt;QuerySet [&#123;‘userinfo__user‘: ‘alex‘, ‘nid‘: 1&#125;, &#123;‘userinfo__user‘: ‘eric‘, ‘nid‘: 2&#125;, &#123;‘userinfo__user‘: None, ‘nid‘: 3&#125;]&gt; 6、多对多之表创建 多对多创建表的时候直接使用ManyToManyField让django自动创建第三张表或者自己手动创建第三张表，第三张表如果指定多个字段的hu models表结构(自定义的第三张表)： 12345678910111213141516class Host(models.Model): hid = models.AutoField(primary_key=True) hostname = models.CharField(max_length=32) ip = models.CharField(max_length=32)class Group(models.Model): gid = models.AutoField(primary_key=True) name = models.CharField(max_length=16) h2g = models.ManyToManyField(‘Host‘, through=‘HostToGroup‘)class HostToGroup(models.Model): hgid = models.AutoField(primary_key=True) host_id = models.ForeignKey(‘Host‘) group_id = models.ForeignKey(‘Group‘) status = models.IntegerField() 插入数据： 12345678910111213models.Host.objects.create(hostname=‘c1‘, ip=‘1.1.1.1‘)models.Host.objects.create(hostname=‘c2‘, ip=‘1.1.1.2‘)models.Host.objects.create(hostname=‘c3‘, ip=‘1.1.1.3‘)models.Host.objects.create(hostname=‘c4‘, ip=‘1.1.1.4‘)models.Host.objects.create(hostname=‘c5‘, ip=‘1.1.1.5‘)models.Group.objects.create(name=‘技术部‘)models.Group.objects.create(name=‘财务部‘)models.Group.objects.create(name=‘人事部‘)models.Group.objects.create(name=‘公关部‘)models.Group.objects.create(name=‘运营部‘)models.Group.objects.create(name=‘销售部‘)models.Group.objects.create(name=‘客服部‘) 操作表： 获取财务部的对象： 12obj = models.Group.objects.get(gid=2)print(obj.gid, obj.name, obj.h2g.all()) 结果： 12 财务部 &lt;QuerySet []&gt; 给财务部添加主机： 12345# 添加一台主机 obj = models.Group.objects.get(gid=2) # print(obj.gid, obj.name, obj.h2g.all()) h1 = models.Host.objects.get(hid=1) obj.h2g.add(h1) 123456# 把剩下的全部添加 obj = models.Group.objects.get(gid=2) # print(obj.gid, obj.name, obj.h2g.all()) # h1 = models.Host.objects.get(hid=1) q = models.Host.objects.filter(hid__gt=1) obj.h2g.add(*q) 将一台机器分配给多个组(就得用反向操作了)： 12h = models.Host.objects.get(hid=1)h.group_set.add(*models.Group.objects.filter(gid__gt=2)) 操作自己手动创建的第三张关系表: 表结构： 表的数据还是原来的数据。 创建表之间的关系，需要自己手动创建关系： 1models.HostToGroup.objects.create(status=1, group_id_id=2, host_id_id=3) Django详解之models操作 标签： 原文地址：http://www.cnblogs.com/allan-king/p/5807659.html]]></content>
      <tags>
        <tag>django</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[cookie和session区别和用法]]></title>
    <url>%2F2019%2F02%2F28%2Fcookie%E5%92%8Csession%E5%8C%BA%E5%88%AB%E5%92%8C%E7%94%A8%E6%B3%95%2F</url>
    <content type="text"><![CDATA[cookie和session的区别和用法flask中**cookie和session介绍**一、cookie：在网站中，http请求是无状态的。也就是说即使第一次和服务器连接后并且登录成功后，第二次请求服务器依然不能知道当前请求是哪个用户。cookie的出现就是为了解决这个问题，第一次登录后服务器返回一些数据（cookie）给浏览器，然后浏览器保存在本地，当该用户发送第二次请求的时候，就会自动的把上次请求存储的cookie数据自动的携带给服务器，服务器通过浏览器携带的数据就能判断当前用户是哪个了。cookie存储的数据量有限，不同的浏览器有不同的存储大小，但一般不超过4KB。因此使用cookie只能存储一些小量的数据。 二、**session:**session和cookie的作用有点类似，都是为了存储用户相关的信息。不同的是，cookie是存储在本地浏览器，而session存储在服务器。存储在服务器的数据会更加的安全，不容易被窃取。但存储在服务器也有一定的弊端，就是会占用服务器的资源，但现在服务器已经发展至今，一些session信息还是绰绰有余的。 三、cookie和session结合使用：web开发发展至今，cookie和session的使用已经出现了一些非常成熟的方案。在如今的市场或者企业里，一般有两种存储方式： 1、存储在服务端：通过cookie存储一个session_id，然后具体的数据则是保存在session中。如果用户已经登录，则服务器会在cookie中保存一个session_id，下次再次请求的时候，会把该session_id携带上来，服务器根据session_id在session库中获取用户的session数据。就能知道该用户到底是谁，以及之前保存的一些状态信息。这种专业术语叫做server side session。 2、将session数据加密，然后存储在cookie中。这种专业术语叫做client side session。flask采用的就是这种方式，但是也可以替换成其他形式。 flask中使用cookie和session一、cookies：在Flask中操作cookie，是通过response对象来操作，可以在response返回之前，通过response.set_cookie来设置，这个方法有以下几个参数需要注意： key：设置的cookie的key。 value：key对应的value。 max_age：改cookie的过期时间，如果不设置，则浏览器关闭后就会自动过期。 expires：过期时间，应该是一个datetime类型。 domain：该cookie在哪个域名中有效。一般设置子域名，比如cms.example.com。 path：该cookie在哪个路径下有效。 使用： 获取：request.cookies.get(key, ‘默认值’) 设置：resp.set_cookie(key, value, max_age=整数) 删除：resp.delete_cookie(key) 二、session：Flask中的session是通过from flask import session。然后添加值key和value进去即可。 client side session：Flask中的session机制是将session信息加密，然后存储在cookie中。专业术语叫做client side session。 server side session：存储在服务器，客户端保存的时session_id（通过cookie完成） 使用： 获取：session.get(key, ‘默认值’) 设置： ​ session.permanent = True ​ session[key] = value 删除： 指定删除：session.pop(key, None) 清空所有：session.clear() 三、manage.py]]></content>
      <tags>
        <tag>cookie</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[几种常见的网络协议]]></title>
    <url>%2F2019%2F02%2F27%2F%E5%87%A0%E7%A7%8D%E5%B8%B8%E8%A7%81%E7%9A%84%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE%2F</url>
    <content type="text"><![CDATA[几种常用的网络协议 一、OSI模型 名称 层次 功能 物理层 1 实现计算机系统与网络间的物理连接 数据链路层 2 进行数据打包与解包，形成信息帧 网络层 3 提供数据通过的路由 传输层 4 提供传输顺序信息与响应 会话层 5 建立和中止连接 表示层 6 数据转换、确认数据格式 应用层 7 提供用户程序接口 二、协议层次 网络中常用协议以及层次关系 1、 进程/应用程的协议 平时最广泛的协议，这一层的每个协议都由客程序和服务程序两部分组成。程序通过服务器与客户机交互来工作。常见协议有：Telnet、FTP、SMTP、HTTP、DNS等。 2、 主机—主机层协议 建立并且维护连接，用于保证主机间数据传输的安全性。这一层主要有两个协议： TCP（Transmission Control Protocol：传输控制协议；面向连接，可靠传输 UDP（User Datagram Protocol）：用户数据报协议；面向无连接，不可靠传输 3、 Internet层协议 负责数据的传输，在不同网络和系统间寻找路由，分段和重组数据报文，另外还有设备寻址。些层包括如下协议： IP（Internet Protocol）:Internet协议，负责TCP/IP主机间提供数据报服务，进行数据封装并产生协议头，TCP与UDP协议的基础。 ICMP（Internet Control Message Protocol）：Internet控制报文协议。ICMP协议其实是IP协议的的附属协议，IP协议用它来与其它主机或路由器交换错误报文和其它的一些网络情况，在ICMP包中携带了控制信息和故障恢复信息。 ARP（Address Resolution Protocol）协议：地址解析协议。 RARP（Reverse Address Resolution Protocol）：逆向地址解析协议。 OSI 全称（Open System Interconnection）网络的OSI七层结构2008年03月28日 星期五 14:18（1）物理层——Physical这是整个OSI参考模型的最低层，它的任务就是提供网络的物理连接。所以，物理层是建立在物理介质上（而不是逻辑上的协议和会话），它提供的是机械和电气接口。主要包括电缆、物理端口和附属设备，如双绞线、同轴电缆、接线设备（如网卡等）、RJ－45接口、串口和并口等在网络中都是工作在这个层次的。物理层提供的服务包括：物理连接、物理服务数据单元顺序化（接收物理实体收到的比特顺序，与发送物理实体所发送的比特顺序相同）和数据电路标识。 （2）数据链路层——DataLink数据链路层是建立在物理传输能力的基础上，以帧为单位传输数据，它的主要任务就是进行数据封装和数据链接的建立。封装的数据信息中，地址段含有发送节点和接收节点的地址，控制段用来表示数据连接帧的类型，数据段包含实际要传输的数据，差错控制段用来检测传输中帧出现的错误。数据链路层可使用的协议有SLIP、PPP、X.25和帧中继等。常见的集线器和低档的交换机网络设备都是工作在这个层次上，Modem之类的拨号设备也是。工作在这个层次上的交换机俗称“第二层交换机”。具体讲，数据链路层的功能包括：数据链路连接的建立与释放、构成数据链路数据单元、数据链路连接的分裂、定界与同步、顺序和流量控制和差错的检测和恢复等方面。 （3）网络层——Network网络层属于OSI中的较高层次了，从它的名字可以看出，它解决的是网络与网络之间，即网际的通信问题，而不是同一网段内部的事。网络层的主要功能即是提供路由，即选择到达目标主机的最佳路径，并沿该路径传送数据包。除此之外，网络层还要能够消除网络拥挤，具有流量控制和拥挤控制的能力。网络边界中的路由器就工作在这个层次上，现在较高档的交换机也可直接工作在这个层次上，因此它们也提供了路由功能，俗称“第三层交换机”。网络层的功能包括：建立和拆除网络连接、路径选择和中继、网络连接多路复用、分段和组块、服务选择和流量控制。 （4）传输层——Transport传输层解决的是数据在网络之间的传输质量问题，它属于较高层次。传输层用于提高网络层服务质量，提供可靠的端到端的数据传输，如常说的QoS就是这一层的主要服务。这一层主要涉及的是网络传输协议，它提供的是一套网络数据传输标准，如TCP协议。传输层的功能包括：映像传输地址到网络地址、多路复用与分割、传输连接的建立与释放、分段与重新组装、组块与分块。根据传输层所提供服务的主要性质，传输层服务可分为以下三大类：A类：网络连接具有可接受的差错率和可接受的故障通知率（网络连接断开和复位发生的比率），A类服务是可靠的网络服务，一般指虚电路服务。C类：网络连接具有不可接受的差错率，C类的服务质量最差，提供数据报服务或无线电分组交换网均属此类。B类：网络连接具有可接受的差错率和不可接受的故障通知率，B类服务介于A类与C类之间，在广域网和互联网多是提供B类服务。 网络服务质量的划分是以用户要求为依据的。若用户要求比较高，则一个网络可能归于C型，反之，则一个网络可能归于B型甚至A型。例如，对于某个电子邮件系统来说，每周丢失一个分组的网络也许可算作A型；而同一个网络对银行系统来说则只能算作C型了。 （5）会话层——Senssion会话层利用传输层来提供会话服务，会话可能是一个用户通过网络登录到一个主机，或一个正在建立的用于传输文件的会话。会话层的功能主要有：会话连接到传输连接的映射、数据传送、会话连接的恢复和释放、会话管理、令牌管理和活动管理。 （6）表示层——Presentation表示层用于数据管理的表示方式，如用于文本文件的ASCII和EBCDIC，用于表示数字的1S或2S补码表示形式。如果通信双方用不同的数据表示方法，他们就不能互相理解。表示层就是用于屏蔽这种不同之处。表示层的功能主要有：数据语法转换、语法表示、表示连接管理、数据加密和数据压缩。 （7）应用层——Application这是OSI参考模型的最高层，它解决的也是最高层次，即程序应用过程中的问题，它直接面对用户的具体应用。应用层包含用户应用程序执行通信任务所需要的协议和功能，如电子邮件和文件传输等，在这一层中TCP/IP协议中的FTP、SMTP、POP等协议得到了充分应用。SNMP(Simple Network Management Protocol,简单网络管理协议)的前身是简单网关监控协议(SGMP)，用来对通信线路进行管理。随后，人们对SGMP进行了很大的修改，特别是加入了符合Internet定义的SMI和MIB：体系结构，改进后的协议就是著名的SNMP。SNMP的目标是管理互联网Internet上众多厂家生产的软硬件平台，因此SNMP受Internet标准网络管理框架的影响也很大。现在SNMP已经出到第三个版本的协议，其功能较以前已经大大地加强和改进了。 SNMP的体系结构是围绕着以下四个概念和目标进行设计的：保持管理代理(agent)的软件成本尽可能低；最大限度地保持远程管理的功能，以便充分利用Internet的网络资源；体系结构必须有扩充的余地；保持SNMP的独立性，不依赖于具体的计算机、网关和网络传输协议。在最近的改进中，又加入了保证SNMP体系本身安全性的目标。OSPF(Open Shortest Path First开放式最短路径优先)是一个内部网关协议(Interior Gateway Protocol,简称IGP)，用于在单一自治系统(autonomous system,AS)内决策路由。与RIP相对，OSPF是链路状态路由协议，而RIP是距离向量路由协议。RIP(Routing information Protocol)是应用较早、使用较普遍的内部网关协议(Interior Gateway Protocol,简称IGP)，适用于小型同类网络，是典型的距离向量(distance-vector)协议。文档见RFC1058、RFC1723。RIP通过广播UDP报文来交换路由信息，每30秒发送一次路由信息更新。RIP提供跳跃计数(hop count)作为尺度来衡量路由距离，跳跃计数是一个包到达目标所必须经过的路由器的数目。如果到相同目标有二个不等速或不同带宽的路由器，但跳跃计数相同，则RIP认为两个路由是等距离的。RIP最多支持的跳数为15，即在源和目的网间所要经过的最多路由器的数目为15，跳数16表示不可达CSMA/CD（Carrier Sense Multiple Access/Collision Detect）即载波监听多路访问/冲突检测方法一、基础篇：是一种争用型的介质访问控制协议。它起源于美国夏威夷大学开发的ALOHA网所采用的争用型协议，并进行了改进，使之具有比ALOHA协议更高的介质利用率。CSMA/CD控制方式的优点是：原理比较简单，技术上易实现，网络中各工作站处于平等地位 ，不需集中控制，不提供优先级控制。但在网络负载增大时，发送时间增长，发送效率急剧下降。CSMA/CD应用在 ISO7层里的数据链路层它的工作原理是: 发送数据前 先监听信道是否空闲 ,若空闲 则立即发送数据.在发送数据时,边发送边继续监听.若监听到冲突,则立即停止发送数据.等待一段随即时间,再重新尝试.二、进阶篇：CSMA/CD控制规程：控制规程的核心问题：解决在公共通道上以广播方式传送数据中可能出现的问题（主要是数据碰撞问题）控制过程包含四个处理内容：侦听、发送、检测、冲突处理（1） 侦听：通过专门的检测机构，在站点准备发送前先侦听一下总线上是否有数据正在传送（线路是否忙）？若“忙”则进入后述的“退避”处理程序，进而进一步反复进行侦听工作。若“闲”，则一定算法原则（“X坚持”算法）决定如何发送。（2） 发送：当确定要发送后，通过发送机构，向总线发送数据。（3） 检测：数据发送后，也可能发生数据碰撞。因此，要对数据边发送，边接收，以判断是否冲突了。（参5P127图）（4）冲突处理： 当确认发生冲突后，进入冲突处理程序。有两种冲突情况： ① 侦听中发现线路忙② 发送过程中发现数据碰撞① 若在侦听中发现线路忙，则等待一个延时后再次侦听，若仍然忙，则继续延迟等待，一直到可以发送为止。每次延时的时间不一致，由退避算法确定延时值。② 若发送过程中发现数据碰撞，先发送阻塞信息，强化冲突，再进行侦听工作，以待下次重新发送（方法同①） 面向比特的协议中最有代表性的是IBM的同步数据链路控制规程SDLC（Synchronous Data Link Control），国际标准化组织ISO （International Standards Organization）的高级数据链路控制规程HDLC（High Level Data Link Control），美国国家标准协会（American National Standar ds Institute ）的先进数据通信规程ADCCP （ Advanced Data Communications Control Procedure）。这些协议的特点是所传输的一帧数据可以是任意位，而且它是靠约定的位组合模式，而不是靠特定字符来标志帧的开始和结束，故称”面向比特”的协议。 二．帧信息的分段 SDLC／HDLC的一帧信息包括以下几个场（Field），所有场都是从最低有效位开始传送。 1． SDLC／HDLC标志字符 SDLC／HDLC协议规定，所有信息传输必须以一个标志字符开始，且以同一个字符结束。这个标志字符是01111110，称标志场（F）。从开始标志到结束标志之间构成一个完整的信息单位，称为一帧（Frame）。所有的信息是以帧的形式传输的，而标志字符提供了每一帧的边界。接收端可以通过搜索”01111110”来探知帧的开头和结束，以此建立帧同步。 2．地址场和控制场 在标志场之后，可以有一个地址场A（Address）和一个控制场C（Contro1）。地址场用来规定与之通信的次站的地址。控制场可规定若干个命令。SDLC规定A场和C场的宽度为8位。HDLC则允许A场可为任意长度，C场为8位或16位。接收方必须检查每个地址字节的第一位，如果为”0”，则后边跟着另一个地址字节；若为”1”，则该字节就是最后一个地址字节。同理，如果控制场第一个字节的第一位为”0”，则还有第二个控制场字节，否则就只有一个字节。 3．信息场 跟在控制场之后的是信息场I（Information）。I场包含有要传送的数据，亦成为数据场。并不是每一帧都必须有信息场。即信息场可以为0，当它为0时，则这一帧主要是控制命令。 4．帧校验场 紧跟在信息场之后的是两字节的帧校验场，帧校验场称为FC（Frame Check）场， 校验序列FCS（Frame check Sequence）。SDLC／HDLC均采用16位循环冗余校验码CRC （Cyclic Redundancy Code），其生成多项式为CCITT多项式X^16+X^12+X^5+1。除了标志场和自动插入的”0”位外，所有的信息都参加CRC计算。 CRC的编码器在发送码组时为每一码组加入冗余的监督码位。接收时译码器可对在纠错范围内的错码进行纠正，对在校错范 围内的错码进行校验，但不能纠正。超出校、纠错范围之外的多位错误将不可能被校验发现 。 三．实际应用时的两个技术问题 1．”0”位插入／删除技术 如上所述，SDLC／HDLC协议规定以01111110为标志字节，但在信息场中也完全有可能有同一种模式的字符，为了把它与标志区分开来，所以采取了”0”位插入和删除技术。具体作法是发送端在发送所有信息（除标志字节外）时，只要遇到连续5个”1”，就自动插入一个”0”当接收端在接收数据时（除标志字节）如果连续接收到5个”1”，就自动将其后的一个”0”删除，以恢复信息的原有形式。这种”0”位的插入和删除过程是由硬件自动完成的，比上述面向字符的”数据透明”容易实现。 2． SDLC／HDLC异常结束 若在发送过程中出现错误，则SDLC／HDLC协议用异常结束（Abort）字符，或称失效序列使本帧作废。在HDLC规程中7个连续的”1”被作为失效字符，而在SDLC中失效字符是8个连续的”1”。当然在失效序列中不使用”0”位插入／删除技术。 SDLC／HDLC协议规定，在一帧之内不允许出现数据间隔。在两帧信息之间，发送器可以连续输出标志字符序列，也可以输出连续的高电平，它被称为空闲（Idle）信号。 # 常用的HTTP协议http协议：超文本传输协议方案，除了没有用户名和密码之外，与通用的URL格式相符，如果省略了端口，就默认为80 基本格式：http://:/?# 示例：http://www.baidu.com:80/index.html https协议：该方案与http方案是一对的，唯一的区别在于方案https使用了网景的SSL，SSL为HTTP连接提供了端到端的加密机制，其语法与HTTP的语法相同，默认端口为443 基本格式：https://:/?# 示例：https://www.baidu.com:80/index.html mailto协议：mailto URL指向的是E-mail地址，由于E-mail的行为与其他方案都有所不同，它并不指向任何可以直接访问的对象 基本格式：mailto: 示例：mailto:joe@joes-hardware.com ftp协议：文件传输协议URL可以用来从FTP服务器上下载或向其上载文件，并获取FTP服务器上的目录结构内容的列表 基本格式：ftp::@:/; 示例：ftp://anonymous:joe%40joes@prep.an.edu:21/pub/gs rtsp和rtspu协议：RTSP URL是可以通过实时流传输协议解析的音/视频媒体资源的标示符。方案respu中的u表示它是使用UDP协议来获取资源的 基本格式：rtsp::@:/ 示例：rtspu://www.baidu.com:554/inte/cto_video file协议：file方案表示一台指定主机上可直接访问的文件。各字段都遵循通用格式，如果省略了主机名，就默认为正在使用URL的本地主机 基本格式：file::@:/ 示例：file://OFFICE-FS/poli/cds.doc telnet协议：telnet方案用于访问交互式业务，它表示的并不是对象自身，而是可通过telnet协议访问的交互式应用程式(资源)。 基本格式：telnet://:@:/ 示例：telnet:csh:webcsh@joes.com:50/]]></content>
      <tags>
        <tag>网络协议</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[输入一个url到浏览器页面展示都经历了哪些过程]]></title>
    <url>%2F2019%2F02%2F26%2F%E8%BE%93%E5%85%A5%E4%B8%80%E4%B8%AAurl%E5%88%B0%E6%B5%8F%E8%A7%88%E5%99%A8%E9%A1%B5%E9%9D%A2%E5%B1%95%E7%A4%BA%E9%83%BD%E7%BB%8F%E5%8E%86%E4%BA%86%E5%93%AA%E4%BA%9B%E8%BF%87%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[在日常的浏览器访问过程中，我们肯定会访问n多页面，但是我们输入一个网址后是如何变成一个页面展示在我们面前，从一个url到页面的展示这个过程中，我们的浏览器都经历了一些什么？ 步骤→ 1- 输入网址→ 2- 缓存解析→ 3- 域名解析→ 4- tcp连接，三次握手→ 6- 页面渲染 一：输入网址 那肯定是输入你要访问的网站网址了，俗称url； 二：缓存解析 浏览器获取了这个url，当然就去解析了，它先去缓存当中看看有没有，从 浏览器缓存-系统缓存-路由器缓存 当中查看，如果有从缓存当中显示页面，然后没有那就进行步骤三；缓存就是把你之前访问的web资源，比如一些js，css，图片什么的保存在你本机的内存或者磁盘当中。 （1） 在chrome浏览器中输入网址： chrome://chrome-urls/ chrome-urls是一个看到所有的Chrome支持的伪RUL，找到其中的chrome://appcache-internals/ 可以看见chrome的本地缓存地址：Instances in: C:\Users\User\AppData\Local\Google\Chrome\User Data\Default (0) （2）在chrome中访问www.baidu.com/，打开开发者模式，不勾选 Disable cache 圈出来的部分显示了资源的来源： from disk cache ： 将资源缓存到磁盘中，等待下次访问时不需要重新下载资源，而直接从磁盘中获取；from memory cache ：将资源缓存到内存中，等待下次访问时不需要重新下载资源，而直接从内存中获取；可以看见资源的来源是缓存当中，从缓存当中获取了这些就可以直接显示在页面中，不需要发送http请求； 三： 域名解析 和步骤二一样，做一个访问新页面的操作juejin.im/timeline，同样打开开发者模式，，不勾选 Disable cache 可以发现它的来源再也不是： from disk cache 或者from memory cache ，即发送http请求。那么在发送http请求前，浏览器做了什么？ 在发送http之前，需要进行DNS解析即域名解析。DNS解析:域名到IP地址的转换过程。域名的解析工作由DNS服务器完成。解析后可以获取域名相应的IP地址 四：tcp连接，三次握手 在域名解析之后，浏览器向服务器发起了http请求，tcp连接，三次握手建立tcp连接。TCP协议是面向连接的，所以在传输数据前必须建立连接 （1）客户端向服务器发送连接请求报文；（2）服务器端接受客户端发送的连接请求后后回复ACK报文，并为这次连接分配资源。（3）客户端接收到ACK报文后也向服务器端发生ACK报文，并分配资源。 这样TCP连接就建立了。在此之后，浏览器开始向服务器发送http请求，请求数据包。请求信息包含一个头部和一个请求体。 五：服务器收到请求 服务器收到浏览器发送的请求信息，返回一个响应头和一个响应体。 六：页面渲染 浏览器收到服务器发送的响应头和响应体，进行客户端渲染，生成Dom树、解析css样式、js交互 简单理解为： 在此期间经历了四个过程，如下： 1.域名解析：根据域名找到IP地址的过程，一个完整的域名由2个或2个以上的部分组成。IP分为网络部分和主机部分，子网掩码就是告诉计算机哪是网络部分，哪是主机部分。路由器中的地址一般使用网段中第一个地址，15.0.0.1这样，每个计算机都要配网关，网关在不同网段转发。MAC地址(物理地址),出厂时固定到网卡上了，48位的二进制，路由器也有mac地址。通过DNS服务器获取IP地址，发数据包时就发给服务器IP。寻找域名对应的ＩＰ地址的过程为：Ｉ查找浏览器缓存；ＩＩ．查找系统缓存，- windows系统为从C:\Windows\System32\drivers\etc\hosts文件中查找 ；- linux系统为从/etc/hosts文件中查找 ；ＩＩＩ．查找路由器缓存和ISP的DNS服务器缓存 ；ＩＶ.如果以上方式均找不到，则从顶级域名开始查找； 2.建立ＴＣＰ连接：建立：三次握手；释放连接：四次挥手。网页一般比较大，一个数据包传不过去，数据包最大ＭＴＵ＝１５００，把网页进行切割、编号，发过去后对方按照编号整合成一个完整的网页。那么，该如何切割呢？有解：ａ．数据分割好后放缓存里，发送缓存，接收缓存都有；ｂ．先放缓存，再准备发；ｃ．从缓存中发出去的数据不能删，因为中途可能传输中丢掉，客户端收到后给一个确认，然后就可以从缓存中删除；ｄ．浏览器端从接受缓存中读取数据，再拼成一个网页。； 3.浏览器发送Ｇｅｔ请求到服务器，服务器根据请求返回内容给浏览器。； 4.返回页面：浏览器显示页面中所有文本。原文：https://blog.csdn.net/lilyheart1/article/details/80611730]]></content>
      <tags>
        <tag>http</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RESTful API 设计指南]]></title>
    <url>%2F2019%2F02%2F26%2FRESTful%20API%20%E8%AE%BE%E8%AE%A1%E6%8C%87%E5%8D%97%2F</url>
    <content type="text"><![CDATA[网络应用程序，分为前端和后端两个部分。当前的发展趋势，就是前端设备层出不穷（手机、平板、桌面电脑、其他专用设备……）。 因此，必须有一种统一的机制，方便不同的前端设备与后端进行通信。这导致API构架的流行，甚至出现“API First”的设计思想。RESTful API是目前比较成熟的一套互联网应用程序的API设计理论。我以前写过一篇《理解RESTful架构》，探讨如何理解这个概念。 今天，我将介绍RESTful API的设计细节，探讨如何设计一套合理、好用的API。我的主要参考了两篇文章（1，2）。 一、协议API与用户的通信协议，总是使用HTTPs协议。 二、域名应该尽量将API部署在专用域名之下。 12&gt; https://api.example.com&gt; 如果确定API很简单，不会有进一步扩展，可以考虑放在主域名下。 12&gt; https://example.org/api/&gt; 三、版本（Versioning）应该将API的版本号放入URL。 12&gt; https://api.example.com/v1/&gt; 另一种做法是，将版本号放在HTTP头信息中，但不如放入URL方便和直观。Github采用这种做法。 四、路径（Endpoint）路径又称”终点”（endpoint），表示API的具体网址。 在RESTful架构中，每个网址代表一种资源（resource），所以网址中不能有动词，只能有名词，而且所用的名词往往与数据库的表格名对应。一般来说，数据库中的表都是同种记录的”集合”（collection），所以API中的名词也应该使用复数。 举例来说，有一个API提供动物园（zoo）的信息，还包括各种动物和雇员的信息，则它的路径应该设计成下面这样。 https://api.example.com/v1/zoos https://api.example.com/v1/animals https://api.example.com/v1/employees 五、HTTP动词对于资源的具体操作类型，由HTTP动词表示。 常用的HTTP动词有下面五个（括号里是对应的SQL命令）。 GET（SELECT）：从服务器取出资源（一项或多项）。 POST（CREATE）：在服务器新建一个资源。 PUT（UPDATE）：在服务器更新资源（客户端提供改变后的完整资源）。 PATCH（UPDATE）：在服务器更新资源（客户端提供改变的属性）。 DELETE（DELETE）：从服务器删除资源。 还有两个不常用的HTTP动词。 HEAD：获取资源的元数据。 OPTIONS：获取信息，关于资源的哪些属性是客户端可以改变的。 下面是一些例子。 GET /zoos：列出所有动物园 POST /zoos：新建一个动物园 GET /zoos/ID：获取某个指定动物园的信息 PUT /zoos/ID：更新某个指定动物园的信息（提供该动物园的全部信息） PATCH /zoos/ID：更新某个指定动物园的信息（提供该动物园的部分信息） DELETE /zoos/ID：删除某个动物园 GET /zoos/ID/animals：列出某个指定动物园的所有动物 DELETE /zoos/ID/animals/ID：删除某个指定动物园的指定动物 六、过滤信息（Filtering）如果记录数量很多，服务器不可能都将它们返回给用户。API应该提供参数，过滤返回结果。 下面是一些常见的参数。 ?limit=10：指定返回记录的数量 ?offset=10：指定返回记录的开始位置。 ?page=2&amp;per_page=100：指定第几页，以及每页的记录数。 ?sortby=name&amp;order=asc：指定返回结果按照哪个属性排序，以及排序顺序。 ?animal_type_id=1：指定筛选条件 参数的设计允许存在冗余，即允许API路径和URL参数偶尔有重复。比如，GET /zoo/ID/animals 与 GET /animals?zoo_id=ID 的含义是相同的。 七、状态码（Status Codes）服务器向用户返回的状态码和提示信息，常见的有以下一些（方括号中是该状态码对应的HTTP动词）。 200 OK - [GET]：服务器成功返回用户请求的数据，该操作是幂等的（Idempotent）。 201 CREATED - [POST/PUT/PATCH]：用户新建或修改数据成功。 202 Accepted - [*]：表示一个请求已经进入后台排队（异步任务） 204 NO CONTENT - [DELETE]：用户删除数据成功。 400 INVALID REQUEST - [POST/PUT/PATCH]：用户发出的请求有错误，服务器没有进行新建或修改数据的操作，该操作是幂等的。 401 Unauthorized - [*]：表示用户没有权限（令牌、用户名、密码错误）。 403 Forbidden - [*] 表示用户得到授权（与401错误相对），但是访问是被禁止的。 404 NOT FOUND - [*]：用户发出的请求针对的是不存在的记录，服务器没有进行操作，该操作是幂等的。 406 Not Acceptable - [GET]：用户请求的格式不可得（比如用户请求JSON格式，但是只有XML格式）。 410 Gone -[GET]：用户请求的资源被永久删除，且不会再得到的。 422 Unprocesable entity - [POST/PUT/PATCH] 当创建一个对象时，发生一个验证错误。 500 INTERNAL SERVER ERROR - [*]：服务器发生错误，用户将无法判断发出的请求是否成功。 状态码的完全列表参见这里。 八、错误处理（Error handling）如果状态码是4xx，就应该向用户返回出错信息。一般来说，返回的信息中将error作为键名，出错信息作为键值即可。 1234&gt; &#123;&gt; error: "Invalid API key"&gt; &#125;&gt; 九、返回结果针对不同操作，服务器向用户返回的结果应该符合以下规范。 GET /collection：返回资源对象的列表（数组） GET /collection/resource：返回单个资源对象 POST /collection：返回新生成的资源对象 PUT /collection/resource：返回完整的资源对象 PATCH /collection/resource：返回完整的资源对象 DELETE /collection/resource：返回一个空文档 十、Hypermedia APIRESTful API最好做到Hypermedia，即返回结果中提供链接，连向其他API方法，使得用户不查文档，也知道下一步应该做什么。 比如，当用户向api.example.com的根目录发出请求，会得到这样一个文档。 1234567&gt; &#123;"link": &#123;&gt; "rel": "collection https://www.example.com/zoos",&gt; "href": "https://api.example.com/zoos",&gt; "title": "List of zoos",&gt; "type": "application/vnd.yourformat+json"&gt; &#125;&#125;&gt; 上面代码表示，文档中有一个link属性，用户读取这个属性就知道下一步该调用什么API了。rel表示这个API与当前网址的关系（collection关系，并给出该collection的网址），href表示API的路径，title表示API的标题，type表示返回类型。 Hypermedia API的设计被称为HATEOAS。Github的API就是这种设计，访问api.github.com会得到一个所有可用API的网址列表。 123456&gt; &#123;&gt; "current_user_url": "https://api.github.com/user",&gt; "authorizations_url": "https://api.github.com/authorizations",&gt; // ...&gt; &#125;&gt; 从上面可以看到，如果想获取当前用户的信息，应该去访问api.github.com/user，然后就得到了下面结果。 12345&gt; &#123;&gt; "message": "Requires authentication",&gt; "documentation_url": "https://developer.github.com/v3"&gt; &#125;&gt; 上面代码表示，服务器给出了提示信息，以及文档的网址。 十一、其他（1）API的身份认证应该使用OAuth 2.0框架。 （2）服务器返回的数据格式，应该尽量使用JSON，避免使用XML。 （完） 转载：http://www.ruanyifeng.com/blog/2014/05/restful_api.html?tdsourcetag=s_pcqq_aiomsg]]></content>
      <tags>
        <tag>api</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[TCP和UDP的优缺点及区别]]></title>
    <url>%2F2019%2F02%2F26%2FTCP%E5%92%8CUDP%E7%9A%84%E4%BC%98%E7%BC%BA%E7%82%B9%E5%8F%8A%E5%8C%BA%E5%88%AB%2F</url>
    <content type="text"><![CDATA[TCP和UDP的优缺点及区别TCP的优点： 可靠，稳定 TCP的可靠体现在TCP在传递数据之前，会有三次握手来建立连接，而且在数据传递时，有确认、窗口、重传、拥塞控制机制，在数据传完后，还会断开连接用来节约系统资源。 TCP的缺点： 慢，效率低，占用系统资源高，易被攻击 TCP在传递数据之前，要先建连接，这会消耗时间，而且在数据传递时，确认机制、重传机制、拥塞控制机制等都会消耗大量的时间，而且要在每台设备上维护所有的传输连接，事实上，每个连接都会占用系统的CPU、内存等硬件资源。 而且，因为TCP有确认机制、三次握手机制，这些也导致TCP容易被人利用，实现DOS、DDOS、CC等攻击。 UDP的优点： 快，比TCP稍安全 UDP没有TCP的握手、确认、窗口、重传、拥塞控制等机制，UDP是一个无状态的传输协议，所以它在传递数据时非常快。没有TCP的这些机制，UDP较TCP被攻击者利用的漏洞就要少一些。但UDP也是无法避免攻击的，比如：UDP Flood攻击…… UDP的缺点： 不可靠，不稳定 因为UDP没有TCP那些可靠的机制，在数据传递时，如果网络质量不好，就会很容易丢包。 基于上面的优缺点，那么： 什么时候应该使用TCP： 当对网络通讯质量有要求的时候，比如：整个数据要准确无误的传递给对方，这往往用于一些要求可靠的应用，比如HTTP、HTTPS、FTP等传输文件的协议，POP、SMTP等邮件传输的协议。 在日常生活中，常见使用TCP协议的应用如下： 浏览器，用的HTTP FlashFXP，用的FTP Outlook，用的POP、SMTP Putty，用的Telnet、SSH QQ文件传输 ………… 什么时候应该使用UDP： 当对网络通讯质量要求不高的时候，要求网络通讯速度能尽量的快，这时就可以使用UDP。 比如，日常生活中，常见使用UDP协议的应用如下： QQ语音 QQ视频 TFTP …… 有些应用场景对可靠性要求不高会用到UPD，比如长视频，要求速率 小结TCP与UDP的区别： 1.基于连接与无连接；2.对系统资源的要求（TCP较多，UDP少）；3.UDP程序结构较简单；4.流模式与数据报模式 ； 5.TCP保证数据正确性，UDP可能丢包，TCP保证数据顺序，UDP不保证。 123456tcp协议和udp协议的差别 TCP UDP 是否连接 面向连接 面向非连接 传输可靠性 可靠 不可靠 应用场合 传输大量数据 少量数据 速度 慢 快 TCP与UDP区别总结： 1、TCP面向连接（如打电话要先拨号建立连接）;UDP是无连接的，即发送数据之前不需要建立连接 1234567892、TCP提供可靠的服务。也就是说，通过TCP连接传送的数据，无差错，不丢失，不重复，且按序到达;UDP尽最大努力交付，即不保证可靠交付3、TCP面向字节流，实际上是TCP把数据看成一连串无结构的字节流;UDP是面向报文的UDP没有拥塞控制，因此网络出现拥塞不会使源主机的发送速率降低（对实时应用很有用，如IP电话，实时视频会议等）4、每一条TCP连接只能是点到点的;UDP支持一对一，一对多，多对一和多对多的交互通信5、TCP首部开销20字节;UDP的首部开销小，只有8个字节 6、TCP的逻辑通信信道是全双工的可靠信道，UDP则是不可靠信道]]></content>
      <tags>
        <tag>http</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python中的单例模式的几种实现方式的及优化]]></title>
    <url>%2F2019%2F02%2F26%2FPython%E4%B8%AD%E7%9A%84%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F%E7%9A%84%E5%87%A0%E7%A7%8D%E5%AE%9E%E7%8E%B0%E6%96%B9%E5%BC%8F%E7%9A%84%E5%8F%8A%E4%BC%98%E5%8C%96%2F</url>
    <content type="text"><![CDATA[Python中的单例模式的几种实现方式的及优化阅读目录(Content) 单例模式 实现单例模式的几种方式 1.使用模块 2.使用装饰器 3.使用类 4.基于new方法实现（推荐使用，方便） 5.基于metaclass方式实现 相关知识 实现单例模式 回到顶部(go to top) 单例模式单例模式（Singleton Pattern）是一种常用的软件设计模式，该模式的主要目的是确保某一个类只有一个实例存在。当你希望在整个系统中，某个类只能出现一个实例时，单例对象就能派上用场。 比如，某个服务器程序的配置信息存放在一个文件中，客户端通过一个 AppConfig 的类来读取配置文件的信息。如果在程序运行期间，有很多地方都需要使用配置文件的内容，也就是说，很多地方都需要创建 AppConfig 对象的实例，这就导致系统中存在多个 AppConfig 的实例对象，而这样会严重浪费内存资源，尤其是在配置文件内容很多的情况下。事实上，类似 AppConfig 这样的类，我们希望在程序运行期间只存在一个实例对象。 在 Python 中，我们可以用多种方法来实现单例模式 回到顶部(go to top) 实现单例模式的几种方式1.使用模块其实，Python 的模块就是天然的单例模式，因为模块在第一次导入时，会生成 .pyc 文件，当第二次导入时，就会直接加载 .pyc 文件，而不会再次执行模块代码。因此，我们只需把相关的函数和数据定义在一个模块中，就可以获得一个单例对象了。如果我们真的想要一个单例类，可以考虑这样做： mysingleton.py 1234class Singleton(object): def foo(self): passsingleton = Singleton() 将上面的代码保存在文件 mysingleton.py 中，要使用时，直接在其他文件中导入此文件中的对象，这个对象即是单例模式的对象 1from a import singleton 2.使用装饰器;) 123456789101112131415161718192021def Singleton(cls): _instance = &#123;&#125; def _singleton(*args, **kargs): if cls not in _instance: _instance[cls] = cls(*args, **kargs) return _instance[cls] return _singleton@Singletonclass A(object): a = 1 def __init__(self, x=0): self.x = xa1 = A(2)a2 = A(3) ;) 3.使用类;) 12345678910class Singleton(object): def __init__(self): pass @classmethod def instance(cls, *args, **kwargs): if not hasattr(Singleton, &quot;_instance&quot;): Singleton._instance = Singleton(*args, **kwargs) return Singleton._instance ;) 一般情况，大家以为这样就完成了单例模式，但是这样当使用多线程时会存在问题 ;) 1234567891011121314151617181920class Singleton(object): def __init__(self): pass @classmethod def instance(cls, *args, **kwargs): if not hasattr(Singleton, &quot;_instance&quot;): Singleton._instance = Singleton(*args, **kwargs) return Singleton._instanceimport threadingdef task(arg): obj = Singleton.instance() print(obj)for i in range(10): t = threading.Thread(target=task,args=[i,]) t.start() ;) 程序执行后，打印结果如下： ;) 12345678910&lt;__main__.Singleton object at 0x02C933D0&gt;&lt;__main__.Singleton object at 0x02C933D0&gt;&lt;__main__.Singleton object at 0x02C933D0&gt;&lt;__main__.Singleton object at 0x02C933D0&gt;&lt;__main__.Singleton object at 0x02C933D0&gt;&lt;__main__.Singleton object at 0x02C933D0&gt;&lt;__main__.Singleton object at 0x02C933D0&gt;&lt;__main__.Singleton object at 0x02C933D0&gt;&lt;__main__.Singleton object at 0x02C933D0&gt;&lt;__main__.Singleton object at 0x02C933D0&gt; ;) 看起来也没有问题，那是因为执行速度过快，如果在init方法中有一些IO操作，就会发现问题了，下面我们通过time.sleep模拟 我们在上面init方法中加入以下代码： 123def __init__(self): import time time.sleep(1) 重新执行程序后，结果如下 ;) 12345678910&lt;__main__.Singleton object at 0x034A3410&gt;&lt;__main__.Singleton object at 0x034BB990&gt;&lt;__main__.Singleton object at 0x034BB910&gt;&lt;__main__.Singleton object at 0x034ADED0&gt;&lt;__main__.Singleton object at 0x034E6BD0&gt;&lt;__main__.Singleton object at 0x034E6C10&gt;&lt;__main__.Singleton object at 0x034E6B90&gt;&lt;__main__.Singleton object at 0x034BBA30&gt;&lt;__main__.Singleton object at 0x034F6B90&gt;&lt;__main__.Singleton object at 0x034E6A90&gt; ;) 问题出现了！按照以上方式创建的单例，无法支持多线程 解决办法：加锁！未加锁部分并发执行,加锁部分串行执行,速度降低,但是保证了数据安全 ;) 12345678910111213141516171819202122232425import timeimport threadingclass Singleton(object): _instance_lock = threading.Lock() def __init__(self): time.sleep(1) @classmethod def instance(cls, *args, **kwargs): with Singleton._instance_lock: if not hasattr(Singleton, &quot;_instance&quot;): Singleton._instance = Singleton(*args, **kwargs) return Singleton._instancedef task(arg): obj = Singleton.instance() print(obj)for i in range(10): t = threading.Thread(target=task,args=[i,]) t.start()time.sleep(20)obj = Singleton.instance()print(obj) ;) 打印结果如下： ;) 12345678910&lt;__main__.Singleton object at 0x02D6B110&gt;&lt;__main__.Singleton object at 0x02D6B110&gt;&lt;__main__.Singleton object at 0x02D6B110&gt;&lt;__main__.Singleton object at 0x02D6B110&gt;&lt;__main__.Singleton object at 0x02D6B110&gt;&lt;__main__.Singleton object at 0x02D6B110&gt;&lt;__main__.Singleton object at 0x02D6B110&gt;&lt;__main__.Singleton object at 0x02D6B110&gt;&lt;__main__.Singleton object at 0x02D6B110&gt;&lt;__main__.Singleton object at 0x02D6B110&gt; ;) 这样就差不多了，但是还是有一点小问题，就是当程序执行时，执行了time.sleep(20)后，下面实例化对象时，此时已经是单例模式了，但我们还是加了锁，这样不太好，再进行一些优化，把intance方法，改成下面的这样就行： ;) 1234567@classmethoddef instance(cls, *args, **kwargs): if not hasattr(Singleton, &quot;_instance&quot;): with Singleton._instance_lock: if not hasattr(Singleton, &quot;_instance&quot;): Singleton._instance = Singleton(*args, **kwargs) return Singleton._instance ;) 这样，一个可以支持多线程的单例模式就完成了 完整代码 这种方式实现的单例模式，使用时会有限制，以后实例化必须通过 obj = Singleton.instance() 如果用 obj=Singleton() ,这种方式得到的不是单例 4.基于new方法实现（推荐使用，方便）通过上面例子，我们可以知道，当我们实现单例时，为了保证线程安全需要在内部加入锁 我们知道，当我们实例化一个对象时，是先执行了类的new方法（我们没写时，默认调用object.new），实例化对象；然后再执行类的init方法，对这个对象进行初始化，所有我们可以基于这个，实现单例模式 ;) 1234567891011121314151617181920212223242526import threadingclass Singleton(object): _instance_lock = threading.Lock() def __init__(self): pass def __new__(cls, *args, **kwargs): if not hasattr(Singleton, &quot;_instance&quot;): with Singleton._instance_lock: if not hasattr(Singleton, &quot;_instance&quot;): Singleton._instance = object.__new__(cls) return Singleton._instanceobj1 = Singleton()obj2 = Singleton()print(obj1,obj2)def task(arg): obj = Singleton() print(obj)for i in range(10): t = threading.Thread(target=task,args=[i,]) t.start() ;) 打印结果如下： ;) 1234567891011&lt;__main__.Singleton object at 0x038B33D0&gt; &lt;__main__.Singleton object at 0x038B33D0&gt;&lt;__main__.Singleton object at 0x038B33D0&gt;&lt;__main__.Singleton object at 0x038B33D0&gt;&lt;__main__.Singleton object at 0x038B33D0&gt;&lt;__main__.Singleton object at 0x038B33D0&gt;&lt;__main__.Singleton object at 0x038B33D0&gt;&lt;__main__.Singleton object at 0x038B33D0&gt;&lt;__main__.Singleton object at 0x038B33D0&gt;&lt;__main__.Singleton object at 0x038B33D0&gt;&lt;__main__.Singleton object at 0x038B33D0&gt;&lt;__main__.Singleton object at 0x038B33D0&gt; ;) 采用这种方式的单例模式，以后实例化对象时，和平时实例化对象的方法一样 obj = Singleton() 5.基于metaclass方式实现相关知识1234&quot;&quot;&quot;1.类由type创建，创建类时，type的__init__方法自动执行，类() 执行type的 __call__方法(类的__new__方法,类的__init__方法)2.对象由类创建，创建对象时，类的__init__方法自动执行，对象()执行类的 __call__ 方法&quot;&quot;&quot; 例子： ;) 1234567891011class Foo: def __init__(self): pass def __call__(self, *args, **kwargs): passobj = Foo()# 执行type的 __call__ 方法，调用 Foo类（是type的对象）的 __new__方法，用于创建对象，然后调用 Foo类（是type的对象）的 __init__方法，用于对对象初始化。obj() # 执行Foo的 __call__ 方法 ;) 元类的使用 ;) 1234567891011121314151617class SingletonType(type): def __init__(self,*args,**kwargs): super(SingletonType,self).__init__(*args,**kwargs) def __call__(cls, *args, **kwargs): # 这里的cls，即Foo类 print(&apos;cls&apos;,cls) obj = cls.__new__(cls,*args, **kwargs) cls.__init__(obj,*args, **kwargs) # Foo.__init__(obj) return objclass Foo(metaclass=SingletonType): # 指定创建Foo的type为SingletonType def __init__(self，name): self.name = name def __new__(cls, *args, **kwargs): return object.__new__(cls)obj = Foo(&apos;xx&apos;) ;) 实现单例模式;) 12345678910111213141516171819import threadingclass SingletonType(type): _instance_lock = threading.Lock() def __call__(cls, *args, **kwargs): if not hasattr(cls, &quot;_instance&quot;): with SingletonType._instance_lock: if not hasattr(cls, &quot;_instance&quot;): cls._instance = super(SingletonType,cls).__call__(*args, **kwargs) return cls._instanceclass Foo(metaclass=SingletonType): def __init__(self,name): self.name = nameobj1 = Foo(&apos;name&apos;)obj2 = Foo(&apos;name&apos;)print(obj1,obj2)]]></content>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux命令大全]]></title>
    <url>%2F2019%2F02%2F25%2Flinux%E5%91%BD%E4%BB%A4%E5%A4%A7%E5%85%A8%2F</url>
    <content type="text"><![CDATA[Linux常用命令大全最近都在和Linux打交道，这方面基础比较薄弱的我只好买了本鸟哥的书看看，感觉还不错。我觉得Linux相比windows比较麻烦的就是很多东西都要用命令来控制，当然，这也是很多人喜欢linux的原因，比较短小但却功能强大。为了方便大家查找linux的相关命令，我就将我了解到的命令列举一下，仅供大家参考： 系统信息arch 显示机器的处理器架构(1)uname -m 显示机器的处理器架构(2)uname -r 显示正在使用的内核版本dmidecode -q 显示硬件系统部件 - (SMBIOS / DMI)hdparm -i /dev/hda 罗列一个磁盘的架构特性hdparm -tT /dev/sda 在磁盘上执行测试性读取操作cat /proc/cpuinfo 显示CPU info的信息cat /proc/interrupts 显示中断cat /proc/meminfo 校验内存使用cat /proc/swaps 显示哪些swap被使用cat /proc/version 显示内核的版本cat /proc/net/dev 显示网络适配器及统计cat /proc/mounts 显示已加载的文件系统lspci -tv 罗列 PCI 设备lsusb -tv 显示 USB 设备date 显示系统日期cal 2007 显示2007年的日历表date 041217002007.00 设置日期和时间 - 月日时分年.秒clock -w 将时间修改保存到 BIOS 关机 (系统的关机、重启以及登出 )shutdown -h now 关闭系统(1)init 0 关闭系统(2)telinit 0 关闭系统(3)shutdown -h hours:minutes &amp; 按预定时间关闭系统shutdown -c 取消按预定时间关闭系统shutdown -r now 重启(1)reboot 重启(2)logout 注销 文件和目录cd /home 进入 ‘/ home’ 目录’cd .. 返回上一级目录cd ../.. 返回上两级目录cd 进入个人的主目录cd ~user1 进入个人的主目录cd - 返回上次所在的目录pwd 显示工作路径ls 查看目录中的文件ls -F 查看目录中的文件ls -l 显示文件和目录的详细资料ls -a 显示隐藏文件ls [0-9] 显示包含数字的文件名和目录名tree 显示文件和目录由根目录开始的树形结构(1)lstree 显示文件和目录由根目录开始的树形结构(2)mkdir dir1 创建一个叫做 ‘dir1’ 的目录’mkdir dir1 dir2 同时创建两个目录mkdir -p /tmp/dir1/dir2 创建一个目录树rm -f file1 删除一个叫做 ‘file1’ 的文件’rmdir dir1 删除一个叫做 ‘dir1’ 的目录’rm -rf dir1 删除一个叫做 ‘dir1’ 的目录并同时删除其内容rm -rf dir1 dir2 同时删除两个目录及它们的内容mv dir1 new_dir 重命名/移动 一个目录cp file1 file2 复制一个文件cp dir/ . 复制一个目录下的所有文件到当前工作目录cp -a /tmp/dir1 . 复制一个目录到当前工作目录cp -a dir1 dir2 复制一个目录ln -s file1 lnk1 创建一个指向文件或目录的软链接ln file1 lnk1 创建一个指向文件或目录的物理链接touch -t 0712250000 file1 修改一个文件或目录的时间戳 - (YYMMDDhhmm)file file1 outputs the mime type of the file as texticonv -l 列出已知的编码iconv -f fromEncoding -t toEncoding inputFile &gt; outputFile creates a new from the given input file by assuming it is encoded in fromEncoding and converting it to toEncoding.find . -maxdepth 1 -name .jpg -print -exec convert “{}” -resize 80x60 “thumbs/{}” \; batch resize files in the current directory and send them to a thumbnails directory (requires convert from Imagemagick) 文件搜索find / -name file1 从 ‘/‘ 开始进入根文件系统搜索文件和目录find / -user user1 搜索属于用户 ‘user1’ 的文件和目录find /home/user1 -name *.bin 在目录 ‘/ home/user1’ 中搜索带有’.bin’ 结尾的文件find /usr/bin -type f -atime +100 搜索在过去100天内未被使用过的执行文件find /usr/bin -type f -mtime -10 搜索在10天内被创建或者修改过的文件find / -name *.rpm -exec chmod 755 ‘{}’ \; 搜索以 ‘.rpm’ 结尾的文件并定义其权限find / -xdev -name *.rpm 搜索以 ‘.rpm’ 结尾的文件，忽略光驱、捷盘等可移动设备locate *.ps 寻找以 ‘.ps’ 结尾的文件 - 先运行 ‘updatedb’ 命令whereis halt 显示一个二进制文件、源码或man的位置which halt 显示一个二进制文件或可执行文件的完整路径 挂载一个文件系统mount /dev/hda2 /mnt/hda2 挂载一个叫做hda2的盘 - 确定目录 ‘/ mnt/hda2’ 已经存在umount /dev/hda2 卸载一个叫做hda2的盘 - 先从挂载点 ‘/ mnt/hda2’ 退出fuser -km /mnt/hda2 当设备繁忙时强制卸载umount -n /mnt/hda2 运行卸载操作而不写入 /etc/mtab 文件- 当文件为只读或当磁盘写满时非常有用mount /dev/fd0 /mnt/floppy 挂载一个软盘mount /dev/cdrom /mnt/cdrom 挂载一个cdrom或dvdrommount /dev/hdc /mnt/cdrecorder 挂载一个cdrw或dvdrommount /dev/hdb /mnt/cdrecorder 挂载一个cdrw或dvdrommount -o loop file.iso /mnt/cdrom 挂载一个文件或ISO镜像文件mount -t vfat /dev/hda5 /mnt/hda5 挂载一个Windows FAT32文件系统mount /dev/sda1 /mnt/usbdisk 挂载一个usb 捷盘或闪存设备mount -t smbfs -o username=user,password=pass //WinClient/share /mnt/share 挂载一个windows网络共享 磁盘空间df -h 显示已经挂载的分区列表ls -lSr |more 以尺寸大小排列文件和目录du -sh dir1 估算目录 ‘dir1’ 已经使用的磁盘空间’du -sk * | sort -rn 以容量大小为依据依次显示文件和目录的大小rpm -q -a –qf ‘%10{SIZE}t%{NAME}n’ | sort -k1,1n 以大小为依据依次显示已安装的rpm包所使用的空间 (fedora, redhat类系统)dpkg-query -W -f=’${Installed-Size;10}t${Package}n’ | sort -k1,1n 以大小为依据显示已安装的deb包所使用的空间 (ubuntu, debian类系统) 用户和群组groupadd group_name 创建一个新用户组groupdel group_name 删除一个用户组groupmod -n new_group_name old_group_name 重命名一个用户组useradd -c “Name Surname “ -g admin -d /home/user1 -s /bin/bash user1 创建一个属于 “admin” 用户组的用户useradd user1 创建一个新用户userdel -r user1 删除一个用户 ( ‘-r’ 排除主目录)usermod -c “User FTP” -g system -d /ftp/user1 -s /bin/nologin user1 修改用户属性passwd 修改口令passwd user1 修改一个用户的口令 (只允许root执行)chage -E 2005-12-31 user1 设置用户口令的失效期限pwck 检查 ‘/etc/passwd’ 的文件格式和语法修正以及存在的用户grpck 检查 ‘/etc/passwd’ 的文件格式和语法修正以及存在的群组newgrp group_name 登陆进一个新的群组以改变新创建文件的预设群组 文件的权限 - 使用 “+” 设置权限，使用 “-“ 用于取消ls -lh 显示权限ls /tmp | pr -T5 -W$COLUMNS 将终端划分成5栏显示chmod ugo+rwx directory1 设置目录的所有人(u)、群组(g)以及其他人(o)以读（r ）、写(w)和执行(x)的权限chmod go-rwx directory1 删除群组(g)与其他人(o)对目录的读写执行权限chown user1 file1 改变一个文件的所有人属性chown -R user1 directory1 改变一个目录的所有人属性并同时改变改目录下所有文件的属性chgrp group1 file1 改变文件的群组chown user1:group1 file1 改变一个文件的所有人和群组属性find / -perm -u+s 罗列一个系统中所有使用了SUID控制的文件chmod u+s /bin/file1 设置一个二进制文件的 SUID 位 - 运行该文件的用户也被赋予和所有者同样的权限chmod u-s /bin/file1 禁用一个二进制文件的 SUID位chmod g+s /home/public 设置一个目录的SGID 位 - 类似SUID ，不过这是针对目录的chmod g-s /home/public 禁用一个目录的 SGID 位chmod o+t /home/public 设置一个文件的 STIKY 位 - 只允许合法所有人删除文件chmod o-t /home/public 禁用一个目录的 STIKY 位 文件的特殊属性 - 使用 “+” 设置权限，使用 “-“ 用于取消chattr +a file1 只允许以追加方式读写文件chattr +c file1 允许这个文件能被内核自动压缩/解压chattr +d file1 在进行文件系统备份时，dump程序将忽略这个文件chattr +i file1 设置成不可变的文件，不能被删除、修改、重命名或者链接chattr +s file1 允许一个文件被安全地删除chattr +S file1 一旦应用程序对这个文件执行了写操作，使系统立刻把修改的结果写到磁盘chattr +u file1 若文件被删除，系统会允许你在以后恢复这个被删除的文件lsattr 显示特殊的属性 打包和压缩文件bunzip2 file1.bz2 解压一个叫做 ‘file1.bz2’的文件bzip2 file1 压缩一个叫做 ‘file1’ 的文件gunzip file1.gz 解压一个叫做 ‘file1.gz’的文件gzip file1 压缩一个叫做 ‘file1’的文件gzip -9 file1 最大程度压缩rar a file1.rar test_file 创建一个叫做 ‘file1.rar’ 的包rar a file1.rar file1 file2 dir1 同时压缩 ‘file1’, ‘file2’ 以及目录 ‘dir1’rar x file1.rar 解压rar包unrar x file1.rar 解压rar包tar -cvf archive.tar file1 创建一个非压缩的 tarballtar -cvf archive.tar file1 file2 dir1 创建一个包含了 ‘file1’, ‘file2’ 以及 ‘dir1’的档案文件tar -tf archive.tar 显示一个包中的内容tar -xvf archive.tar 释放一个包tar -xvf archive.tar -C /tmp 将压缩包释放到 /tmp目录下tar -cvfj archive.tar.bz2 dir1 创建一个bzip2格式的压缩包tar -xvfj archive.tar.bz2 解压一个bzip2格式的压缩包tar -cvfz archive.tar.gz dir1 创建一个gzip格式的压缩包tar -xvfz archive.tar.gz 解压一个gzip格式的压缩包zip file1.zip file1 创建一个zip格式的压缩包zip -r file1.zip file1 file2 dir1 将几个文件和目录同时压缩成一个zip格式的压缩包unzip file1.zip 解压一个zip格式压缩包 RPM 包 - （Fedora, Redhat及类似系统）rpm -ivh package.rpm 安装一个rpm包rpm -ivh –nodeeps package.rpm 安装一个rpm包而忽略依赖关系警告rpm -U package.rpm 更新一个rpm包但不改变其配置文件rpm -F package.rpm 更新一个确定已经安装的rpm包rpm -e package_name.rpm 删除一个rpm包rpm -qa 显示系统中所有已经安装的rpm包rpm -qa | grep httpd 显示所有名称中包含 “httpd” 字样的rpm包rpm -qi package_name 获取一个已安装包的特殊信息rpm -qg “System Environment/Daemons” 显示一个组件的rpm包rpm -ql package_name 显示一个已经安装的rpm包提供的文件列表rpm -qc package_name 显示一个已经安装的rpm包提供的配置文件列表rpm -q package_name –whatrequires 显示与一个rpm包存在依赖关系的列表rpm -q package_name –whatprovides 显示一个rpm包所占的体积rpm -q package_name –scripts 显示在安装/删除期间所执行的脚本lrpm -q package_name –changelog 显示一个rpm包的修改历史rpm -qf /etc/httpd/conf/httpd.conf 确认所给的文件由哪个rpm包所提供rpm -qp package.rpm -l 显示由一个尚未安装的rpm包提供的文件列表rpm –import /media/cdrom/RPM-GPG-KEY 导入公钥数字证书rpm –checksig package.rpm 确认一个rpm包的完整性rpm -qa gpg-pubkey 确认已安装的所有rpm包的完整性rpm -V package_name 检查文件尺寸、 许可、类型、所有者、群组、MD5检查以及最后修改时间rpm -Va 检查系统中所有已安装的rpm包- 小心使用rpm -Vp package.rpm 确认一个rpm包还未安装rpm2cpio package.rpm | cpio –extract –make-directories bin 从一个rpm包运行可执行文件rpm -ivh /usr/src/redhat/RPMS/arch/package.rpm 从一个rpm源码安装一个构建好的包rpmbuild –rebuild package_name.src.rpm 从一个rpm源码构建一个 rpm 包 YUM 软件包升级器 - （Fedora, RedHat及类似系统）yum install package_name 下载并安装一个rpm包yum localinstall package_name.rpm 将安装一个rpm包，使用你自己的软件仓库为你解决所有依赖关系yum update package_name.rpm 更新当前系统中所有安装的rpm包yum update package_name 更新一个rpm包yum remove package_name 删除一个rpm包yum list 列出当前系统中安装的所有包yum search package_name 在rpm仓库中搜寻软件包yum clean packages 清理rpm缓存删除下载的包yum clean headers 删除所有头文件yum clean all 删除所有缓存的包和头文件 DEB 包 (Debian, Ubuntu 以及类似系统)dpkg -i package.deb 安装/更新一个 deb 包dpkg -r package_name 从系统删除一个 deb 包dpkg -l 显示系统中所有已经安装的 deb 包dpkg -l | grep httpd 显示所有名称中包含 “httpd” 字样的deb包dpkg -s package_name 获得已经安装在系统中一个特殊包的信息dpkg -L package_name 显示系统中已经安装的一个deb包所提供的文件列表dpkg –contents package.deb 显示尚未安装的一个包所提供的文件列表dpkg -S /bin/ping 确认所给的文件由哪个deb包提供 APT 软件工具 (Debian, Ubuntu 以及类似系统)apt-get install package_name 安装/更新一个 deb 包apt-cdrom install package_name 从光盘安装/更新一个 deb 包apt-get update 升级列表中的软件包apt-get upgrade 升级所有已安装的软件apt-get remove package_name 从系统删除一个deb包apt-get check 确认依赖的软件仓库正确apt-get clean 从下载的软件包中清理缓存apt-cache search searched-package 返回包含所要搜索字符串的软件包名称 查看文件内容cat file1 从第一个字节开始正向查看文件的内容tac file1 从最后一行开始反向查看一个文件的内容more file1 查看一个长文件的内容less file1 类似于 ‘more’ 命令，但是它允许在文件中和正向操作一样的反向操作head -2 file1 查看一个文件的前两行tail -2 file1 查看一个文件的最后两行tail -f /var/log/messages 实时查看被添加到一个文件中的内容 文本处理cat file1 file2 … | command &lt;&gt; file1_in.txt_or_file1_out.txt general syntax for text manipulation using PIPE, STDIN and STDOUTcat file1 | command( sed, grep, awk, grep, etc…) &gt; result.txt 合并一个文件的详细说明文本，并将简介写入一个新文件中cat file1 | command( sed, grep, awk, grep, etc…) &gt;&gt; result.txt 合并一个文件的详细说明文本，并将简介写入一个已有的文件中grep Aug /var/log/messages 在文件 ‘/var/log/messages’中查找关键词”Aug”grep ^Aug /var/log/messages 在文件 ‘/var/log/messages’中查找以”Aug”开始的词汇grep [0-9] /var/log/messages 选择 ‘/var/log/messages’ 文件中所有包含数字的行grep Aug -R /var/log/ 在目录 ‘/var/log’ 及随后的目录中搜索字符串”Aug”sed ‘s/stringa1/stringa2/g’ example.txt 将example.txt文件中的 “string1” 替换成 “string2”sed ‘/^$/d’ example.txt 从example.txt文件中删除所有空白行sed ‘/ #/d; /^$/d’ example.txt 从example.txt文件中删除所有注释和空白行echo ‘esempio’ | tr ‘[:lower:]’ ‘[:upper:]’ 合并上下单元格内容sed -e ‘1d’ result.txt 从文件example.txt 中排除第一行sed -n ‘/stringa1/p’ 查看只包含词汇 “string1”的行sed -e ‘s/ $//‘ example.txt 删除每一行最后的空白字符sed -e ‘s/stringa1//g’ example.txt 从文档中只删除词汇 “string1” 并保留剩余全部sed -n ‘1,5p;5q’ example.txt 查看从第一行到第5行内容sed -n ‘5p;5q’ example.txt 查看第5行sed -e ‘s/00/0/g’ example.txt 用单个零替换多个零cat -n file1 标示文件的行数cat example.txt | awk ‘NR%2==1’ 删除example.txt文件中的所有偶数行echo a b c | awk ‘{print $1}’ 查看一行第一栏echo a b c | awk ‘{print $1,$3}’ 查看一行的第一和第三栏paste file1 file2 合并两个文件或两栏的内容paste -d ‘+’ file1 file2 合并两个文件或两栏的内容，中间用”+”区分sort file1 file2 排序两个文件的内容sort file1 file2 | uniq 取出两个文件的并集(重复的行只保留一份)sort file1 file2 | uniq -u 删除交集，留下其他的行sort file1 file2 | uniq -d 取出两个文件的交集(只留下同时存在于两个文件中的文件)comm -1 file1 file2 比较两个文件的内容只删除 ‘file1’ 所包含的内容comm -2 file1 file2 比较两个文件的内容只删除 ‘file2’ 所包含的内容comm -3 file1 file2 比较两个文件的内容只删除两个文件共有的部分 字符设置和文件格式转换dos2unix filedos.txt fileunix.txt 将一个文本文件的格式从MSDOS转换成UNIXunix2dos fileunix.txt filedos.txt 将一个文本文件的格式从UNIX转换成MSDOSrecode ..HTML &lt; page.txt &gt; page.html 将一个文本文件转换成htmlrecode -l | more 显示所有允许的转换格式 文件系统分析badblocks -v /dev/hda1 检查磁盘hda1上的坏磁块fsck /dev/hda1 修复/检查hda1磁盘上linux文件系统的完整性fsck.ext2 /dev/hda1 修复/检查hda1磁盘上ext2文件系统的完整性e2fsck /dev/hda1 修复/检查hda1磁盘上ext2文件系统的完整性e2fsck -j /dev/hda1 修复/检查hda1磁盘上ext3文件系统的完整性fsck.ext3 /dev/hda1 修复/检查hda1磁盘上ext3文件系统的完整性fsck.vfat /dev/hda1 修复/检查hda1磁盘上fat文件系统的完整性fsck.msdos /dev/hda1 修复/检查hda1磁盘上dos文件系统的完整性dosfsck /dev/hda1 修复/检查hda1磁盘上dos文件系统的完整性 初始化一个文件系统mkfs /dev/hda1 在hda1分区创建一个文件系统mke2fs /dev/hda1 在hda1分区创建一个linux ext2的文件系统mke2fs -j /dev/hda1 在hda1分区创建一个linux ext3(日志型)的文件系统mkfs -t vfat 32 -F /dev/hda1 创建一个 FAT32 文件系统fdformat -n /dev/fd0 格式化一个软盘mkswap /dev/hda3 创建一个swap文件系统 SWAP文件系统mkswap /dev/hda3 创建一个swap文件系统swapon /dev/hda3 启用一个新的swap文件系统swapon /dev/hda2 /dev/hdb3 启用两个swap分区 备份dump -0aj -f /tmp/home0.bak /home 制作一个 ‘/home’ 目录的完整备份dump -1aj -f /tmp/home0.bak /home 制作一个 ‘/home’ 目录的交互式备份restore -if /tmp/home0.bak 还原一个交互式备份rsync -rogpav –delete /home /tmp 同步两边的目录rsync -rogpav -e ssh –delete /home ip_address:/tmp 通过SSH通道rsyncrsync -az -e ssh –delete ip_addr:/home/public /home/local 通过ssh和压缩将一个远程目录同步到本地目录rsync -az -e ssh –delete /home/local ip_addr:/home/public 通过ssh和压缩将本地目录同步到远程目录dd bs=1M if=/dev/hda | gzip | ssh user@ip_addr ‘dd of=hda.gz’ 通过ssh在远程主机上执行一次备份本地磁盘的操作dd if=/dev/sda of=/tmp/file1 备份磁盘内容到一个文件tar -Puf backup.tar /home/user 执行一次对 ‘/home/user’ 目录的交互式备份操作( cd /tmp/local/ &amp;&amp; tar c . ) | ssh -C user@ip_addr ‘cd /home/share/ &amp;&amp; tar x -p’ 通过ssh在远程目录中复制一个目录内容( tar c /home ) | ssh -C user@ip_addr ‘cd /home/backup-home &amp;&amp; tar x -p’ 通过ssh在远程目录中复制一个本地目录tar cf - . | (cd /tmp/backup ; tar xf - ) 本地将一个目录复制到另一个地方，保留原有权限及链接find /home/user1 -name ‘.txt’ | xargs cp -av –target-directory=/home/backup/ –parents 从一个目录查找并复制所有以 ‘.txt’ 结尾的文件到另一个目录find /var/log -name ‘.log’ | tar cv –files-from=- | bzip2 &gt; log.tar.bz2 查找所有以 ‘.log’ 结尾的文件并做成一个bzip包dd if=/dev/hda of=/dev/fd0 bs=512 count=1 做一个将 MBR (Master Boot Record)内容复制到软盘的动作dd if=/dev/fd0 of=/dev/hda bs=512 count=1 从已经保存到软盘的备份中恢复MBR内容 光盘cdrecord -v gracetime=2 dev=/dev/cdrom -eject blank=fast -force 清空一个可复写的光盘内容mkisofs /dev/cdrom &gt; cd.iso 在磁盘上创建一个光盘的iso镜像文件mkisofs /dev/cdrom | gzip &gt; cd_iso.gz 在磁盘上创建一个压缩了的光盘iso镜像文件mkisofs -J -allow-leading-dots -R -V “Label CD” -iso-level 4 -o ./cd.iso data_cd 创建一个目录的iso镜像文件cdrecord -v dev=/dev/cdrom cd.iso 刻录一个ISO镜像文件gzip -dc cd_iso.gz | cdrecord dev=/dev/cdrom - 刻录一个压缩了的ISO镜像文件mount -o loop cd.iso /mnt/iso 挂载一个ISO镜像文件cd-paranoia -B 从一个CD光盘转录音轨到 wav 文件中cd-paranoia – “-3” 从一个CD光盘转录音轨到 wav 文件中（参数-3）cdrecord –scanbus 扫描总线以识别scsi通道dd if=/dev/hdc | md5sum 校验一个设备的md5sum编码，例如一张 CD 网络 - （以太网和WIFI无线）ifconfig eth0 显示一个以太网卡的配置ifup eth0 启用一个 ‘eth0’ 网络设备ifdown eth0 禁用一个 ‘eth0’ 网络设备ifconfig eth0 192.168.1.1 netmask 255.255.255.0 控制IP地址ifconfig eth0 promisc 设置 ‘eth0’ 成混杂模式以嗅探数据包 (sniffing)dhclient eth0 以dhcp模式启用 ‘eth0’route -n show routing tableroute add -net 0/0 gw IP_Gateway configura default gatewayroute add -net 192.168.0.0 netmask 255.255.0.0 gw 192.168.1.1 configure static route to reach network ‘192.168.0.0/16’route del 0/0 gw IP_gateway remove static routeecho “1” &gt; /proc/sys/net/ipv4/ip_forward activate ip routinghostname show hostname of systemhost www.example.com lookup hostname to resolve name to ip address and viceversa(1)nslookup www.example.com lookup hostname to resolve name to ip address and viceversa(2)ip link show show link status of all interfacesmii-tool eth0 show link status of ‘eth0’ethtool eth0 show statistics of network card ‘eth0’netstat -tup show all active network connections and their PIDnetstat -tupl show all network services listening on the system and their PIDtcpdump tcp port 80 show all HTTP trafficiwlist scan show wireless networksiwconfig eth1 show configuration of a wireless network cardhostname show hostnamehost www.example.com lookup hostname to resolve name to ip address and viceversanslookup www.example.com lookup hostname to resolve name to ip address and viceversawhois www.example.com lookup on Whois database GO TOP INDEX ^Microsoft Windows networks (SAMBA)nbtscan ip_addr netbios name resolutionnmblookup -A ip_addr netbios name resolutionsmbclient -L ip_addr/hostname show remote shares of a windows hostsmbget -Rr smb://ip_addr/share like wget can download files from a host windows via smbmount -t smbfs -o username=user,password=pass //WinClient/share /mnt/share mount a windows network share 参考：http://www.cnblogs.com/fnlingnzb-learner/p/5831284.html]]></content>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据库redis命令大全]]></title>
    <url>%2F2019%2F02%2F23%2F%E6%95%B0%E6%8D%AE%E5%BA%93redis%E5%91%BD%E4%BB%A4%E5%A4%A7%E5%85%A8%2F</url>
    <content type="text"><![CDATA[数据库 【redis】 命令大全以下纯属搬砖，我用Python抓取的redis命令列表页内容 如果想看命令的具体使用可查去官网查看，以下整理为个人查找方便而已 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189地理位置GEOADD 将指定的地理空间位置（纬度、经度、名称）添加到指定的key中GEODIST 返回两个给定位置之间的距离GEOHASH 返回一个或多个位置元素的 Geohash 表示GEOPOS 从key里返回所有给定位置元素的位置（经度和纬度）GEORADIUS 以给定的经纬度为中心， 找出某一半径内的元素GEORADIUSBYMEMBER 找出位于指定范围内的元素，中心点是由给定的位置元素决定keyDEL 该用于在 key 存在是删除 key。Dump 序列化给定 key ，并返回被序列化的值。EXISTS 检查给定 key 是否存在。Expire seconds为给定 key 设置过期时间。Expireat EXPIREAT 的作用和 EXPIRE 类似，都用于为 key 设置过期时间。 不同在于 EXPIREAT 接受的时间参数是 UNIX 时间戳(unix timestamp)。PEXPIREAT 设置 key 的过期时间亿以毫秒计。PEXPIREAT 设置 key 过期时间的时间戳(unix timestamp) 以毫秒计Keys 查找所有符合给定模式( pattern)的 key 。Move 将当前数据库的 key 移动到给定的数据库 db 当中。PERSIST 移除 key 的过期时间，key 将持久保持。Pttl 以毫秒为单位返回 key 的剩余的过期时间。TTL 以秒为单位，返回给定 key 的剩余生存时间(TTL, time to live)。RANDOMKEY 从当前数据库中随机返回一个 key 。Rename 修改 key 的名称Renamenx 仅当 newkey 不存在时，将 key 改名为 newkey 。Type 返回 key 所储存的值的类型。String SET 设置指定 key 的值Get 获取指定 key 的值。Getrange 返回 key 中字符串值的子字符Getset 将给定 key 的值设为 value ，并返回 key 的旧值(old value)。Getbit 对 key 所储存的字符串值，获取指定偏移量上的位(bit)。Mget 获取所有(一个或多个)给定 key 的值。Setbit 对 key 所储存的字符串值，设置或清除指定偏移量上的位(bit)。Setex 将值 value 关联到 key ，并将 key 的过期时间设为 seconds (以秒为单位)。Setnx 只有在 key 不存在时设置 key 的值。Setrange 用 value 参数覆写给定 key 所储存的字符串值，从偏移量 offset 开始。Strlen 返回 key 所储存的字符串值的长度。Mset 同时设置一个或多个 key-value 对。Msetnx 同时设置一个或多个 key-value 对，当且仅当所有给定 key 都不存在。Psetex 这个和 SETEX 相似，但它以毫秒为单位设置 key 的生存时间，而不是像 SETEX 那样，以秒为单位。Incr 将 key 中储存的数字值增一。Incrby 将 key 所储存的值加上给定的增量值（increment） 。Incrbyfloat 将 key 所储存的值加上给定的浮点增量值（increment） 。Decr 将 key 中储存的数字值减一。Decrby key 所储存的值减去给定的减量值（decrement） 。Append 如果 key 已经存在并且是一个字符串， APPEND 将 value 追加到 key 原来的值的末尾。HashHdel 删除一个或多个哈希表字段Hexists 查看哈希表 key 中，指定的字段是否存在。Hget 获取存储在哈希表中指定字段的值/td&gt;Hgetall 获取在哈希表中指定 key 的所有字段和值Hincrby 为哈希表 key 中的指定字段的整数值加上增量 increment 。Hincrbyfloat 为哈希表 key 中的指定字段的浮点数值加上增量 increment 。Hkeys 获取所有哈希表中的字段Hlen 获取哈希表中字段的数量Hmget 获取所有给定字段的值Hmset 同时将多个 field-value (域-值)对设置到哈希表 key 中。Hset 将哈希表 key 中的字段 field 的值设为 value 。Hsetnx 只有在字段 field 不存在时，设置哈希表字段的值。Hvals 获取哈希表中所有值ListBlpop 移出并获取列表的第一个元素， 如果列表没有元素会阻塞列表直到等待超时或发现可弹出元素为止。Brpop 移出并获取列表的最后一个元素， 如果列表没有元素会阻塞列表直到等待超时或发现可弹出元素为止。Brpoplpush 从列表中弹出一个值，将弹出的元素插入到另外一个列表中并返回它； 如果列表没有元素会阻塞列表直到等待超时或发现可弹出元素为止。Lindex 通过索引获取列表中的元素Linsert 在列表的元素前或者后插入元素Llen 获取列表长度Lpop 移出并获取列表的第一个元素Lpush 将一个或多个值插入到列表头部Lpushx 将一个或多个值插入到已存在的列表头部Lrange 获取列表指定范围内的元素Lrem 移除列表元素Lset 通过索引设置列表元素的值Ltrim 对一个列表进行修剪(trim)，就是说，让列表只保留指定区间内的元素，不在指定区间之内的元素都将被删除。Rpop 移除并获取列表最后一个元素Rpoplpush 移除列表的最后一个元素，并将该元素添加到另一个列表并返回Rpush 在列表中添加一个或多个值Rpushx 为已存在的列表添加值Set 命令Sadd 向集合添加一个或多个成员Scard 获取集合的成员数Sdiff 返回给定所有集合的差集Sdiffstore 返回给定所有集合的差集并存储在 destination 中Sinter 返回给定所有集合的交集Sinterstore 返回给定所有集合的交集并存储在 destination 中Sismember 判断 member 元素是否是集合 key 的成员Smembers 返回集合中的所有成员Smove 将 member 元素从 source 集合移动到 destination 集合Spop 移除并返回集合中的一个随机元素Srandmember 返回集合中一个或多个随机数Srem 移除集合中一个或多个成员Sunion 返回所有给定集合的并集Sunionstore 所有给定集合的并集存储在 destination 集合中Sscan 迭代集合中的元素sorted set有序集合Zadd 向有序集合添加一个或多个成员，或者更新已存在成员的分数Zcard 获取有序集合的成员数Zcount 计算在有序集合中指定区间分数的成员数Zincrby 有序集合中对指定成员的分数加上增量 incrementZinterstore 计算给定的一个或多个有序集的交集并将结果集存储在新的有序集合 key 中Zlexcount 在有序集合中计算指定字典区间内成员数量Zrange 通过索引区间返回有序集合成指定区间内的成员Zrangebylex 通过字典区间返回有序集合的成员Zrangebyscore 通过分数返回有序集合指定区间内的成员Zrank 返回有序集合中指定成员的索引Zrem 移除有序集合中的一个或多个成员Zremrangebylex 移除有序集合中给定的字典区间的所有成员Zremrangebyrank 移除有序集合中给定的排名区间的所有成员Zremrangebyscore 移除有序集合中给定的分数区间的所有成员Zrevrange 返回有序集中指定区间内的成员，通过索引，分数从高到底Zrevrangebyscore 返回有序集中指定分数区间内的成员，分数从高到低排序Zrevrank 返回有序集合中指定成员的排名，有序集成员按分数值递减(从大到小)排序Zscore 返回有序集中，成员的分数值Zunionstore 计算给定的一个或多个有序集的并集，并存储在新的 key 中Zscan 迭代有序集合中的元素（包括元素成员和元素分值）Redis HyperLogLog 命令Pfadd 添加指定元素到 HyperLogLog 中。Pfcount 返回给定 HyperLogLog 的基数估算值。Pgmerge 将多个 HyperLogLog 合并为一个 HyperLogLogRedis 发布订阅 命令Psubscribe 订阅一个或多个符合给定模式的频道。Pubsub 查看订阅与发布系统状态。Publish 将信息发送到指定的频道。Punsubscribe 退订所有给定模式的频道。Subscribe 订阅给定的一个或多个频道的信息。Unsubscribe 指退订给定的频道。Redis 事务 命令Discard 取消事务，放弃执行事务块内的所有。Exec 执行所有事务块内的。Multi 标记一个事务块的开始。Unwatch 取消 WATCH 对所有 key 的监视。Watch 监视一个(或多个) key ，如果在事务执行之前这个(或这些) key 被其他所改动，那么事务将被打断。Redis 脚本 命令Eval 执行 Lua 脚本。Evalsha 执行 Lua 脚本。Script Exists 查看指定的脚本是否已经被保存在缓存当中。Script Flush 从脚本缓存中移除所有脚本。Script kill 杀死当前正在运行的 Lua 脚本。Script Load 将脚本 script 添加到脚本缓存中，但并不立即执行这个脚本。Redis 连接 命令Auth 验证密码是否正确Echo 打印字符串Ping 查看服务是否运行Quit 关闭当前连接Select 切换到指定的数据库Redis 服务器 命令Bgrewriteaof 异步执行一个 AOF（AppendOnly File） 文件重写操作Bgsave 在后台异步保存当前数据库的数据到磁盘Client Kill 关闭客户端连接Client List 获取连接到服务器的客户端连接列表Client Getname 获取连接的名称Client Pause 在指定时间内终止运行来自客户端的Client Setname 设置当前连接的名称Cluster Slots 获取集群节点的映射数组Command 获取 详情数组Command Count 获取 总数Command Getkeys 获取给定的所有键Time 返回当前服务器时间Command Info 获取指定 描述的数组Config Get 获取指定配置参数的值Config rewrite 对启动 服务器时所指定的 redis.conf 配置文件进行改写Config Set 修改 redis 配置参数，无需重启Config Resetstat 重置 INFO 中的某些统计数据Dbsize 返回当前数据库的 key 的数量Debug Object 获取 key 的调试信息Debug Segfault 让 服务崩溃Flushall 删除所有数据库的所有keyFlushdb 删除当前数据库的所有keyInfo 获取 服务器的各种信息和统计数值Lastsave 返回最近一次 成功将数据保存到磁盘上的时间，以 UNIX 时间戳格式表示Monitor 实时打印出 服务器接收到的，调试用Role 返回主从实例所属的角色Save 异步保存数据到硬盘Shutdown 异步保存数据到硬盘，并关闭服务器Slaveof 将当前服务器转变为指定服务器的从属服务器(slave server)Showlog 管理 redis 的慢日志Sync 用于复制功能(replication)的内部]]></content>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python面试题总结]]></title>
    <url>%2F2019%2F02%2F23%2Fpython%E9%9D%A2%E8%AF%95%E9%A2%98%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[用python删除一个文件12345678import osmy_file = &apos;D:/text.txt&apos; # 文件路径if os.path.exists(my_file): # 如果文件存在 #删除文件，可使用以下两种方法。 os.remove(my_file) # 则删除 #os.unlink(my_file)else: print(&apos;no such file:%s&apos;%my_file) Python中is和==的区别Python中有很多运算符，今天我们就来讲讲is和==两种运算符在应用上的本质区别是什么。 在讲is和==这两种运算符区别之前，首先要知道Python中对象包含的三个基本要素，分别是：id(身份标识)、type(数据类型)和value(值)。 is和==都是对对象进行比较判断作用的，但对对象比较判断的内容并不相同。下面来看看具体区别在哪。 ==比较操作符和is同一性运算符区别 ==是python标准操作符中的比较操作符，用来比较判断两个对象的value(值)是否相等，例如下面两个字符串间的比较： 例1. 1234&gt;&gt;&gt; a = &apos;cheesezh&apos;&gt;&gt;&gt; b = &apos;cheesezh&apos;&gt;&gt;&gt; a == bTrue is也被叫做同一性运算符，这个运算符比较判断的是对象间的唯一身份标识，也就是id是否相同。通过对下面几个list间的比较，你就会明白is同一性运算符的工作原理： 例2. ;) 1234567891011121314151617&gt;&gt;&gt; x = y = [4,5,6]&gt;&gt;&gt; z = [4,5,6]&gt;&gt;&gt; x == yTrue&gt;&gt;&gt; x == zTrue&gt;&gt;&gt; x is yTrue&gt;&gt;&gt; x is zFalse&gt;&gt;&gt;&gt;&gt;&gt; print id(x)3075326572&gt;&gt;&gt; print id(y)3075326572&gt;&gt;&gt; print id(z)3075328140 ;) 前三个例子都是True，这什么最后一个是False呢？x、y和z的值是相同的，所以前两个是True没有问题。至于最后一个为什么是False，看看三个对象的id分别是什么就会明白了。 下面再来看一个例子，例3中同一类型下的a和b的（a==b）都是为True，而（a is b）则不然。 例3. ;) 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748&gt;&gt;&gt; a = 1 #a和b为数值类型&gt;&gt;&gt; b = 1&gt;&gt;&gt; a is bTrue&gt;&gt;&gt; id(a)14318944&gt;&gt;&gt; id(b)14318944&gt;&gt;&gt; a = &apos;cheesezh&apos; #a和b为字符串类型&gt;&gt;&gt; b = &apos;cheesezh&apos;&gt;&gt;&gt; a is bTrue&gt;&gt;&gt; id(a)42111872&gt;&gt;&gt; id(b)42111872&gt;&gt;&gt; a = (1,2,3) #a和b为元组类型&gt;&gt;&gt; b = (1,2,3)&gt;&gt;&gt; a is bFalse&gt;&gt;&gt; id(a)15001280&gt;&gt;&gt; id(b)14790408&gt;&gt;&gt; a = [1,2,3] #a和b为list类型&gt;&gt;&gt; b = [1,2,3]&gt;&gt;&gt; a is bFalse&gt;&gt;&gt; id(a)42091624&gt;&gt;&gt; id(b)42082016&gt;&gt;&gt; a = &#123;&apos;cheese&apos;:1,&apos;zh&apos;:2&#125; #a和b为dict类型&gt;&gt;&gt; b = &#123;&apos;cheese&apos;:1,&apos;zh&apos;:2&#125;&gt;&gt;&gt; a is bFalse&gt;&gt;&gt; id(a)42101616&gt;&gt;&gt; id(b)42098736&gt;&gt;&gt; a = set([1,2,3])#a和b为set类型&gt;&gt;&gt; b = set([1,2,3])&gt;&gt;&gt; a is bFalse&gt;&gt;&gt; id(a)14819976&gt;&gt;&gt; id(b)14822256 ;) 通过例3可看出，只有数值型和字符串型的情况下，a is b才为True，当a和b是tuple，list，dict或set型时，a is b为False。 参考资料：http://www.iplaypython.com/jinjie/is.html 序号 方法 描述 1 GET 请求指定的页面信息，并返回实体主体。 2 HEAD 类似于get请求，只不过返回的响应中没有具体的内容，用于获取报头 3 POST 向指定资源提交数据进行处理请求（例如提交表单或者上传文件）。数据被包含在请求体中。POST请求可能会导致新的资源的建立和/或已有资源的修改。 4 PUT 从客户端向服务器传送的数据取代指定的文档的内容。 5 DELETE 请求服务器删除指定的页面。 6 CONNECT HTTP/1.1协议中预留给能够将连接改为管道方式的代理服务器。 7 OPTIONS 允许客户端查看服务器的性能。 8 TRACE 回显服务器收到的请求，主要用于测试或诊断。 HTTP/1.1中定义五种响应代码： 1xx：指示信息–表示请求已接收，继续处理 2xx：成功–表示请求已被成功接收、理解、接受 3xx：重定向–要完成请求必须进行更进一步的操作 4xx：客户端错误–请求有语法错误或请求无法实现 5xx：服务器端错误–服务器未能实现合法的请求 几种常用的操作系统调度策略一、先来先服务和短作业(进程)优先调度算法1．先来先服务调度算法2．短作业(进程)优先调度算法二、高优先权优先调度算法1．优先权调度算法的类型2．高响应比优先调度算法三、基于时间片的轮转调度算法1．时间片轮转法2．多级反馈队列调度算法死锁的四个必要条件和解决办法死锁概念及产生原理​ 概念：多个并发进程因争夺系统资源而产生相互等待的现象。​ 原理：当一组进程中的每个进程都在等待某个事件发生，而只有这组进程中的其他进程才能触发该事件，这就称这组进程发生了死锁。​ 本质原因：​ 1）、系统资源有限。​ 2）、进程推进顺序不合理。 死锁产生的4个必要条件​ 1、互斥：某种资源一次只允许一个进程访问，即该资源一旦分配给某个进程，其他进程就不能再访问，直到该进程访问结束。​ 2、占有且等待：一个进程本身占有资源（一种或多种），同时还有资源未得到满足，正在等待其他进程释放该资源。​ 3、不可抢占：别人已经占有了某项资源，你不能因为自己也需要该资源，就去把别人的资源抢过来。​ 4、循环等待：存在一个进程链，使得每个进程都占有下一个进程所需的至少一种资源。​ 当以上四个条件均满足，必然会造成死锁，发生死锁的进程无法进行下去，它们所持有的资源也无法释放。这样会导致CPU的吞吐量下降。所以死锁情况是会浪费系统资源和影响计算机的使用性能的。那么，解决死锁问题就是相当有必要的了。 避免死锁的方法1、死锁预防 —– 确保系统永远不会进入死锁状态​ 产生死锁需要四个条件，那么，只要这四个条件中至少有一个条件得不到满足，就不可能发生死锁了。由于互斥条件是非共享资源所必须的，不仅不能改变，还应加以保证，所以，主要是破坏产生死锁的其他三个条件。a、破坏“占有且等待”条件​ 方法1：所有的进程在开始运行之前，必须一次性地申请其在整个运行过程中所需要的全部资源。​ 优点：简单易实施且安全。​ 缺点：因为某项资源不满足，进程无法启动，而其他已经满足了的资源也不会得到利用，严重降低了资源的利用率，造成资源浪费。​ 使进程经常发生饥饿现象。​ 方法2：该方法是对第一种方法的改进，允许进程只获得运行初期需要的资源，便开始运行，在运行过程中逐步释放掉分配到的已经使用完毕的资源，然后再去请求新的资源。这样的话，资源的利用率会得到提高，也会减少进程的饥饿问题。b、破坏“不可抢占”条件​ 当一个已经持有了一些资源的进程在提出新的资源请求没有得到满足时，它必须释放已经保持的所有资源，待以后需要使用的时候再重新申请。这就意味着进程已占有的资源会被短暂地释放或者说是被抢占了。​ 该种方法实现起来比较复杂，且代价也比较大。释放已经保持的资源很有可能会导致进程之前的工作实效等，反复的申请和释放资源会导致进程的执行被无限的推迟，这不仅会延长进程的周转周期，还会影响系统的吞吐量。c、破坏“循环等待”条件​ 可以通过定义资源类型的线性顺序来预防，可将每个资源编号，当一个进程占有编号为i的资源时，那么它下一次申请资源只能申请编号大于i的资源。如图所示： 这样虽然避免了循环等待，但是这种方法是比较低效的，资源的执行速度回变慢，并且可能在没有必要的情况下拒绝资源的访问，比如说，进程c想要申请资源1，如果资源1并没有被其他进程占有，此时将它分配个进程c是没有问题的，但是为了避免产生循环等待，该申请会被拒绝，这样就降低了资源的利用率2、避免死锁 —– 在使用前进行判断，只允许不会产生死锁的进程申请资源的死锁避免是利用额外的检验信息，在分配资源时判断是否会出现死锁，只在不会出现死锁的情况下才分配资源。两种避免办法：​ 1、如果一个进程的请求会导致死锁，则不启动该进程​ 2、如果一个进程的增加资源请求会导致死锁 ，则拒绝该申请。避免死锁的具体实现通常利用银行家算法​ 银行家算法a、银行家算法的相关数据结构​ 可利用资源向量Available：用于表示系统里边各种资源剩余的数目。由于系统里边拥有的资源通常都是有很多种（假设有m种），所以，我们用一个有m个元素的数组来表示各种资源。数组元素的初始值为系统里边所配置的该类全部可用资源的数目，其数值随着该类资源的分配与回收动态地改变。​ 最大需求矩阵Max：用于表示各个进程对各种资源的额最大需求量。进程可能会有很多个（假设为n个），那么，我们就可以用一个nxm的矩阵来表示各个进程多各种资源的最大需求量​ 分配矩阵Allocation：顾名思义，就是用于表示已经分配给各个进程的各种资源的数目。也是一个nxm的矩阵。​ 需求矩阵Need：用于表示进程仍然需要的资源数目，用一个nxm的矩阵表示。系统可能没法一下就满足了某个进程的最大需求（通常进程对资源的最大需求也是只它在整个运行周期中需要的资源数目，并不是每一个时刻都需要这么多），于是，为了进程的执行能够向前推进，通常，系统会先分配个进程一部分资源保证进程能够执行起来。那么，进程的最大需求减去已经分配给进程的数目，就得到了进程仍然需要的资源数目了。 银行家算法通过对进程需求、占有和系统拥有资源的实时统计，确保系统在分配给进程资源不会造成死锁才会给与分配。死锁避免的优点：不需要死锁预防中的抢占和重新运行进程，并且比死锁预防的限制要少。死锁避免的限制：​ 必须事先声明每个进程请求的最大资源量​ 考虑的进程必须无关的，也就是说，它们执行的顺序必须没有任何同步要求的限制​ 分配的资源数目必须是固定的。​ 在占有资源时，进程不能退出3、死锁检测与解除 —– 在检测到运行系统进入死锁，进行恢复。​ 允许系统进入到死锁状态​ 死锁检测下图截自《操作系统–精髓与设计原理》 死锁的解除 如果利用死锁检测算法检测出系统已经出现了死锁 ，那么，此时就需要对系统采取相应的措施。常用的解除死锁的方法：1、抢占资源：从一个或多个进程中抢占足够数量的资源分配给死锁进程，以解除死锁状态。2、终止（或撤销）进程：终止或撤销系统中的一个或多个死锁进程，直至打破死锁状态。​ a、终止所有的死锁进程。这种方式简单粗暴，但是代价很大，很有可能会导致一些已经运行了很久的进程前功尽弃。​ b、逐个终止进程，直至死锁状态解除。该方法的代价也很大，因为每终止一个进程就需要使用死锁检测来检测系统当前是否处于死锁状态。另外，每次终止进程的时候终止那个进程呢？每次都应该采用最优策略来选择一个“代价最小”的进程来解除死锁状态。一般根据如下几个方面来决定终止哪个进程：​ 进程的优先级​ 进程已运行时间以及运行完成还需要的时间​ 进程已占用系统资源​ 进程运行完成还需要的资源​ 终止进程数目 进程是交互还是批处理 原文：https://blog.csdn.net/guaiguaihenguai/article/details/80303835]]></content>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[常用经典SQL语句大全完整版--详解+实例]]></title>
    <url>%2F2019%2F02%2F23%2F%E5%B8%B8%E7%94%A8%E7%BB%8F%E5%85%B8SQL%E8%AF%AD%E5%8F%A5%E5%A4%A7%E5%85%A8%E5%AE%8C%E6%95%B4%E7%89%88-%E8%AF%A6%E8%A7%A3-%E5%AE%9E%E4%BE%8B%2F</url>
    <content type="text"><![CDATA[下列语句部分是Mssql语句，不可以在access中使用。 SQL分类： DDL—数据定义语言(CREATE，ALTER，DROP，DECLARE) DML—数据操纵语言(SELECT，DELETE，UPDATE，INSERT) DCL—数据控制语言(GRANT，REVOKE，COMMIT，ROLLBACK) 首先,简要介绍基础语句： 1、说明：创建数据库CREATE DATABASE database-name 2、说明：删除数据库drop database dbname 3、说明：备份sql server — 创建 备份数据的 deviceUSE masterEXEC sp_addumpdevice ’disk’, ’testBack’, ’c:\mssql7backup\MyNwind_1.dat’ — 开始 备份BACKUP DATABASE pubs TO testBack 4、说明：创建新表create table tabname(col1 type1 [not null][primary key],col2 type2 [not null],..) 根据已有的表创建新表：A：create table tab_new like tab_old (使用旧表创建新表)B：create table tab_new as select col1,col2… from tab_old definition only 5、说明： 删除新表：drop table tabname 6、说明： 增加一个列：Alter table tabname add column col type 注：列增加后将不能删除。DB2中列加上后数据类型也不能改变，唯一能改变的是增加varchar类型的长度。 7、说明： 添加主键：Alter table tabname add primary key(col) 说明： 删除主键：Alter table tabname drop primary key(col) 8、说明： 创建索引：create [unique] index idxname on tabname(col….) 删除索引：drop index idxname 注：索引是不可更改的，想更改必须删除重新建。 123456789101112131415161718192021222324CREATE INDEX index_name ON table_name(column_name,column_name) include(score)普通索引CREATE UNIQUE INDEX index_name ON table_name (column_name) ;非空索引CREATE PRIMARY KEY INDEX index_name ON table_name (column_name) ;主键索引 使用ALTER TABLE语句创建索引alter table table_name add index index_name (column_list) ;alter table table_name add unique (column_list) ;alter table table_name add primary key (column_list) ;删除索引drop index index_name on table_name ;alter table table_name drop index index_name ;alter table table_name drop primary key ; 9、说明： 创建视图：create view viewname as select statement 删除视图：drop view viewname10、说明：几个简单的基本的sql语句 选择：select from table1 where 范围 插入：insert into table1(field1,field2) values(value1,value2) 删除：delete from table1 where 范围 更新：update table1 set field1=value1 where 范围 查找：select from table1 where field1 like ’%value1%’ —like的语法很精妙，查资料! 排序：select from table1 order by field1,field2 [desc] 总数：select count as totalcount from table1 求和：select sum(field1) as sumvalue from table1 平均：select avg(field1) as avgvalue from table1 最大：select max(field1) as maxvalue from table1 最小：select min(field1) as minvalue from table1 11、说明：几个高级查询运算词 A： UNION 运算符 UNION 运算符通过组合其他两个结果表（例如 TABLE1 和 TABLE2）并消去表中任何重复行而派生出一个结果表。当 ALL 随 UNION 一起使用时（即 UNION ALL），不消除重复行。两种情况下，派生表的每一行不是来自 TABLE1 就是来自 TABLE2。 B： EXCEPT 运算符 EXCEPT 运算符通过包括所有在 TABLE1 中但不在 TABLE2 中的行并消除所有重复行而派生出一个结果表。当 ALL 随 EXCEPT 一起使用时 (EXCEPT ALL)，不消除重复行。 C： INTERSECT 运算符 INTERSECT 运算符通过只包括 TABLE1 和 TABLE2 中都有的行并消除所有重复行而派生出一个结果表。当 ALL 随 INTERSECT 一起使用时 (INTERSECT ALL)，不消除重复行。 注：使用运算词的几个查询结果行必须是一致的。 12、说明：使用外连接 A、left outer join： 左外连接（左连接）：结果集几包括连接表的匹配行，也包括左连接表的所有行。SQL: select a.a, a.b, a.c, b.c, b.d, b.f from a LEFT OUT JOIN b ON a.a = b.c B：right outer join: 右外连接(右连接)：结果集既包括连接表的匹配连接行，也包括右连接表的所有行。 C：full outer join： 全外连接：不仅包括符号连接表的匹配行，还包括两个连接表中的所有记录。 其次，大家来看一些不错的sql语句 1、说明：复制表(只复制结构,源表名：a 新表名：b) (Access可用) 法一：select into b from a where 1&lt;&gt;1 法二：select top 0 into b from a 2、说明：拷贝表(拷贝数据,源表名：a 目标表名：b) (Access可用)insert into b(a, b, c) select d,e,f from b; 3、说明：跨数据库之间表的拷贝(具体数据使用绝对路径) (Access可用)insert into b(a, b, c) select d,e,f from b in ‘具体数据库’ where 条件 例子：..from b in ’”&amp;Server.MapPath(“.”)&amp;”\data.mdb” &amp;”’ where.. 4、说明：子查询(表名1：a 表名2：b)select a,b,c from a where a IN (select d from b ) 或者: select a,b,c from a where a IN (1,2,3) 5、说明：显示文章、提交人和最后回复时间select a.title,a.username,b.adddate from table a,(select max(adddate) adddate from table where table.title=a.title) b6、说明：外连接查询(表名1：a 表名2：b)select a.a, a.b, a.c, b.c, b.d, b.f from a LEFT OUT JOIN b ON a.a = b.c 7、说明：在线视图查询(表名1：a )select from (SELECT a,b,c FROM a) T where t.a &gt; 1; 8、说明：between的用法,between限制查询数据范围时包括了边界值,not between不包括select from table1 where time between time1 and time2select a,b,c, from table1 where a not between 数值1 and 数值2 9、说明：in 的使用方法select from table1 where a [not] in (‘值1’,’值2’,’值4’,’值6’) 10、说明：两张关联表，删除主表中已经在副表中没有的信息delete from table1 where not exists ( select from table2 where table1.field1=table2.field1 ) 11、说明：四表联查问题：select from a left inner join b on a.a=b.b right inner join c on a.a=c.c inner join d on a.a=d.d where ….. 12、说明：日程安排提前五分钟提醒SQL: select from 日程安排 where datediff(’minute’,f开始时间,getdate())&gt;5 13、说明：一条sql 语句搞定数据库分页select top 10 b. from (select top 20 主键字段,排序字段 from 表名 order by 排序字段 desc) a,表名 b where b.主键字段 = a.主键字段 order by a.排序字段 14、说明：前10条记录select top 10 form table1 where 范围 15、说明：选择在每一组b值相同的数据中对应的a最大的记录的所有信息(类似这样的用法可以用于论坛每月排行榜,每月热销产品分析,按科目成绩排名,等等.)select a,b,c from tablename ta where a=(select max(a) from tablename tb where tb.b=ta.b) 16、说明：包括所有在 TableA 中但不在 TableB和TableC 中的行并消除所有重复行而派生出一个结果表(select a from tableA ) except (select a from tableB) except (select a from tableC) 17、说明：随机取出10条数据select top 10 * from tablename order by newid() 18、说明：随机选择记录select newid() 19、说明：删除重复记录Delete from tablename where id not in (select max(id) from tablename group by col1,col2,…) 20、说明：列出数据库里所有的表名select name from sysobjects where type=’U’21、说明：列出表里的所有的select name from syscolumns where id=object_id(’TableName’) 22、说明：列示type、vender、pcs字段，以type字段排列，case可以方便地实现多重选择，类似select 中的case。select type,sum(case vender when ’A’ then pcs else 0 end),sum(case vender when ’C’ then pcs else 0 end),sum(case vender when ’B’ then pcs else 0 end) FROM tablename group by type 显示结果：type vender pcs电脑 A 1电脑 A 1光盘 B 2光盘 A 2手机 B 3手机 C 3 23、说明：初始化表table1TRUNCATE TABLE table1 24、说明：选择从10到15的记录select top 5 from (select top 15 from table order by id asc) table_别名 order by id desc随机选择数据库记录的方法（使用Randomize函数，通过SQL语句实现） 对存储在数据库中的数据来说，随机数特性能给出上面的效果，但它们可能太慢了些。你不能要求ASP“找个随机数”然后打印出来。实际上常见的解决方案是建立如下所示的循环：RandomizeRNumber = Int(Rnd499) +1 While Not objRec.EOFIf objRec(“ID”) = RNumber THEN… 这里是执行脚本 …end ifobjRec.MoveNextWend 这很容易理解。首先，你取出1到500范围之内的一个随机数（假设500就是数据库内记录的总数）。然后，你遍历每一记录来测试ID 的值、检查其是否匹配RNumber。满足条件的话就执行由THEN 关键字开始的那一块代码。假如你的RNumber 等于495，那么要循环一遍数据库花的时间可就长了。虽然500这个数字看起来大了些，但相比更为稳固的企业解决方案这还是个小型数据库了，后者通常在一个数据库内就包含了成千上万条记录。这时候不就死定了？ 采用SQL，你就可以很快地找出准确的记录并且打开一个只包含该记录的recordset，如下所示：RandomizeRNumber = Int(Rnd499) + 1 SQL = “SELECT FROM Customers WHERE ID = “ &amp; RNumber set objRec = ObjConn.Execute(SQL)Response.WriteRNumber &amp; “ = “ &amp; objRec(“ID”) &amp; “ “ &amp; objRec(“c_email”) 不必写出RNumber 和ID，你只需要检查匹配情况即可。只要你对以上代码的工作满意，你自可按需操作“随机”记录。Recordset没有包含其他内容，因此你很快就能找到你需要的记录这样就大大降低了处理时间。再谈随机数 现在你下定决心要榨干Random 函数的最后一滴油，那么你可能会一次取出多条随机记录或者想采用一定随机范围内的记录。把上面的标准Random 示例扩展一下就可以用SQL应对上面两种情况了。 为了取出几条随机选择的记录并存放在同一recordset内，你可以存储三个随机数，然后查询数据库获得匹配这些数字的记录： SQL = “SELECT FROM Customers WHERE ID = “ &amp; RNumber &amp; “ OR ID = “ &amp; RNumber2 &amp; “ OR ID = “ &amp; RNumber3 假如你想选出10条记录（也许是每次页面装载时的10条链接的列表），你可以用BETWEEN 或者数学等式选出第一条记录和适当数量的递增记录。这一操作可以通过好几种方式来完成，但是 SELECT 语句只显示一种可能（这里的ID 是自动生成的号码）：SQL = “SELECT FROM Customers WHERE ID BETWEEN “ &amp; RNumber &amp; “ AND “ &amp; RNumber &amp; “+ 9” 注意：以上代码的执行目的不是检查数据库内是否有9条并发记录。 随机读取若干条记录，测试过Access语法：SELECT top 10 From 表名 ORDER BY Rnd(id)Sql server:select top n from 表名 order by newid()mysql select From 表名 Order By rand() Limit n Access左连接语法(最近开发要用左连接,Access帮助什么都没有,网上没有Access的SQL说明,只有自己测试, 现在记下以备后查) 语法 select table1.fd1,table1,fd2,table2.fd2 From table1 left join table2 on table1.fd1,table2.fd1 where … 使用SQL语句 用…代替过长的字符串显示 语法： SQL数据库：select case when len(field)&gt;10 then left(field,10)+’…’ else field end as news_name,news_id from tablename Access数据库：SELECT iif(len(field)&gt;2,left(field,2)+’…’,field) FROM tablename; Conn.Execute说明 Execute方法 该方法用于执行SQL语句。根据SQL语句执行后是否返回记录集，该方法的使用格式分为以下两种： 1．执行SQL查询语句时，将返回查询得到的记录集。用法为： Set 对象变量名=连接对象.Execute(“SQL 查询语言”) Execute方法调用后，会自动创建记录集对象，并将查询结果存储在该记录对象中，通过Set方法，将记录集赋给指定的对象保存，以后对象变量就代表了该记录集对象。 2．执行SQL的操作性语言时，没有记录集的返回。此时用法为： 连接对象.Execute “SQL 操作性语句” [, RecordAffected][, Option] ·RecordAffected 为可选项，此出可放置一个变量，SQL语句执行后，所生效的记录数会自动保存到该变量中。通过访问该变量，就可知道SQL语句队多少条记录进行了操作。 ·Option 可选项，该参数的取值通常为adCMDText，它用于告诉ADO，应该将Execute方法之后的第一个字符解释为命令文本。通过指定该参数，可使执行更高效。 ·BeginTrans、RollbackTrans、CommitTrans方法 这三个方法是连接对象提供的用于事务处理的方法。BeginTrans用于开始一个事物；RollbackTrans用于回滚事务；CommitTrans用于提交所有的事务处理结果，即确认事务的处理。 事务处理可以将一组操作视为一个整体，只有全部语句都成功执行后，事务处理才算成功；若其中有一个语句执行失败，则整个处理就算失败，并恢复到处里前的状态。 BeginTrans和CommitTrans用于标记事务的开始和结束，在这两个之间的语句，就是作为事务处理的语句。判断事务处理是否成功，可通过连接对象的Error集合来实现，若Error集合的成员个数不为0，则说明有错误发生，事务处理失败。Error集合中的每一个Error对象，代表一个错误信息。SQL语句大全精要2006/10/26 13:46DELETE语句DELETE语句：用于创建一个删除查询，可从列在 FROM 子句之中的一个或多个表中删除记录，且该子句满足 WHERE 子句中的条件，可以使用DELETE删除多个记录。语法：DELETE [table.] FROM table WHERE criteria语法：DELETE FROM table WHERE criteria=’查询的字’说明：table参数用于指定从其中删除记录的表的名称。criteria参数为一个表达式，用于指定哪些记录应该被删除的表达式。可以使用 Execute 方法与一个 DROP 语句从数据库中放弃整个表。不过，若用这种方法删除表，将会失去表的结构。不同的是当使用 DELETE，只有数据会被删除；表的结构以及表的所有属性仍然保留，例如字段属性及索引。UPDATE有关UPDATE，急！！！！！！！！！！！在ORACLE数据库中表 A ( ID ,FIRSTNAME,LASTNAME )表 B( ID,LASTNAME)表 A 中原来ID,FIRSTNAME两个字段的数据是完整的表 B中原来ID,LASTNAME两个字段的数据是完整的现在要把表 B中的LASTNAME字段的相应的数据填入到A表中LASTNAME相应的位置。两个表中的ID字段是相互关联的。先谢谢了!!!!update a set a.lastname=(select b.lastname from b where a.id=b.id) 掌握SQL四条最基本的数据操作语句：Insert，Select，Update和Delete。 练掌握SQL是数据库用户的宝贵财富。在本文中，我们将引导你掌握四条最基本的数据操作语句—SQL的核心功能—来依次介绍比较操作符、选择断言以及三值逻辑。当你完成这些学习后，显然你已经开始算是精通SQL了。 在我们开始之前，先使用CREATE TABLE语句来创建一个表（如图1所示）。DDL语句对数据库对象如表、列和视进行定义。它们并不对表中的行进行处理，这是因为DDL语句并不处理数据库中实际的数据。这些工作由另一类SQL语句—数据操作语言（DML）语句进行处理。 SQL中有四种基本的DML操作：INSERT，SELECT，UPDATE和DELETE。由于这是大多数SQL用户经常用到的，我们有必要在此对它们进行一一说明。在图1中我们给出了一个名为EMPLOYEES的表。其中的每一行对应一个特定的雇员记录。请熟悉这张表，我们在后面的例子中将要用到它。 The Execute method executes a specified query, SQL statement, stored procedure, or provider-specific text.Execute的作用是：执行一个查询语句、陈述语句、程序或技术提供对象[provider]的详细文本。 The results are stored in a new Recordset object if it is a row-returning query. A closed Recordset object will be returned if it is not a row-returning query.如果返回行[row-returning]查询语句，那么结果将被存储在一个新的记录对象中；如果它不是一个返回行[row-returning]查询语句，那么它将返回一个关闭的记录对象。 Note: The returned Recordset is always a read-only, forward-only Recordset!注意：返回的Recordset是一个只读的、只向前兼容的Recordset。 Tip: To create a Recordset with more functionality, first create a Recordset object. Set the desired properties, and then use the Recordset object’s Open method to execute the query.提示：在第一次创建Recordset对象时，需要将它创建为一个更具功能性的Recordset对象。设置一个我们所希望的属性，使用Recordset对象的Open方法去执行查询语句。 Syntax for row-returningrow-returning[返回行]语法 Set objrs=objconn.Execute(commandtext,ra,options) Syntax for non-row-returningnon-row-returning[非返回行]语法 objconn.Execute commandtext,ra,options Parameter参数 Description描述 commandtext Required. The SQL statement, stored procedure, or provider-specific text to execute 必要参数。指定需要执行的SQL语句，现存的程序或技术提供对象[provider]的详细文本 ra Optional. The number of records affected by the query 可选参数。返回查询语句执行的记录数 options Optional. Sets how the provider should evaluate the commandtext parameter. Can be one or more CommandTypeEnum or ExecuteOptionEnum values. Default is adCmdUnspecified 可选参数。设置技术提供对象[provider]应该如何评估CommandText属性的功能。它可以是一个或多个CommandTypeEnum 或 ExecuteOptionEnum的值。默认值是adCmdUnspecified Example案例 &lt;%sql=”SELECT companyname FROM Customers”Set rs=conn.Execute(sql)%&gt; CommandTypeEnum Values Constant常量 Value值 Description描述 adCmdUnspecified -1 Does not specify the command type argument. 不指定指令类型自变量 adCmdText 1 Evaluates CommandText as a textual definition of a command or stored procedure call. 指示提供者应该将Source作为命令的文本定义来计算。 adCmdTable 2 Evaluates CommandText as a table name whose columns are all returned by an internally generated SQL query. 指示ADO生成SQL查询以便从在Source中命名的表中返回所有行 adCmdStoredProc 4 Evaluates CommandText as a stored procedure name. 将CommandText作为一个已存的程序名称 adCmdUnknown 8 Indicates that the type of command in the CommandText property is not known. 默认值。指定未知的CommandText属性命令 adCmdFile 256 Evaluates CommandText as the file name of a persistently stored Recordset. Used with Recordset.Open or Requery only. 指示应从在Source中命名的文件中恢复保留（保存的）Recordset。它仅能与Recordset.Open 或 Requery 指令一起使用 adCmdTableDirect 512 Evaluates CommandText as a table name whose columns are all returned. Used with Recordset.Open or Requery only. To use the Seek method, the Recordset must be opened with adCmdTableDirect. This value cannot be combined with the ExecuteOptionEnum value adAsyncExecute. 指示提供者更改从在 Source 中命名的表中返回所有行/ 将CommandText作为一个表的名称（该表的列全部是通过内部的SQL查询语句返回的）。它仅适用Recordset.Open 或 Requery 指令；如果需要使用查找方式，那么Recordset必须以adCmdTableDirect打开。这个值不能与ExecuteOptionEnum值 adAsyncExecute一起使用 ExecuteOptionEnum Values Constant常量 Value值 Description描述 adOptionUnspecified -1 Indicates that the command is unspecified. 指明为指定的指令 adAsyncExecute Indicates that the command should execute asynchronously. This value cannot be combined with the CommandTypeEnum value adCmdTableDirect. 指明指令是否需要异步执行。这个值不能与CommandTypeEnum 之中的adCmdTableDirect一起使用 adAsyncFetch Indicates that the remaining rows after the initial quantity specified in the CacheSize property should be retrieved asynchronously. 指明在CacheSize属性中指定了初始量以后，是否应该异步获取保留行[remaining rows] adAsyncFetchNonBlocking Indicates that the main thread never blocks while retrieving. If the requested row has not been retrieved, the current row automatically moves to the end of the file. If you open a Recordset from a Stream containing a persistently stored Recordset, adAsyncFetchNonBlocking will not have an effect; the operation will be synchronous and blocking. adAsynchFetchNonBlocking has no effect when the adCmdTableDirect option is used to open the Recordset. 指示主要线程在提取期间从未堵塞。如果所请求的行尚未提取，那么当前行将自动移到文件末尾。如果打开的记录流中的记录固定地包含一个记录，那么adAsyncFetchNonBlocking将不会产生作用；才作程序将同时运行以及阻塞该常量。当adCmdTableDirect选项用于打开记录时，adAsynchFetchNonBlocking将不会产生任何作用 adExecuteNoRecords Indicates that the command text is a command or stored procedure that does not return rows (for example, a command that only inserts data). If any rows are retrieved, they are discarded and not returned. adExecuteNoRecords can only be passed as an optional parameter to the Command or Connection Execute method. 它仅指明了指令文本仅是一条不返回任何行的指令或现存程序（如：一条只执行数据插入的指令）。如果没有任何行被提取，那么他们将放弃执行并不返回任何值。 adExecuteNoRecords仅可以作为一个可选参数传递到指令中或连接执行方法[Connection Execute method]中 adExecuteStream Indicates that the results of a command execution should be returned as a stream. adExecuteStream can only be passed as an optional parameter to the Command Execute method. 指明需要以结果流的形式返回命令执行的结果。adExecuteStream仅可以作为一个可选参数传递到指令中或连接执行方法[Connection Execute method]中 adExecuteRecord Indicates that the CommandText is a command or stored procedure that returns a single row which should be returned as a Record object. 指明CommandText仅是返回一个单独行（该单独行作为一条记录对象返回）的一条指令或现存程序]]></content>
      <tags>
        <tag>sql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MTCP建立连接和断开连接过程详解]]></title>
    <url>%2F2019%2F02%2F23%2FMTCP%E5%BB%BA%E7%AB%8B%E8%BF%9E%E6%8E%A5%E5%92%8C%E6%96%AD%E5%BC%80%E8%BF%9E%E6%8E%A5%E8%BF%87%E7%A8%8B%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[TCP是一个面向连接的服务,面向连接的服务是电话系统服务模式的抽象,每一次完整的数据传输都必须经过建立连接,数据传输和终止连接三个过程,TCP建立连接的过程称为三次握手,下面说一下三次握手的具体过程: TCP三次握手过程 主机A通过向主机B 发送一个含有同步序列号的标志位的数据段给主机B ,向主机B 请求建立连接,通过这个数据段,主机A告诉主机B 两件事:我想要和你通信;你可以用哪个序列号作为起始数据段来回应我。 主机B 收到主机A的请求后,用一个带有确认应答(ACK)和同步序列号(SYN)标志位的数据段响应主机A,也告诉主机A两件事:我已经收到你的请求了,你可以传输数据了;你要用哪佧序列号作为起始数据段来回应我。 主机A收到这个数据段后,再发送一个确认应答,确认已收到主机B 的数据段:我已收到回复,我现在要开始传输实际数据了。 这样TCP三次握手就完成了,主机A和主机B 就可以传输数据了。三次握手的特点：没有应用层的数据,SYN这个标志位只有在TCP建产连接时才会被置1,握手完成后SYN标志位被置0。 TCP建立连接要进行三次握手,而断开连接要进行四次,这是由于TCP的半关闭造成的,因为TCP连接是全双工的(即数据可在两个方向上同时传递)所以进行关闭时每个方向上都要单独进行关闭,这个单方向的关闭就叫半关闭.关闭的方法是一方完成它的数据传输后,就发送一个FIN来向另一方通告将要终止这个方向的连接.当一端收到一个FIN,它必须通知应用层TCP连接已终止了这个方向的数据传送,发送FIN通常是应用层进行关闭的结果。 四次断开过程 当主机A完成数据传输后,将控制位FIN置1,提出停止TCP连接的请求 主机B收到FIN后对其作出响应,确认这一方向上的TCP连接将关闭,将ACK置1 由B 端再提出反方向的关闭请求,将FIN置1 主机A对主机B的请求进行确认,将ACK置1,双方向的关闭结束。 由TCP的三次握手和四次断开可以看出,TCP使用面向连接的通信方式,大大提高了数据通信的可靠性,使发送数据端和接收端在数据正式传输前就有了交互,为数据正式传输打下了可靠的基础。 讲到这里在来一张全面的图来理解一下：(图片来自：http://blog.csdn.net/hjw1991324/article/details/51044580)]]></content>
      <tags>
        <tag>http</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[防止ＳＱＬ注入的五种方法]]></title>
    <url>%2F2019%2F02%2F23%2F%E9%98%B2%E6%AD%A2SQL%E6%B3%A8%E5%85%A5%E7%9A%84%E4%BA%94%E7%A7%8D%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[防止ＳＱＬ注入的五种方法一、SQL注入简介 ​ SQL注入是比较常见的网络攻击方式之一，它不是利用操作系统的BUG来实现攻击，而是针对程序员编程时的疏忽，通过SQL语句，实现无帐号登录，甚至篡改数据库。 二、SQL注入攻击的总体思路 1.寻找到SQL注入的位置 2.判断服务器类型和后台数据库类型 3.针对不通的服务器和数据库特点进行SQL注入攻击 三、SQL注入攻击实例 比如在一个登录界面，要求输入用户名和密码： 可以这样输入实现免帐号登录： 用户名： ‘or 1 = 1 – 密 码： 点登陆,如若没有做特殊处理,那么这个非法用户就很得意的登陆进去了.(当然现在的有些语言的数据库API已经处理了这些问题) 这是为什么呢? 下面我们分析一下： 从理论上说，后台认证程序中会有如下的SQL语句： String sql = “select * from user_table where username= ‘ “+userName+” ‘ and password=’ “+password+” ‘“; 当输入了上面的用户名和密码，上面的SQL语句变成： SELECT * FROM user_table WHERE username= ‘’or 1 = 1 – and password=’’ 分析SQL语句： 条件后面username=”or 1=1 用户名等于 ” 或1=1 那么这个条件一定会成功； 然后后面加两个-，这意味着注释，它将后面的语句注释，让他们不起作用，这样语句永远都能正确执行，用户轻易骗过系统，获取合法身份。 这还是比较温柔的，如果是执行 SELECT * FROM user_table WHERE username=’’ ;DROP DATABASE (DB Name) –’ and password=’’ ….其后果可想而知… 四、应对方法 下面我针对JSP，说一下应对方法： 1.（简单又有效的方法）PreparedStatement 采用预编译语句集，它内置了处理SQL注入的能力，只要使用它的setXXX方法传值即可。 使用好处： (1).代码的可读性和可维护性. (2).PreparedStatement尽最大可能提高性能. (3).最重要的一点是极大地提高了安全性. 原理： sql注入只对sql语句的准备(编译)过程有破坏作用 而PreparedStatement已经准备好了,执行阶段只是把输入串作为数据处理, 而不再对sql语句进行解析,准备,因此也就避免了sql注入问题. 2.使用正则表达式过滤传入的参数 要引入的包： import java.util.regex.*; 正则表达式： private String CHECKSQL = “^(.+)\sand\s(.+)|(.+)\sor(.+)\s$”; 判断是否匹配： Pattern.matches(CHECKSQL,targerStr); 下面是具体的正则表达式： 检测SQL meta-characters的正则表达式 ： /(\%27)|(\’)|(--)|(\%23)|(#)/ix 修正检测SQL meta-characters的正则表达式 ：/((\%3D)|(=))[^\n]*((\%27)|(\’)|(--)|(\%3B)|(:))/i 典型的SQL 注入攻击的正则表达式 ：/\w*((\%27)|(\’))((\%6F)|o|(\%4F))((\%72)|r|(\%52))/ix 检测SQL注入，UNION查询关键字的正则表达式 ：/((\%27)|(\’))union/ix(\%27)|(\’) 检测MS SQL Server SQL注入攻击的正则表达式： /exec(\s|+)+(s|x)p\w+/ix 等等….. 3.字符串过滤 比较通用的一个方法： （||之间的参数可以根据自己程序的需要添加） public static boolean sql_inj(String str){ String inj_str = “‘|and|exec|insert|select|delete|update| count|*|%|chr|mid|master|truncate|char|declare|;|or|-|+|,”; String inj_stra[] = split(inj_str,”|”); for (int i=0 ; i &lt; inj_stra.length ; i++ ){ if (str.indexOf(inj_stra[i])&gt;=0){ return true; } } return false; } 4.jsp中调用该函数检查是否包函非法字符 防止SQL从URL注入： sql_inj.java代码： package sql_inj; import java.net.*; import java.io.*; import java.sql.*; import java.text.*; import java.lang.String; public class sql_inj{ public static boolean sql_inj(String str){ String inj_str = “‘|and|exec|insert|select|delete|update| count|*|%|chr|mid|master|truncate|char|declare|;|or|-|+|,”; //这里的东西还可以自己添加 String[] inj_stra=inj_str.split(“\|”); for (int i=0 ; i &lt; inj_stra.length ; i++ ){ if (str.indexOf(inj_stra[i])&gt;=0){ return true; } } return false; } } 5.JSP页面判断代码： 使用javascript在客户端进行不安全字符屏蔽 功能介绍：检查是否含有”‘”,”\”,”/” 参数说明：要检查的字符串 返回值：0：是1：不是 函数名是 function check(a){ return 1; fibdn = new Array (”‘” ,”\”,”/”); i=fibdn.length; j=a.length; for (ii=0; ii＜i; ii++) { for (jj=0; jj＜j; jj++) { temp1=a.charAt(jj); temp2=fibdn[ii]; if (tem’; p1==temp2) { return 0; } } } return 1; } =================================== 总的说来，防范一般的SQL注入只要在代码规范上下点功夫就可以了。 凡涉及到执行的SQL中有变量时，用JDBC（或者其他数据持久层）提供的如：PreparedStatement就可以 ，切记不要用拼接字符串的方法就可以了。]]></content>
      <tags>
        <tag>sql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CSRF_oken介绍与应对策略]]></title>
    <url>%2F2019%2F02%2F18%2FCSRF-oken%E4%BB%8B%E7%BB%8D%E4%B8%8E%E5%BA%94%E5%AF%B9%E7%AD%96%E7%95%A5%2F</url>
    <content type="text"><![CDATA[CSRF 背景与介绍CSRF（Cross Site Request Forgery, 跨站域请求伪造）是一种网络的攻击方式，它在 2007 年曾被列为互联网 20 大安全隐患之一。其他安全隐患，比如 SQL 脚本注入，跨站域脚本攻击等在近年来已经逐渐为众人熟知，很多网站也都针对他们进行了防御。然而，对于大多数人来说，CSRF 却依然是一个陌生的概念。即便是大名鼎鼎的 Gmail, 在 2007 年底也存在着 CSRF 漏洞，从而被黑客攻击而使 Gmail 的用户造成巨大的损失。 CSRF 攻击实例CSRF 攻击可以在受害者毫不知情的情况下以受害者名义伪造请求发送给受攻击站点，从而在并未授权的情况下执行在权限保护之下的操作。比如说，受害者 Bob 在银行有一笔存款，通过对银行的网站发送请求 http://bank.example/withdraw?account=bob&amp;amount=1000000&amp;for=bob2 可以使 Bob 把 1000000 的存款转到 bob2 的账号下。通常情况下，该请求发送到网站后，服务器会先验证该请求是否来自一个合法的 session，并且该 session 的用户 Bob 已经成功登陆。黑客 Mallory 自己在该银行也有账户，他知道上文中的 URL 可以把钱进行转帐操作。Mallory 可以自己发送一个请求给银行：http://bank.example/withdraw?account=bob&amp;amount=1000000&amp;for=Mallory。但是这个请求来自 Mallory 而非 Bob，他不能通过安全认证，因此该请求不会起作用。这时，Mallory 想到使用 CSRF 的攻击方式，他先自己做一个网站，在网站中放入如下代码： src=”http://bank.example/withdraw?account=bob&amp;amount=1000000&amp;for=Mallory ”，并且通过广告等诱使 Bob 来访问他的网站。当 Bob 访问该网站时，上述 url 就会从 Bob 的浏览器发向银行，而这个请求会附带 Bob 浏览器中的 cookie 一起发向银行服务器。大多数情况下，该请求会失败，因为他要求 Bob 的认证信息。但是，如果 Bob 当时恰巧刚访问他的银行后不久，他的浏览器与银行网站之间的 session 尚未过期，浏览器的 cookie 之中含有 Bob 的认证信息。这时，悲剧发生了，这个 url 请求就会得到响应，钱将从 Bob 的账号转移到 Mallory 的账号，而 Bob 当时毫不知情。等以后 Bob 发现账户钱少了，即使他去银行查询日志，他也只能发现确实有一个来自于他本人的合法请求转移了资金，没有任何被攻击的痕迹。而 Mallory 则可以拿到钱后逍遥法外。 CSRF 攻击的对象在讨论如何抵御 CSRF 之前，先要明确 CSRF 攻击的对象，也就是要保护的对象。从以上的例子可知，CSRF 攻击是黑客借助受害者的 cookie 骗取服务器的信任，但是黑客并不能拿到 cookie，也看不到 cookie 的内容。另外，对于服务器返回的结果，由于浏览器同源策略的限制，黑客也无法进行解析。因此，黑客无法从返回的结果中得到任何东西，他所能做的就是给服务器发送请求，以执行请求中所描述的命令，在服务器端直接改变数据的值，而非窃取服务器中的数据。所以，我们要保护的对象是那些可以直接产生数据改变的服务，而对于读取数据的服务，则不需要进行 CSRF 的保护。比如银行系统中转账的请求会直接改变账户的金额，会遭到 CSRF 攻击，需要保护。而查询余额是对金额的读取操作，不会改变数据，CSRF 攻击无法解析服务器返回的结果，无需保护。 当前防御 CSRF 的几种策略验证 HTTP Referer 字段根据 HTTP 协议，在 HTTP 头中有一个字段叫 Referer，它记录了该 HTTP 请求的来源地址。在通常情况下，访问一个安全受限页面的请求来自于同一个网站，比如需要访问 http://bank.example/withdraw?account=bob&amp;amount=1000000&amp;for=Mallory，用户必须先登陆 bank.example，然后通过点击页面上的按钮来触发转账事件。这时，该转帐请求的 Referer 值就会是转账按钮所在的页面的 URL，通常是以 bank.example 域名开头的地址。而如果黑客要对银行网站实施 CSRF 攻击，他只能在他自己的网站构造请求，当用户通过黑客的网站发送请求到银行时，该请求的 Referer 是指向黑客自己的网站。因此，要防御 CSRF 攻击，银行网站只需要对于每一个转账请求验证其 Referer 值，如果是以 bank.example 开头的域名，则说明该请求是来自银行网站自己的请求，是合法的。如果 Referer 是其他网站的话，则有可能是黑客的 CSRF 攻击，拒绝该请求。这种方法的显而易见的好处就是简单易行，网站的普通开发人员不需要操心 CSRF 的漏洞，只需要在最后给所有安全敏感的请求统一增加一个拦截器来检查 Referer 的值就可以。特别是对于当前现有的系统，不需要改变当前系统的任何已有代码和逻辑，没有风险，非常便捷。然而，这种方法并非万无一失。Referer 的值是由浏览器提供的，虽然 HTTP 协议上有明确的要求，但是每个浏览器对于 Referer 的具体实现可能有差别，并不能保证浏览器自身没有安全漏洞。使用验证 Referer 值的方法，就是把安全性都依赖于第三方（即浏览器）来保障，从理论上来讲，这样并不安全。事实上，对于某些浏览器，比如 IE6 或 FF2，目前已经有一些方法可以篡改 Referer 值。如果 bank.example 网站支持 IE6 浏览器，黑客完全可以把用户浏览器的 Referer 值设为以 bank.example 域名开头的地址，这样就可以通过验证，从而进行 CSRF 攻击。即便是使用最新的浏览器，黑客无法篡改 Referer 值，这种方法仍然有问题。因为 Referer 值会记录下用户的访问来源，有些用户认为这样会侵犯到他们自己的隐私权，特别是有些组织担心 Referer 值会把组织内网中的某些信息泄露到外网中。因此，用户自己可以设置浏览器使其在发送请求时不再提供 Referer。当他们正常访问银行网站时，网站会因为请求没有 Referer 值而认为是 CSRF 攻击，拒绝合法用户的访问。在请求地址中添加 token 并验证CSRF 攻击之所以能够成功，是因为黑客可以完全伪造用户的请求，该请求中所有的用户验证信息都是存在于 cookie 中，因此黑客可以在不知道这些验证信息的情况下直接利用用户自己的 cookie 来通过安全验证。要抵御 CSRF，关键在于在请求中放入黑客所不能伪造的信息，并且该信息不存在于 cookie 之中。可以在 HTTP 请求中以参数的形式加入一个随机产生的 token，并在服务器端建立一个拦截器来验证这个 token，如果请求中没有 token 或者 token 内容不正确，则认为可能是 CSRF 攻击而拒绝该请求。这种方法要比检查 Referer 要安全一些，token 可以在用户登陆后产生并放于 session 之中，然后在每次请求时把 token 从 session 中拿出，与请求中的 token 进行比对，但这种方法的难点在于如何把 token 以参数的形式加入请求。对于 GET 请求，token 将附在请求地址之后，这样 URL 就变成 http://url?csrftoken=tokenvalue。 而对于 POST 请求来说，要在 form 的最后加上 ，这样就把 token 以参数的形式加入请求了。但是，在一个网站中，可以接受请求的地方非常多，要对于每一个请求都加上 token 是很麻烦的，并且很容易漏掉，通常使用的方法就是在每次页面加载时，使用 javascript 遍历整个 dom 树，对于 dom 中所有的 a 和 form 标签后加入 token。这样可以解决大部分的请求，但是对于在页面加载之后动态生成的 html 代码，这种方法就没有作用，还需要程序员在编码时手动添加 token。该方法还有一个缺点是难以保证 token 本身的安全。特别是在一些论坛之类支持用户自己发表内容的网站，黑客可以在上面发布自己个人网站的地址。由于系统也会在这个地址后面加上 token，黑客可以在自己的网站上得到这个 token，并马上就可以发动 CSRF 攻击。为了避免这一点，系统可以在添加 token 的时候增加一个判断，如果这个链接是链到自己本站的，就在后面添加 token，如果是通向外网则不加。不过，即使这个 csrftoken 不以参数的形式附加在请求之中，黑客的网站也同样可以通过 Referer 来得到这个 token 值以发动 CSRF 攻击。这也是一些用户喜欢手动关闭浏览器 Referer 功能的原因。在 HTTP 头中自定义属性并验证这种方法也是使用 token 并进行验证，和上一种方法不同的是，这里并不是把 token 以参数的形式置于 HTTP 请求之中，而是把它放到 HTTP 头中自定义的属性里。通过 XMLHttpRequest 这个类，可以一次性给所有该类请求加上 csrftoken 这个 HTTP 头属性，并把 token 值放入其中。这样解决了上种方法在请求中加入 token 的不便，同时，通过 XMLHttpRequest 请求的地址不会被记录到浏览器的地址栏，也不用担心 token 会透过 Referer 泄露到其他网站中去。然而这种方法的局限性非常大。XMLHttpRequest 请求通常用于 Ajax 方法中对于页面局部的异步刷新，并非所有的请求都适合用这个类来发起，而且通过该类请求得到的页面不能被浏览器所记录下，从而进行前进，后退，刷新，收藏等操作，给用户带来不便。另外，对于没有进行 CSRF 防护的遗留系统来说，要采用这种方法来进行防护，要把所有请求都改为 XMLHttpRequest 请求，这样几乎是要重写整个网站，这代价无疑是不能接受的。 读后感看了很多篇关于token的文章，这个算是最通俗易懂的文章之一了。 CSRF攻击属于一种恶意网站的攻击，恶意网站会通过你电脑，尚未过期的session登陆状态，来发送一些请求，达到某种目的。 防止的方法： 1.可以通过Referer得到请求来源，判断是正规网站的来源，还是通过CSRF攻击所请求的。 但是这种办法黑客可以通过修改referer来实现，并且也属于第三方的，通过浏览器来实现安全。对于程序员来说，不可定性还是很高。 2.可以通过设置一定个token，在登陆的时候，自动生成一个token，在表单提交或者请求连接的时候，都加上token值。这个样子的话，如果是CSRF攻击的话，那么就不存在token值或错误的token值。就会的导致token不一致，无法过拦截器。 现在做的项目就是在登陆的时候自动生成一个token值，存入到mysql数据库，当请求的时候，就会去数据库匹配token。至于为什么使用mysql里存储token，不用session存储。这个我就不知道了，可能是手机端吧。 3.可以在自定义属性XMLHttpRequest中，添加一个token，这个token不是以参数的形式传递的，而是放到HTTP头中自定义的属性里，通过XMLHttpRequest给所有求情加上token。 但是XMLHttpRequest是大多数用于ajax请求，局限性比较大，不是所有的类都是由这个类来发起的。对于一些遗留性代码，如果要使用这种方式，需要重写整个程序，这个代价是非常大的。并且通过该类访问的地址，在浏览器上不会有记录，所以用户在前进，后退，刷新，收藏等操作，不容易实现。造成一定困难。 CSRF 防御方法选择之道通过上文讨论可知，目前业界应对 CSRF 攻击有一些克制方法，但是每种方法都有利弊，没有一种方法是完美的。如何选择合适的方法非常重要。如果网站是一个现有系统，想要在最短时间内获得一定程度的 CSRF 的保护，那么验证 Referer 的方法是最方便的，要想增加安全性的话，可以选择不支持低版本浏览器，毕竟就目前来说，IE7+, FF3+ 这类高版本浏览器的 Referer 值还无法被篡改。 如果系统必须支持 IE6，并且仍然需要高安全性。那么就要使用 token 来进行验证，在大部分情况下，使用 XmlHttpRequest 并不合适，token 只能以参数的形式放于请求之中，若你的系统不支持用户自己发布信息，那这种程度的防护已经足够，否则的话，你仍然难以防范 token 被黑客窃取并发动攻击。在这种情况下，你需要小心规划你网站提供的各种服务，从中间找出那些允许用户自己发布信息的部分，把它们与其他服务分开，使用不同的 token 进行保护，这样可以有效抵御黑客对于你关键服务的攻击，把危害降到最低。毕竟，删除别人一个帖子比直接从别人账号中转走大笔存款严重程度要轻的多。 如果是开发一个全新的系统，则抵御 CSRF 的选择要大得多。笔者建议对于重要的服务，可以尽量使用 XMLHttpRequest 来访问，这样增加 token 要容易很多。另外尽量避免在 js 代码中使用复杂逻辑来构造常规的同步请求来访问需要 CSRF 保护的资源，比如 window.location 和 document.createElement(“a”) 之类，这样也可以减少在附加 token 时产生的不必要的麻烦。 最后，要记住 CSRF 不是黑客唯一的攻击手段，无论你 CSRF 防范有多么严密，如果你系统有其他安全漏洞，比如跨站域脚本攻击 XSS，那么黑客就可以绕过你的安全防护，展开包括 CSRF 在内的各种攻击，你的防线将如同虚设。 总结与展望可见，CSRF 是一种危害非常大的攻击，又很难以防范。目前几种防御策略虽然可以很大程度上抵御 CSRF 的攻击，但并没有一种完美的解决方案。一些新的方案正在研究之中，比如对于每次请求都使用不同的动态口令，把 Referer 和 token 方案结合起来，甚至尝试修改 HTTP 规范，但是这些新的方案尚不成熟，要正式投入使用并被业界广为接受还需时日。在这之前，我们只有充分重视 CSRF，根据系统的实际情况选择最合适的策略，这样才能把 CSRF 的危害降到最低。]]></content>
      <tags>
        <tag>csrf</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[在hexo博客上添加可爱的live2D模型]]></title>
    <url>%2F2019%2F02%2F18%2F%E5%9C%A8Hexo%E5%8D%9A%E5%AE%A2%E4%B8%8A%E6%B7%BB%E5%8A%A0%E5%8F%AF%E7%88%B1%E7%9A%84Live%202D%E6%A8%A1%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[在查找资料的偶然间，我发现一个博客上有非常可爱的Live 2D模型，当时我就被打动了，马上开启审查元素，试图找出这个Live 2D模型的信息，可是找了半天没找到。最后通过截图-&gt;谷歌图片的方式，终于一层一层的找到了相关资料，我正好有一个Hexo博客，所以今天就来在博客上添加一波Live 2D模型！ 首先，安装npm包： npm install –save hexo-helper-live2d1然后在hexo的配置文件_config.yml中添加如下配置，详细配置可以参考文档： live2d: enable: true scriptFrom: local pluginRootPath: live2dw/ pluginJsPath: lib/ pluginModelPath: assets/ tagMode: false debug: false model:​ use: live2d-widget-model-shizuku display:​ position: right​ width: 150​ height: 300 mobile:​ show: true12345678910111213141516然后下载模型，模型名称可以到这里参考，一些模型的预览可以在这里。 npm install live2d-widget-model-shizuku1所有模型列表如下： live2d-widget-model-chitoselive2d-widget-model-epsilon2_1live2d-widget-model-gflive2d-widget-model-haru/01 (use npm install –save live2d-widget-model-haru)live2d-widget-model-haru/02 (use npm install –save live2d-widget-model-haru)live2d-widget-model-harutolive2d-widget-model-hibikilive2d-widget-model-hijikilive2d-widget-model-izumilive2d-widget-model-koharulive2d-widget-model-mikulive2d-widget-model-ni-jlive2d-widget-model-nicolive2d-widget-model-nietzschelive2d-widget-model-nipsilonlive2d-widget-model-nitolive2d-widget-model-shizukulive2d-widget-model-tororolive2d-widget-model-tsumikilive2d-widget-model-unitychanlive2d-widget-model-wankolive2d-widget-model-z16下载完之后，在Hexo根目录中新建文件夹live2d_models，然后在node_modules文件夹中找到刚刚下载的live2d模型，将其复制到live2d_models中，然后编辑配置文件中的model.use项，将其修改为live2d_models文件夹中的模型文件夹名称。 一切就绪之后，用hexo server命令启动服务器，稍等一下就可以看到右下角出现了一个可爱的萌萌哒的妹纸！本来录了一个GIF，可惜上传上来变成了PNG格式……想看动态图的话只能直接看我的博客了，不过因为所有东西都在Github上托管的原因，可能Live2D不能马上加载出来。]]></content>
  </entry>
  <entry>
    <title><![CDATA[使用Hexo+Github一步步搭建属于自己的博客基础篇]]></title>
    <url>%2F2019%2F02%2F18%2F%E4%BD%BF%E7%94%A8Hexo-Github%E4%B8%80%E6%AD%A5%E6%AD%A5%E6%90%AD%E5%BB%BA%E5%B1%9E%E4%BA%8E%E8%87%AA%E5%B7%B1%E7%9A%84%E5%8D%9A%E5%AE%A2%E5%9F%BA%E7%A1%80%E7%AF%87%2F</url>
    <content type="text"><![CDATA[前言：电脑系统为window 10专业版，64位相关步骤： 1、安装Node.js和配置好Node.js环境，打开cmd命令行，成功界面如下 2、安装Git和配置好Git环境，安装成功的象征就是在电脑上任何位置鼠标右键能够出现如下两个选择 注意：一般出于安全考虑，只有在Git Bash Here中才能进行Git的相关操作。如果需要在cmd命令行里调用Git，那么就要配置电脑的环境变量Path，或者在安装的时候选择use Git from the Windows Command Prompt。这个可有可无，影响不大，成功配置的界面如图 3、Github账户注册和新建项目，项目必须要遵守格式：账户名.github.io，不然接下来会有很多麻烦。并且需要勾选Initialize this repository with a README在建好的项目右侧有个settings按钮，点击它，向下拉到GitHub Pages，你会看到那边有个网址，访问它，你将会惊奇的发现该项目已经被部署到网络上，能够通过外网来访问它。 4、安装Hexo，在自己认为合适的地方创个文件夹，我是在D盘建了一个blog文件夹。然后通过命令行进入到该文件夹里面 输入npm install hexo -g，开始安装Hexo 输入hexo -v，检查hexo是否安装成功 输入hexo init，初始化该文件夹（有点漫长的等待。。。） 看到后面的“Start blogging with Hexo！”，激动有木有！！！！！ 输入npm install，安装所需要的组件 输入hexo g，首次体验Hexo 输入hexo s，开启服务器，访问该网址，正式体验Hexo问题：假如页面一直无法跳转，那么可能端口被占用了。此时我们ctrl+c停止服务器，接着输入“hexo server -p 端口号”来改变端口号 那么出现如下图就成功了 5、将Hexo与Github page联系起来，设置Git的user name和email（如果是第一次的话） 上图是在其文件夹里面鼠标右键，点击Git Base Here。这里“feng”可以替换成自己的用户名，邮箱可以替换成自己的邮箱 输入cd ~/.ssh，检查是否由.ssh的文件夹 输入ls，列出该文件下的内容。下图说明存在 输入ssh-keygen -t rsa -C “929762930@qq.com”，连续三个回车，生成密钥，最后得到了两个文件：id_rsa和id_rsa.pub（默认存储路径是：C:\Users\Administrator.ssh）。 输入eval “$(ssh-agent -s)”，添加密钥到ssh-agent 再输入ssh-add ~/.ssh/id_rsa，添加生成的SSH key到ssh-agent 登录Github，点击头像下的settings，添加ssh 新建一个new ssh key，将id_rsa.pub文件里的内容复制上去 输入ssh -T git@github.com，测试添加ssh是否成功。如果看到Hi后面是你的用户名，就说明成功了 问题：假如ssh-key配置失败，那么只要以下步骤就能完全解决 首先，清除所有的key-pairssh-add -Drm -r ~/.ssh删除你在github中的public-key 重新生成ssh密钥对ssh-keygen -t rsa -C “xxx@xxx.com“ 接下来正常操作在github上添加公钥public-key:1、首先在你的终端运行 xclip -sel c ~/.ssh/id_rsa.pub将公钥内容复制到剪切板2、在github上添加公钥时，直接复制即可3、保存 测试：在终端 ssh -T git@github.com 6、配置Deployment，在其文件夹中，找到_config.yml文件，修改repo值（在末尾） repo值是你在github项目里的ssh（右下角） 7、新建一篇博客，在cmd执行命令：hexo new post “博客名” 这时候在文件夹_posts目录下将会看到已经创建的文件 在生成以及部署文章之前，需要安装一个扩展：npm install hexo-deployer-git –save 使用编辑器编好文章，那么就可以使用命令：hexo d -g，生成以及部署了 部署成功后访问你的地址：http://用户名.github.io。那么将看到生成的文章]]></content>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【史上最全】国内外常用精品API汇总]]></title>
    <url>%2F2019%2F02%2F18%2F%E3%80%90%E5%8F%B2%E4%B8%8A%E6%9C%80%E5%85%A8%E3%80%91%E5%9B%BD%E5%86%85%E5%A4%96%E5%B8%B8%E7%94%A8%E7%B2%BE%E5%93%81API%E6%B1%87%E6%80%BB%2F</url>
    <content type="text"><![CDATA[【史上最全】国内外常用精品API汇总API是获取网络服务最便捷的方式，合理地使用API开发项目可以大大提高开发效率，把精力都集中在程序的业务逻辑之上，避免重复造轮子。推荐给大家个人觉得很赞的第三方API（资源整合自网络）。文章分为天气查询、生活常用、文体娱乐、企业金融、通讯服务、交通出行、技术开发七大类，如果你觉得分类不直观，想直接获取免费可试用的api，也可以直接搜索用友APILink，或访问官网api.yonyoucloud.com 一、天气查询天气查询应用的场景非常广，我猜很多人练手的第一个项目就是做天气查询类的demo。 全国天气预报 - 一个简单的HTTP接口，根据用户输入的adcode，查询目标区域当前/未来的天气情况。 使用API前需先申请Key。 AccuWeather - AccuWeather API 通过一个简单的 REST 风格的 Web 界面为订阅者提供基于位置的天气数据的访问. Aeris Weather - 驱动你的定制应用的先进 API, 为新鲜空气提供了从简到繁的解决方案. 彩云天气 - 中国天气信息. 和风天气 - 中国天气信息. Open Weather Map - Open Weather Map 服务提供免费的天气数据和预测 API, 适用于任何制图服务, 如网页和智能手机应用程序. Weather Underground - 可靠的数据, 准确的预测, 全球覆盖80种语言. Weather Unlocked - 电子广告商, 电子商务和开发人员的天气驱动方案. 心知天气 - 中国天气信息. Yandex.Weather - Yandex.Weather 使用专有的预测技术 Meteum 来评估俄罗斯地区特定地点的当前天气情况, 并为这些地理坐标创建预报. Yahoo! Weather - 获取任何位置的最新天气信息, 包括5天预报, 风, 大气, 天文条件等. 二、生活常用空气质量指数- 支持全国300多个城市的空气质量指数（AQI）查询，每小时更新一次，可查询到城市的首要污染物、空气质量的优良级别、指数颜色值等信息 全国医院信息查询- 可查询到国内各大医院的详细信息，包括医院所在的具体地址、医院类型、医院名称、医院等级、联系方式、重点科室、医院专家和医院简介等详细信息。 公交及站点查询-全国城市公交站点、线路、换乘查询。列车时刻表信息查询- 根据车次查询列车时刻信息，及各站里程；根据始发和终点站查询列车时刻信息，及各站里程 物流五级区域查询-最新全国省、市、县行政区域信息，未包括我国台湾省、香港特别行政区、澳门特别行政区 今日油价查询-提供今日油价查询。 支持查询全国各省市的今日油价，提供89号汽油、90号汽油、92号汽油、93号汽油、95号汽油、97号汽油、0号柴油的价格 新发地菜市场行情-提供北京新发地菜市场行情查询，输入菜品名称就可以查询到该菜品的最低价格、最高价格、平均价格、计量单位以及价格更新日期 全国高校信息查询-根据省份、城市、详细地址、大学名称可查询到符合条件的大学的基本信息，包括大学类别（比如理工类、综合类、财经类、艺术类等）、大学详细地址、学校级别（本科、专科）、联系方式、电子邮箱、site等信息。 谷歌日历 - Google Calendar API 可以让你将你的应用与 Google Calendar 集成, 为你吸引用户创造新的途径. Outlook Calendar - The Calendar API 提供了访问由 Office 365 中 Azure Active Directory 保护的事件, 日历, 日历组以及以下域中的特定 Microsoft 帐户中的类似数据: Hotmail.com, Live.com, MSN.com, Outlook.com 和 Passport.com. 外卖 百度外卖 - 支持商户，菜品，商品，订单和基础数据等内容，提供SDK和Demo。 大众点评 - 支持商户，团购，在线预定，商品点评，数据统计，元数据等内容。 饿了么 - 支持查询，预定，订单，其他订单，数据推送，支付，评价，活动，账户同步，数据落地同步等内容。 美团外卖 - 支持门店，配送范围，菜品，药品，订单，订单推送等内容。 其他 常见疾病查询；万年历查询；二十四节气查询；节假日查询；标准中文电码查询；BMI计算；区号查询；简繁体转换 三、文体娱乐博客 Blogger - Blogger API v3 版本允许你创建新的博客, 编辑或者删除已经存在的博客, 查询符合特定标准的博客. Medium - 访问 medium.com 的数据. s Weebly -借助 Weebly Cloud, 你可以提供 Weebly 的最佳网站构建方式, 使你的客户能够在几分钟内创建自己的网站, 博客或在线商店, 同时完全控制帐单, 支持和客户关系. WordPress - 访问 WordPress 的 API. Telegraph - 访问 Telegraph 的 API, Telegram 的 发布服务. 书籍 An API Of Ice And Fire - 冰与火之歌的 API 提供 JSON 格式的“冰与火之歌”宇宙中的所有书籍, 人物, 房屋的数据. 无需验证身份. Node 和 Swift 库可用. Open Library Books API - Open Library 是一个开放的, 可编辑的图书馆目录, 为每一本出版的图书都建立了网页. The New York Public Library Digital Collections API - 一个多世纪以来, 纽约公共图书馆已经积累了一系列罕见而独特的材料, 涵盖了所有有记录的知识. Bookshare - Bookshare API 使我们的合作伙伴能够使具有合格的阅读障碍的顾客搜索, 浏览和下载书籍和期刊. 杂志 豆瓣一刻(非官方) - 支持获取指定日期文章列表，栏目总览，推荐作者，作者信息，作者更多文章信息，栏目文章列表及翻页，文章评论及热门评论列表。 #非官方 开眼(非官方) - 支持获取未登录状态下开眼精选、发现、关注信息。 #非官方 One一个(非官方) - 支持获取首页图片，文章，音乐及电影。 #非官方 图虫(非官方) - 支持获取图虫 app 所有信息。 #非官方 一席(非官方) - 支持获取一席主页、演讲、讲者、枝桠等内容 #非官方 知乎日报(非官方) - 支持获取界面启动图像，软件版本查询，最新消息，消息内容获取与离线下载，过往消息，新闻额外消息，新闻对应长/短评论查看，主题日报列表，主题日报内容，热门消息，栏目总览，栏目具体消息，新闻的推荐者，某个专栏之前的新闻，Editor的主页等。 #非官方 知乎专栏(非官方) - 支持获取指定专栏的信息，指定专栏的文章列表，指定的文章内容，评论列表，点赞信息。 #非官方 新闻 &amp; 信息 BrewereyDB - BreweryDB 是一个包含啤酒厂, 啤酒, 啤酒活动和公会信息的数据库. Diigo - Diigo API 允许你构建与 Diigo 服务交互的应用程序. feedly - 访问 feedly 的 API. Genius - Genius API 帮助维基百科建立世界上最伟大的公共知识项目. goodreads - Goodreads API 允许开发人员访问 Goodreads 数据, 以帮助处理书籍的网站或应用程序更加个性化, 社交化和更具吸引力. HackerNews - 官方 HN API 的文档和示例. Inoreader - Inoreader API 允许你帮助用户订阅订阅源, 阅读文章或将其编目以供稍后查看. Instapaper - Instapaper API 允许第三方应用程序将 URL 添加到 Instapaper. Narro -访问文章和读物, 并代表客户提交. Newsblur - NewsBlur 的 API 允许用户获取摘要, 摘要数量, 摘要图标, 内容分析和独立的摘要故事. NPR - NPR 的 API 提供了一种灵活, 强大的方式来访问你最喜欢的 NPR 内容. Pinboard - Pinboard API 是一种以编程方式与书签, 笔记和其他 Pinboard 数据进行交互的方式. Pocket - 通过集成 Pocket API, 将『保存后使用』的功能带给用户和应用程序. Product Hunt - 访问 producthunt.com 的 API. 纽约时报 - 访问『纽约时报』的 API. 今日美国 - 访问来自『今日美国』的新闻和有趣的故事. 今日热闻API：包含以下十四个新闻频道，可以获得文章的内容和图片。 （头条、新闻、财经、体育、娱乐、军事、教育、科技、NBA、股票、星座、女性、健康、育儿。） 游戏 暴雪 - Battle.net 是一个在线电子游戏网站, 其特点是由暴雪娱乐开发的游戏集合. 可用的 Battle.net API 包括 D3, WoW, SC2, 社区 API 和游戏数据 API. 部落冲突 - 部落冲突 API 提供了接近实时的游戏相关数据. 星战前夜 - EVE Online 是最受欢迎的科幻大型多人在线角色扮演游戏（MMORPG）之一. EVE Online CREST 和 XML API 提供了对角色, 行业, 市场, Solar System, 联盟和企业以及其他游戏数据的编程访问. Facebook Games Services - Facebook Games Services 为游戏开发者提供了各种服务, 包括(但不限于) 成就 API, 分数 API, 应用通知, 请求, 游戏养成和 Facebook SDK for Unity. Google Play Games Services - Google Developers Games 网站提供了各种 API, SDK 和服务, 包括(但不限于)游戏发布 API, Unity 插件, Play 游戏服务(成就, 排行榜, 玩家统计等)和 Google AdMob. Riot Games - 为英雄联盟开发者社区提供安全可靠的游戏数据访问. Steam Web APIs - Steam Web API 允许开发人员向 Steam 查询他们可以在自己的网站上展示的信息. 目前我们提供的唯一 API 提供了 Team Fortress 2 的项目数据, 但是这个列表将随着时间的推移而增长. Giant Bomb - Giant Bomb API 提供了对 Giant Bomb 网站上的大量信息的程序化访问, 例如游戏名称, 评级, 视频, 公司, 主题, 流派等等。 笑话大全：https://www.apishop.net/#/api/detail/?productID=122 菜谱大全：https://www.apishop.net/#/api/detail/?productID=171 新华字典：https://apistore.eolinker.com/#/api/detail/?productID=98 NBA赛事：https://www.apishop.net/#/api/detail/?productID=125 周公解梦：https://www.apishop.net/#/api/detail/?productID=126 电视节目：https://www.apishop.net/#/api/detail/?productID=129 炉石传说卡牌：https://www.apishop.net/#/api/detail/?productID=203 万智牌卡牌：https://www.apishop.net/#/api/detail/?productID=204 绕口令：https://www.apishop.net/#/api/detail/?productID=127 健身 &amp; 可穿戴 Adidas AG - 访问 Adidas AG 的 API. Fitbit - Fitbit API 允许开发人员在自己的应用程序, 产品和服务中与 Fitbit 数据进行交互. Jawbone UP - 利用步数, 运动, 食物和睡眠跟踪的力量建立自己的产品和体验. Lifelog - 索尼的 Lifelog API使你可以安全地访问智能手机中的传感器和 SmartWear 设备收集到的用户的生活方式, 健身和健康数据. 利用它在你的应用程序或服务中创建的具有创造性的新用例. Misfit - 你现在可以利用一整套工具将 Misfit 的活动跟踪, 睡眠跟踪和可穿戴控制功能集成到你的产品和服务中. Nike+ - Nike Activity Services 会将用户活动汇总的详细信息返回给 Nike +. 例如, 用户的跑步细节, 如平均速度, 时间, 距离, 从他/她的 Nike + FuelBand 获得的 NikeFuel, 终身成就等等. Recon - 访问 Recon instruments 的数据. Strava - Strava V3 API 是一个公开可用的接口, 允许开发人员访问丰富的 Strava 数据集. Withings - Withings API 允许开发人员利用 Withings 设备和 Withings 记录的数据创建应用程序. 音乐 Deezer - Deezer 是一种基于网络的音乐流服务. 豆瓣音乐 - 允许访问豆瓣音乐的数据. 考拉FM - 允许访问考拉 FM 的数据. Last.fm - Last.fm API 允许任何人使用 Last.fm 数据创建他们自己的程序, 无论他们使用网络, 桌面还是移动设备上. MusicGraph - 由 Senzari 推出的 MusicGraph API 是世界上第一个音乐知识引擎, 它将作为一个功能强大的『图形 API』的方式提供, 开发人员可以利用它来利用强大的音乐智能来增强其应用. Musixmatch - 使用 Musixmatch API 将歌词带到你的应用程序中. One Music - One Music API 能够提供令人惊讶的音乐范围的元数据, 因为它汇集了现有的, 维护良好的在线数据库. 蜻蜓FM - 允许访问蜻蜓 FM 的数据. 企鹅FM - 允许访问企鹅 FM 的数据. SoundCloud - 允许用户在网络上上传和分享音乐. Spotify - Spotify 的 Web API 可让你的应用程序从 Spotify 音乐目录获取数据, 并管理用户的播放列表和保存的音乐. 视频 Dailymotion - Dailymotion 是全球第二大视频托管平台. 豆瓣电影 - 电影数据. Narrative - 自定义剪辑, 获取玩家, 徽章, 并与 Narrative API 一起玩耍. 爱奇艺 - 支持查询爱奇艺的数据. 乐视视频 - 允许查询, 上传, 下载等. Rotten Tomatoes - Rotten Tomatoes API 提供了获得 Rotten Tomatoes 的评分和评论, 允许获得批准的公司和个人用 Rotten Tomatoes 数据丰富他们的应用和小部件. 搜狐视频 - 允许查询数据. The Movie Database (TMDb) - The Movie Database 提供最受好评的电影, 即将到来的电影, 现在播放电影, 热门电影, 热门电视节目, 最受好评的电视节目, On the air 节目, Airing today TV shows, 热门人物等的接口. Vimeo - 最受创作者支持的网络社区, 可以获得高质量的工具, 用于在没有广告的情况下以华丽的高清格式托管, 分享和流式传输视频. Youtube - 将YouTube 的功能嵌入到你自己的网站和应用程序中. 优酷 - 允许上传, 下载, 登录等. 电影 豆瓣电影 - 豆瓣电影支持电影条目，影人条目，搜索和榜单等。 豆瓣电影(非官方) - 获取最近热映电影、短评、影评、图片等。 #非官方 猫眼电影(非官方) - 支持查询首页电影列表，电影详情(含评论)，本地影院和影院详情，选座。 #非官方 Time时光(非官方) - 支持获取时光网网站数据。 #非官方 V电影(非官方) - 支持获取V电影网站的数据。 #非官方 笔记 OneNote - OneNote支持获取，复制，创建，更新，导入与导出笔记，支持为笔记添加多媒体内容，管理权限等。提供SDK和Demo。 有道云笔记 -有道云笔记提供了Android SDK，同时Open API允许进行授权，用户，笔记本，笔记，分享，附件等方面的操作。 为知笔记 - 为知笔记Windows客户端开放了大量的API，其中绝大部分，都通过COM提供，可以在javascript, C#, C++, Delphi等语言中使用。接口通过IDL(Interface description language)语言描述。 印象笔记 - 印象笔记提供了ActionScript 3, Android, C++, Windows, iOS, Java, JavaScript, OS X, Perl, PHP, Python, Ruby等平台的SDK和完整的API参考文档， 翻译 百度翻译 - 支持多种语言之间的相互翻译. Google Translate - 支持动态地翻译上千种语言间的相互翻译. 金山词霸 - 支持简单的翻译功能. 金山词霸(非官方) - 金山词霸允许进行简单的翻译操作。 #非官方 Microsoft Translator - 支持多种语言的基于云的机器翻译服务, 可达到全球国内生产总值 (GDP) 的95％以上. 牛津词典 - 访问牛津词典的 API. 扇贝 - 提供了完整的 API, 支持查询, 添加学习记录, 写笔记等. Yandex Translate - 支持超过70种语言并且能够翻译单独的词语或完整的文本. 译云翻译 API - 支持几种语言之间的翻译. 有道翻译 - 支持简单的翻译操作. 有道词典(非官方) - 允许进行简单的翻译操作。 #非官方 必应词典 - 微软翻译API支持文字和语音两种类型，支持多种语言互相翻译，提供C#版本Demo。 必应词典(非官方) - 支持单词和语句翻译。 #非官 教育文化 成语大全：https://www.apishop.net/#/api/detail/?productID=93 新华字典：https://www.apishop.net/#/api/detail/?productID=98 汉语词典：https://www.apishop.net/#/api/detail/?productID=99 名言警句：https://www.apishop.net/#/api/detail/?productID=123 英语名言：https://www.apishop.net/#/api/detail/?productID=124 驾驶员从业资格题：https://www.apishop.net/#/api/detail/?productID=190 猫咪大全：https://www.apishop.net/#/api/detail/?productID=193 狗狗大全：https://www.apishop.net/#/api/detail/?productID=192 小型宠物大全：https://www.apishop.net/#/api/detail/?productID=195 水族宠物大全：https://www.apishop.net/#/api/detail/?productID=200 爬行类宠物大全：https://www.apishop.net/#/api/detail/?productID=201 植物大全：https://www.apishop.net/#/api/detail/?productID=199 旅游 携程 - 访问携程的数据. 艺龙 - 访问艺龙网的酒店和飞机票数据. 去哪儿 - 访问去哪儿网的酒店, 火车票, 飞机票和保险数据. 途牛 - 访问途牛的数据. 仅对供应商开放. 摄影 500px - 500px API 提供对 500px 功能和内容的编程访问. Giphy - 世界上最大的 GIF 图片库. Imgur - 使用 Imgur 的 RESTful API, 你可以做任何你能够在 imgur.com 网站做的事情. Pixabay - pixabay API 是一个 RESTful 接口, 用于搜索和检索 Creative Commons CC0 下发布的 Pixabay 图像和视频. Unsplash - 访问世界上最强大的图片引擎. Unsplash It - 使用来自 unsplash 的优美的占位图. Unsplash Resource - 一个用于嵌入 Unsplash 图片的简单 API. 社交 Disqus -Disqus 平台包含各种功能, 如社交整合, 社交网络, 用户档案, 垃圾邮件和审核工具, 分析, 电子邮件通知和移动评论. 豆瓣 - 访问图书, 电影, 音乐, 广播等内容. Facebook - Facebook是一家美国营利性公司, 也是一家在线社交媒体和社交网络服务公司. Flickr - 几乎是世界上最好的在线照片管理和共享的应用. Foursquare - Foursquare API 让你可以访问我们的世界级的地点数据库, 并且可以与 Foursquare 用户和商家进行互动. Instagram - 与朋友和家人用一种简单有趣并有创造性的方式来捕捉, 编辑, 分享照片, 视频和信息. LinkedIn - 世界上最大的专业网络平台. Pinterest - Pinterest API 使你能够访问用户的 Pinterest 数据, 喜欢他们的信息流, Pins, 关注者等. Reddit - Reddit 是一个美国社交新闻聚合, 网上内容评分, 和讨论的网站. Tumblr - Tumblr 是一个表达自我, 发现自我, 并与你喜爱的东西紧密相连的地方. Twitter - 访问 Twitter 的数据. 微博 - 访问微博, 用户, 评论, 收藏等内容. 四、企业金融Yelp - 访问 Yelp 的 API. Zomato - Zomato API 使你能够访问全球10000个城市超过150万家餐厅的最新, 最详尽的信息. 购物 Amazon - 访问Amazon 的 API. Best Buy -访问 Best Buy 的 APIs. 当当 - 访问当当网的 API. eBay - 访问 eBay 的 API. Home Depot - 访问 Home Depot 的API. 京东 - 访问京东的 API. Semantics3 - 访问 Semantics3 的 RESTful API. Slice - 访问 Slice 的 REST API. 淘宝 - 访问淘宝的 API. 电商 当当 - 当当允许商家用户和网站接入授权，可进行商品，订单，图片，问答，店铺和促销等方面的操作。 京东 - 京东提供了Java, PHP, .net的SDK，授权后可进行多种操作。 苏宁开放服务 - 苏宁提供了Java, PHP, .Net, Python版本的SDK，授权后可进行多种操作。 淘宝开放平台 - 淘宝提供了Java, .Net, PHP, Python版本的SDK，授权后提供多种操作。 亚马逊 - 亚马逊提供多种语言版本的SDK，授权后允许多种操作。 电商通 – 用友电商通对接淘宝、苏宁、京东、1号店API 支付 PayPal - 访问 PayPal REST API. Paymill - 访问完整的 API 参考, 获得你需要知道引入 PAYMILL 相关的任何信息。 Paytm - 访问你需要使用的 API 的详细信息, 使用 Paytm Wallet 在你的应用/网站上进行付款, 并处理与付款相关的操作问题(例如: 退款, 交易状态检查). WePay - WePay 专为平台, 如市场, 众筹网站和小型商业工具而设计. 可获得无缝的用户体验和防欺诈保护. 金融服务 汇率查询：提供币种查询、汇率转换、中国银行汇率查询、十大银行实时汇率查询 银行网点及联行号查询：支持72家银行网点相关信息查询 股票预期共识数据：覆盖了几乎所有券商机构的分析报告，分别计算了各个券商机构相同股票净利润、EPS、营业利润、营业收入预测值的简单平均值，并将机构和时间的量化后再进行加权计算分别得到了其最终的预测数据值。 金属矿产_现货价格：金属矿产现货价格动态详情 虚拟货币交易行情、区块链今日快讯 企业服务 企业工商信息查询：提供企业工商信息查询功能，主要查询企业的企业名称、统一社会信用代码、工商注册号、注册地址、营业状态、企业类型、注册时间、法人、注册资金、经营期限、注册机构、行业、经营范围、官网、邮箱、电话、税号等数据。 企业开票税号查询：可以查到公司纳税人识别号、注册地址等开发票需要的详细信息。 上市企业查询：查询新三板、上海A股、上海B股、深圳A股、深圳B股企业信息，根据关键字查询上市公司信息。 全国五级行政区划查询：最新全国省、市、县行政区域信息，未包括我国台湾省、香港特别行政区、澳门特别行政区。 实名认证 手机号三要素实名认证：手机号、姓名和身份证号，认证信息是否匹配。数据来自公安部，实时核查，比较靠谱的接口 身份证二要素实名认证：快速验证姓名与身份证号的真实性和一致性 识别图片身份证信息：从身份证图片中识别出身份证信息 银行卡三要素实名认证：银行卡号、持卡人姓名、持卡人身份证号，验证此三种信息是否一致，可快速校验个人身份信息，数据来自公安部和银联中心 图片与图像处理 别样网 - 无版权免费大尺寸图片共享平台。 Camera360 - 支持全帧率直播美白滤镜，提供SDK和Demo。 嗨图 - 支持图片标注，仅提供iOS版本SDK。 名片全能王 - 支持精准识别几十种语言的名片，自动切边并美化名片图像，自动返回识别结果，提供多种版本SDK，收费。 pixabay - 在所有的图像和视频Pixabay释放自由版权下创作共用CC0。你可以下载、修改、分发，并使用它们在任何你喜欢的任何东西，即使在商业应用程序中使用它们。不需要归属权。 企业证件识别 - 支持身份证，驾驶证，护照等，收费。 扫描全能王 - 支持图像智能剪裁，五种图像增强模式，手动调节图像细节，自动返回扫描结果等，提供iOS与Android版本SDK，收费。 我知图 - 支持相似图像搜索，图像识别匹配，图像识别关键词推荐，重复图片探测等内容。 图片隐写术-图片版权保护API，图片水印加密技术，处理后的图片看上去没有任何变化，但是实际上图片已经拥有了自己的唯一标识 工作 Airtable - Airtable Standard API 允许你创建, 读取, 更新和销毁记录. Buffer - The Buffer API 提供了访问用户的待发送和已发送的更新内容, 社交媒体资料, 定时访问和更多内容. Concur Labs - 访问 Concur 的 RESTful API. Envoy - 访问 Envoy 的 API. JotForm - JotForm API 可以在不使用JotForm 网站的情况下连接到你的表单数据. MailChimp - 访问 MailChimp 的 API. Pruvan - 访问 Pruvan 的 API. Quip - Quip REST API 让你实现流程自动化, 并将Quip 与你或你公司使用的其他产品集成在一起. Salesforce - 访问 Salesforce 的 API. Square - Square 提供简单的信用卡处理和针对各类业务的完整解决方案. Wolfram Data Drop - 访问 Wolfram Data Drop 的 RESTful API. 五、通讯服务 短信API 在各大网站或APP，用户注册、修改密码等涉及到个人隐私的操作时，都离不开短信验证码。 平时也收到不少的商家促销短信、还有通知短信等等，这些都可以通过短信服务的API实现。 短信API ：短信验证码、通知短信等；支持虚拟运营商号段，保证短信发送不间断 短信API接口【营销类】：适用于产品推广、活动宣传等营销类使用场景 短信API接口【金融类】：适用于金融行业产品营销、客户关怀、投资提醒等场景 语音验证码：通过电话获取语音验证码，杜绝恶意注册，确保用户真实性。适用于用户注册、手机绑定、安全登录、身份验证、找回密码、支付认证等场景 IP地址、域名查询：可查询到IP地址、域名的地理位置。地理位置精确到省、市、区。手机号归属地：能根据手机号查询到手机号所在的省份和城市、该手机号属于哪种运营商，是移动，电信或者联通，该手机号码所在地区的身份证号前几位，例如，云南昆明的身份证号前几位为：530000。 邮编查询：查询该地区的邮政编码。 邮件 Context.IO - Context.IO 是一个现代的, 可扩展的电子邮件 API, 简化了电子邮件数据的处理. Gmail - 现代, 简单, 快速, RESTful. Inbox - Inbox 提供了用于与邮件提供商合作的现代 RESTful API. 停止与旧的协议角力, 专注于构建伟大的应用程序. Mandrill - Mandrill 就像 MailChimp, 适用于应用程序. 发送交易性的, 易于触发和个性化的电子邮件, 然后跟踪结果. Outlook Mail - Outlook Mail API允许你阅读, 创建和发送消息和附件, 查看和响应事件消息, 以及管理由 Office 365中的 Azure Active Directory 保护的文件夹. 它还在 Microsoft 帐户中专门提供了与这些域中相同的功能: Hotmail.com, Live.com, MSN.com, Outlook.com 和 Passport.com. 通信 Cisco Spark - 创建一个房间, 邀请他人, 搜索公司里的人, 将信息发布到一个房间, 获取房间历史记录, 或者在他人发布新信息时实时通知他们. Dingtalk - 访问 Dingtalk 的 API. dondeEsta Family - 访问 dondeEsta family 的 API. Fleep - Fleep是所有团队和项目的使者. GroupMe - GroupMe API 使你能够使用群组消息传递功能来增强现有的应用程序, 创建有趣的新体验, 或者只是为现有的群组添加一些调味品. indoona - 基于 HTTPS 的 The indoona RESTful API 使你能够: 给 indoona 用户和群组发送信息, 创建特定的联系人地址簿使 indoona 用户能够与你的应用聊天. LINE - LINE是一款免费应用, 用于在智能手机, 平板电脑和个人电脑等电子设备上进行即时通讯. MessageBird - MessageBird API 将你的网站或应用程序连接到世界各地的运营商. 使用API, 你可以集成短信, 聊天和语音. Slack - Slack是基于云的专有团队协作工具和服务. Telegram - The Bot API 允许你轻松创建使用 Telegram 消息作为接口的应用. The Telegram API 允许你建立自己的定制 Telegram 客户端. Yo - Yo 是最简单的通知平台. 消息推送 百度云推送 - 支持iOS, Android和服务器端，支持推送，统计，组管理等Rest API接口。服务器端支持Java, Python, PHP, REST API。提供所支持各语言版本的SDK。 华为推送 - 支持Android，提供SDK。 极光 - 支持Android, iOS, WindowsPhone, 服务器端REST API, 提供Java, Python, PHP, Ruby, C#, Node.js等版本的SDK。 LeanCloud - 支持Android, iOS, WindowsPhone和Web网页推送，使用云引擎和JavaScript创建推送，使用REST API推送消息。提供Objectvie-C(开放源码), JavaScript(开放源码), Android, Unity, .Net, WindowsPhone, Java(开放源码), Python(开放源码), PHP(开放源码), C++(开放源码), Swift(开放源码)版本SDK。同时提供Demo。 腾讯信鸽 - 支持iOS和Android平台，服务器端采用Rest API, 同时服务器端支持Java, PHP, Python等语言并提供SDK。 小米 - 支持Android和iOS平台，服务器端支持Java, Python并提供SDK。 友盟 - 支持Android和iOS平台，服务器端支持PHP, Java, Python并提供SDK。 六、交通出行快递查询 Trackingmore - Trackingmore目前支持400多家国内外快递商，免费版有使用次数限制。 全国快递物流查询 - 提供包括申通、顺丰、圆通、韵达、中通、汇通等国内快递公司在内的百家快递物流单号查询，免费版有使用次数限制。 AfterShip - 支持超过200家物流公司的物流跟踪和通知. Aramex - 通过全球物流提供商网络提供包裹, 快递和货运服务. Canada Post - 允许电子商务解决方案提供商和在线商家将加拿大邮政服务(如邮寄,评级和跟踪数据)整合到平台或网站中. DHL - DHL XML 服务为开发者提供了整合 DHL 来自140多个国家的服务可用性, 运输时间, 费率, 物流跟踪以及更多功能的能力. FedEx - FedEx 网络服务允许企业将 FedEx 的运输功能集成到他们现有的仓库管理系统中, 无需现场托管。 UPS - 提供了将 UPS 的运输功能集成到网站和企业应用程序的能力. 出行服务 公交及站点查询：https://apistore.eolinker.com/#/api/detail/?productID=77 经纬度地址转换：https://apistore.eolinker.com/#/api/detail/?productID=78 中国省市区查询：https://apistore.eolinker.com/#/api/detail/?productID=75 全国油价查询：https://apistore.eolinker.com/#/api/detail/?productID=82 POI检索：https://apistore.eolinker.com/#/api/detail/?productID=97 公交、地铁路线规划查询：https://apistore.eolinker.com/#/api/detail/?productID=105 车型大全：https://apistore.eolinker.com/#/api/detail/?productID=117 火车票查询：https://www.apishop.net/#/api/detail/?productID=91 长途汽车查询：https://www.apishop.net/#/api/detail/?productID=100 汽车尾号限行：https://www.apishop.net/#/api/detail/?productID=194 驾考题库：https://www.apishop.net/#/api/detail/?productID=187 共享汽车 Lyft - 允许访问实时 ETA, 可用性, 价格估计, 乘坐状态等数据. 神州租车 - 来自中国的共享汽车公司. Uber - 允许定制旅行体验, 请求出行, 后勤保障, 创建机器人等等. 滴滴 - 滴滴提供了iOS和Android SDK, 可实现拉起滴滴叫车等方面的操作。 地图 百度地图 - 百度地图提供了Android, iOS版本的SDK和JavaScript API，可进行定位、地图、数据、出行、鹰眼轨迹和分析服务。 高德地图 - 高德地图提供了JavaScript和web服务API，Android和iOS SDK，支持地图，定位，搜索，路线规划，导航和室内地图等。 腾讯地图 - 腾讯地图提供了JavaScript API，Android和iOS SDK，支持定位，地图，地点搜索，路线和导航等。 天地图 - 天地图提供了H5 API和JavaScript API等web API，同时提供了Android和iOS SDK，支持基础地图服务，图层管理，地图覆盖物，地图工具，地名搜索和出行规划服务。 图吧地图 - 图吧提供了JavaScript和Flash API，Android和iOS SDK，支持定位，地址解析，位置标注，位置截图，路线规划，周边查询，兴趣点搜索和在线导航。 地图 高德地图 - 访问高德地图的 Web API. 百度地图 - 访问百度地图的 Web API. 必应地图 - 访问必应地图的 API. Google Maps - Google Maps web Service 是一个 Google 服务的 HTTP 接口集合, 为你的地图应用程序提供地理数据. Here Maps - 使用简单的 HTTP GET 方法提供地图, 路由, 地理编码, 地点, 定位, 交通, 过境和天气信息. 腾讯地图 - 访问腾讯地图的 WebService API. 即时通讯 环信 - 支持Android, iOS, WebIM, Linux, REST集成，支持多种消息类型。 融云 - 支持Android, iOS, Web, 游戏集成，支持多种消息类型。 网易云信 - 支持IM实时通讯，实时音视频，教学白班，专线电话，短信，聊天室，提供iOS, Android, Windows和Web SDK。 腾讯云通信IM - 提供iOS, Android, Windows和Web SDK，支持多种消息类型。 旅游 12306(非官方) - 支持获取12306火车票票数、票价查询。 #非官方 去哪儿 - 支持获取去哪儿网的内容。 途牛 - 支持途牛网的内容，仅开放给供应商系统。 途牛火车票(非官方) - 支持获取途牛火车票票数、票价查询。 #非官方 携程 - 支持携程网的内容。 艺龙 - 支持获取产品数据，完成用户的预订，进行订单查询、更改或取消。提供在线工具，以及H5, Java, C#, PHP, Ruby版本的Demo。 七、技术开发用友云 阿里云 百度云 Bmob Google Cloud Platform LeanCloud Oracle Cloud 七牛 腾讯云 云存储 Amazon Cloud Drive - 借助 Amazon Cloud Drive 最新的 RESTful API 和 Android 与 iOS SDK, Amazon Drive 正转向为受邀的开发者提供服务, 以确保他们能够为其所支持的使用案例提供始终如一的可用云盘服务。 Box - 支持搜索, 元数据, 粒度权限模型, 企业级安全, 保留策略, 120种类型的文件预览功能. Digital Ocean - 在55秒内部署SSD云服务器. Document Cloud - DocumentCloud 运行在你通过 OpenCalais 上传的每一份文件中, 为你提供有关人员, 地点和组织的广泛信息. Dropbox - 为和文件相关的应用提供了一个强大的 API. Google Drive- Google Drive API 允许你从移动设备和网络应用中读取, 写入和同步存储在 Google Drive 中的文件. OneDrive - 访问 OneDrive 中的文件. QNAP - 借助 QNAP 开发工具包(API 和 SDK), 开发人员可以设计能在客户端设备(如智能手机或 PC)上运行的应用, 并远程管理和访问存储在NAS上的文件和文档。 Verizon Cloud - 上传, 检索和管理大量数据, 通过 API 调用访问数据, 查看预先打包的报告, 依靠 Verizon 的安全措施保证数据安全和随时可用. 开发者网站 Coding - 授权后可访问http://coding.net网站的内容。 干货集中营 - 提供妹子图和Android, iOS, 前端，拓展资源等内容。 diycode - 授权后可访问diycode网站的内容。 开源中国 - 授权后可访问开源中国网站的内容。 Laravel China - 授权后可访问 Laravel China 网站的内容。 Ruby China - 授权后可访问Ruby China网站的内容。 V2EX - 可访问V2EX网站的内容。 开发工具 四位图片验证码生成：https://www.apishop.net/#/api/detail/?productID=102 六位图片验证码生成：https://www.apishop.net/#/api/detail/?productID=101 中文分词：https://www.apishop.net/#/api/detail/?productID=120 二维码编解码：https://www.apishop.net/#/api/detail/?productID=128 网站排名查询：https://www.apishop.net/#/api/detail/?productID=214 设计 Dribbble - 访问 Bucket, 项目, 作品, 团队, 用户和工作等数据. Behance - 获取项目, 可关注的广告素材, 创意领域, 用户, 收藏等信息. deviantART - 允许获取 deviantart.com 的数据. 开发 ARTIK Cloud - ARTIK Cloud API 提供访问 ARTIK Cloud 平台的数据. AT&amp;T M2X - M2X 的 RESTful API 简化了设备和 M2X 服务之间的连接, 使你能够构建利用时间序列数据分析和分布式的高可用性时间序列数据存储的应用程序和服务, 为你的客户和最终用户提供有意义的信息, 并构建物联网和 M2M 解决方案, 而无需管理自己的存储基础架构. Bitbucket - Bitbucket 是一个基于 Web 的托管服务, 由 Atlassian 拥有, 用于使用 Mercurial 或 Git 版本控制系统的源代码和开发项目. bitly - bitly是一种最简单, 最有趣的方式来保存, 分享和发现来自网络的链接. Buddy - Buddy 是一个持续集成服务. 它支持 GitHub, Bitbucket 和 Gitlab 项目. 自动化 Web 和 Docker 应用程序的生命周期: 构建, 测试和部署. Bugzilla - Bugzilla 是一个基于 Web 的通用的错误追踪器和测试工具, 最初由 Mozilla 项目开发和使用, 并在 Mozilla Public License 下获得许可. CircleCI - CircleCI API 是一个 RESTful, 全功能的 API, 允许你访问所有信息并触发 CircleCI 中的所有操作. Coding - 访问 https://coding.net/ 的 API. diycode - 访问 https://www.diycode.cc/ 的 API. 干活集中营 - 访问 http://gank.io/ 的 API. GitHub - 世界上领先的软件开发平台. Gitter - GitHub 的聊天工具. GitLab - 通过一个简单而强大的 API 自动化 GitLab. Google Play Developer - Google Play Developer API 允许你执行大量的发布和应用程序管理任务。 IPInfo.io - 使用ipinfo.io IP查找API快速简单地将IP地理位置集成到你的脚本或网站。 Laravel China - 访问 https://laravel-china.org/ 的 API. openHAB - openHAB 的 REST API 服务于不同的目标. 它可用于将 openHAB 与其他系统集成, 因为它允许读取项目和项目状态以及状态更新或发送项目命令. 此外, 它还提供对站点地图的访问, 因此它是远程用户界面(例如胖客户端或完全基于 Javascript 的 Web 客户端)使用的接口. 开源中国 - 访问 https://oschina.net/ 的 API. Particle - Particle Cloud API 是一个 REST API. QR Code Generator - 你可以使用 QR 码生成器 Web API 在 api.qrserver.com 上生成和解码/读取 QR 码图形. Ruby China - 访问 https://ruby-china.org/ 的 API. StackExchange 访问 Stack Exchange API. SVN - 文档涵盖了 Subversion 库提供的公共 API. 它主要面向程序员, 无论是从事 Subversion 本身的开发人员, 还是希望使用这些 API 的第三方应用程序开发人员. TravisCI - 这是官方 Travis CI Web 界面使用的 API, 因此 web 界面所能做的所有事情都可以通过 API 完成. V2EX - 访问 https://www.v2ex.com/ 的 API. W3C - 作为对 W3C 社区的开发人员要求与 W3C 的数据进行交互的要求的相应, W3C Systems 团队开发了一个 Web API. 通过它, 规格, 群组, 组织和用户的数据变得可用. W3C API 是基于 JSON 格式的仅针对公开数据的只读 Web API. ZenHub - ZenHub 是唯一的原生集成在 GitHub 接口中的项目管理工具. 物联网 Automatic - 为和 Automatic 数据交互提供了 REST API, 实时事件 API 和 流式 API. Amazon Alexa - 利用 Alexa Voice Service API, 开发人员可以通过话筒和扬声器为连接的产品提供语音功能. Google Assistant - Actions on Google 允许你为 Google Assistant 创建应用. Home8 - 100％无线物联网系统, Home8 简化了智能报警系统的 DIY 安装, 同时为你提供最佳的视频认证报警保护. Homey - 访问 Homey 的 API. HP Print - 访问 HP Print 的 API. LIFX - LIFX 是一款多色智能 WiFi LED 灯泡. LIFX HTTP API 允许你通过互联网控制 LIFX 设备, 并且是与 LIFX 设备交互的REST API. LightwaveRF - 该 API 概述了 LightwaveRF 系统当前正在使用的本地命令协议. microBees - 轻松执行 REST API 并订阅实时消息. Mojio - 使用 REST 节点进行请求和响应类型集成, 使用 PUSH API 来实时推送数据. myStrom - myStrom WLAN Energy Control Switch 提供了一个 REST API, 允许你从 myStrom 独立的本地网络直接访问/控制交换机. Neurio - Neurio 是一个带有公共 API 的开放平台, 所以你可以任意扩展它. 将其连接到 Web 服务, 或编写自己的应用程序. Philips Hue - 飞利浦的 Hue 连接的灯泡和桥接器让你能够完全控制你的照明. Smappee - 使用 Smappee 的 API, 可以帮助你测量电能消耗和太阳能生产量. SmartThins - 访问 SmartThings 的 API. Stack Lighting - Stack API 是一个 REST API, 它定义了一组允许开发人员执行请求并通过 HTTP 协议接收响应的函数. 该 API 为开发人员提供了控制亮度, 色温, 运动设置, 环境光线感应设置以及其他功能的功能, 以根据个人喜好调整 Stack 响应式照明. Vinli - Vinli 是一个用于简单快速地构建车联网应用的平台. Yeelight - Yeelight 智能 LED 产品支持通过 WiFi 远程控制. 机器学习 Amazon Machine Learning - Amazon Machine Learning 使开发人员可以轻松构建智能应用程序, 包括欺诈检测, 需求预测, 有针对性的市场营销和点击预测等. BigML - BigML 平台具有异常检测, 聚类分析, 用于决策树的 SunBurst 可视化, 文本分析等功能. Diffbot - Diffbot 平台利用 AI, 计算机视觉, 机器学习和自然语言处理的组合, 自动从网页(如文本, 图像, 视频, 产品信息和评论)提取数据. Google Cloud Prediction - Google Cloud Prediction API 提供了一个 RESTful API 来构建机器学习模型. Prediction 的基于云的机器学习工具可以帮助你分析数据, 为你的应用程序添加各种功能, 如客户情绪分析, 垃圾邮件检测, 推荐系统等. IBM Watson - 允许开发人员构建利用机器学习技术的应用程序, 如自然语言处理, 计算机视觉和预测. Microsoft Azure Machine Learning - Microsoft Azure 机器学习平台提供自然语言处理, 推荐引擎, 模式识别, 计算机视觉和预测建模等功能. 图灵聊天机器人：http://doc.tuling123.com/openapi2/263611 团队协作 Asana - 允许你以编程方式更新和访问平台上的大部分数据. join.me - join.me 是一个在线会议工具, 让人们可以一起完成伟大的事情. Teambition - Teambition 的 Open Platform 提供用于获取数据的完整开放 API 集. 根据项目数据构建应用程序将充分利用你的协作数据, 如项目跟踪, 数据挖掘等. TeamSnap - 使用世界上最好的团队管理解决方案来支持你的用户. Trello - Trello 是一个基于 Web的项目管理应用程序. Worktile - 访问 Worktile 的 API. 文本分析 BosonNLP - 中文文本分析. 腾讯文智 - 中文文本分析. Text Analytics API - The Text Analytics API 是一套文本分析 Web 服务, 使用最佳的 Microsoft 机器学习算法构建. Watson Natural Language Understanding - Watson 的 Natural Language Understanding 使用自然语言处理来分析任何文本的语义特征. 待办 Beeminder - 访问 Beeminder 的 API. FollowUp.cc - 访问 FollowUp.cc 的 API. Todoist - Todoist API (也称为『Sync API』) 专门用于客户端(例如移动应用程序)和 Todoist 之间的高效数据同步. Toodledo - Toodledo API 可以自由使用, 并提供对用户的任务, 笔记, 大纲和列表的访问. 语音分析 百度语音 - 访问百度的语音分析 REST API. Cloud Speech API - Google Cloud Speech API 使开发人员能够通过在易于使用的 API 中应用强大的神经网络模型, 将音频转换为文本. 语义识别 BosonNLP玻森 - 支持REST API并提供Python SDK。 腾讯文智 - 支持词法类，句法类，篇章类，下载类API，目前平台能识别类别囊括了求职招聘、影视、音乐、健康养生、财经、广告推广、犯罪、政治等90多个类别，且算法支持快速迭代更新已有类别及增加新类别。提供Python SDK。 语音识别 百度语音 - 支持全平台REST API, 离线在线融合模式，深度语义解析，场景识别定制，自定义上传语料、训练模型，基础服务永久免费。提供相应SDK和Demo应用。 搜狗语音云开放平台 - 支持在线/离线语音识别，在线听歌识曲，离线语音合成等内容。提供相应平台SDK。 讯飞开放平台 - 支持语音听写/转写，在线/离线命令词识别，语音唤醒等内容，平台支持广泛，提供相应SDK。 人工智能 百度AI开放平台：涵盖图像处理、自然语言、语音技术、知识图谱、数据智能、AR、视频技术和深度学习八大方面。看需选择即可。 人脸识别Face++ 注：申请试用的API Key可以免费 OCR-身份证识别：https://www.apishop.net/#/api/detail/?productID=186 OCR-营业执照识别：https://www.apishop.net/#/api/detail/?productID=196 OCR-行驶证识别：https://www.apishop.net/#/api/detail/?productID=197 银行卡识别：验证身份真实性 名片识别：https://www.apishop.net/#/api/detail/?productID=206 车牌识别：https://www.apishop.net/#/api/detail/?productID=207 《机动车合格证》二维码解码：https://www.apishop.net/#/api/detail/?productID=216 综合 用友APILink- 提供中国可用的API，金融企业和生活相关，支持免费试用。 阿里大于 - 提供中国可用的 API . Amazon Developer - 允许构建有关 Amazon 的应用与游戏, Alexa, AWS, Amazon 服务与 API 以及 Amazon 设备的软件。 APiX - 提供中国可用的信用相关的 API. 阿凡达数据 - 提供中国可用的 API . 百度API STORE - 提供中国可用的 API . Google API Library - Google API Library 包含100多个 API, 例如 Google Cloud API, Google Maps API, Google Apps API, 移动 API, 社交媒体 API, Youtube API, 广告 API 以及其他受欢迎的 API. HaoService - 提供中国可用的 API . iTunes Search API - 允许在网站中放置搜索字段以搜索 iTunes Store, App Store, iBooks Store 和 Mac App Store 中的内容. Microsoft Developer - 访问 Microsoft 的公共 API. ProgrammableWeb - 关于 API 的新闻和信息的主要来源, 记录全球 API 经济的发展, 提供网络最依赖的 API 目录. Yahoo! Developer Network - Yahoo Developer Network 为开发者提供了用于简化构建, 宣传, 增强应用的API 和 工具. 和 Yahoo 一起赚钱]]></content>
      <tags>
        <tag>API</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql表设计的常用类型]]></title>
    <url>%2F2019%2F02%2F18%2Fmysql%E8%A1%A8%E8%AE%BE%E8%AE%A1%E7%9A%84%E5%B8%B8%E7%94%A8%E7%B1%BB%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[目录 整数类型，tinyint、smallint、mediumint、int、bigint 实数类型，float、double 字符串类型，varhcar、char 时间类型，datetime、timestamp 1. 整数类型，tinyint、smallint、mediumint、int、bigint如果需要保存整数（不含小数），可以选择tinyint、smallint、mediumint、int、bigint，它们的范围如下图： 另外，一些小知识： 整形的计算是使用64位的bigint进行计算的如果为整形指定长度，并不会限制其大小范围，只是影响显示，其存储与计算与其它长度的整形一致 2. 实数类型，float、double如果仅为了存储，不作精确的计算，可用float和double，它们的计算结果并不是精确的，只是近似计算，是CPU直接的原生浮点计算，效率比较高，但不精确。 如果需要精确计算，则可以用decimal，但存储成本和计算成本比float和double高。 3. 字符串类型，varhcar、char它们的主要区别在于varhcar是变长的，char是定长的。 在记录的字符串长度不一，或最大的字符串长度大于字符串平均长度时，使用varchar非常合适记录可知的定长的字符串，用char就合适了 4. 时间类型，datetime、timestampdatetime将时间数据年月日时分秒内部存储为整数类型，它需要8字节的空间。timestamp记录GTM 2017-01-01至今的秒数，使用4字节的空间。它的缺点是时间范围只能到2038年，另外，它依赖与时区，时区的变更会使时间变得不同。timestamp更小，但有缺点，主要取决于这些缺点是否影响到你的程序。另外，使用timestamp需注意一点是，我在使用工具创建一个表时，创建时没有特别设置“默认值”、“非空”、“更新”等属性，但timestamp会设置“默认值”为“CURRENT_TIMESTAMP”，“非空”，和“自动更新”。（究竟是工具的行为还是MySQL的行为我没有考究，大家引起注意这点，不要因此导致业务异常）：]]></content>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python3_time.sleep用法]]></title>
    <url>%2F2019%2F02%2F18%2Fpython3-time-sleep%E7%94%A8%E6%B3%95%2F</url>
    <content type="text"><![CDATA[sleep() 方法暂停给定秒数后执行程序。该参数可以是一个浮点数来表示一个更精确的睡眠时间。实际中止时间可能不到所请求的，因为任何捕获信号将终止 sleep()接下来执行该信号捕捉的程序。语法 以下是sleep()方法的语法：time.sleep(t)参数 t – 这是要暂停执行的秒数。 返回值此方法不返回任何值。示例 下面的示例说明 sleep()方法的使用。#!/usr/bin/python3import time print (“Start : %s” % time.ctime())time.sleep( 5 )print (“End : %s” % time.ctime()) 当我们运行上面的程序，它会产生以下结果：Start : Mon Feb 15 12:08:42 2016End : Mon Feb 15 12:08:47 2016]]></content>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何区分静态和动态网页]]></title>
    <url>%2F2019%2F02%2F18%2F%E5%A6%82%E4%BD%95%E5%8C%BA%E5%88%86%E9%9D%99%E6%80%81%E5%92%8C%E5%8A%A8%E6%80%81%E7%BD%91%E9%A1%B5%2F</url>
    <content type="text"><![CDATA[静态页面，动态页面主要根据页面制作的语言来区分： 静态页面运用语言：HTML（超文本符号语言）或XML（可扩展符号语言） 动态页面运用语言：HTML＋ASP 或HTML+ASP.NET或 HTML＋PHP 或 HTML＋JSP 等。 静态页面与动态的区别 程序是否在服务器端运转，是重要标志。在服务器端运转的程序、页面、组件，属于动态页面，它们会随不同客户、不同时间，返回不同的页面，例如ASP、PHP、JSP、ASP.net、CGI等。运转于客户端的程序、页面、插件、组件，属于静态页面，例如html页、Flash、JavaScript、VBScript等等，它们是永久不变的。 静态页面和动态页面各有特点，网站选用动态页面还是静态页面主要取决于网站的功能需求和网站内容的多少，如果网站功能比较简单，内容更新量不是很大，选用纯静态页面的方法会更简单，反之通常要选用动态页面技能来完成。 静态页面是网站建设的基础，静态页面和动态页面之间也并不矛盾，为了网站适应搜索引擎检索的需求，即使选用动态网站技能，也可以将页面内容转化为静态页面发布。 网站设计中，纯粹HTML格式的页面通常被称为“静态页面”，早期的网站通常都是由静态页面制作的。 ### 静态页面的网址方式通常为： 也就是以.htm、.html、.shtml、.xml等为后后缀的。在HTML格式的页面上，也可以出现各种动态的效果，如.GIF格式的动画、FLASH、翻滚字母等，这些“动态效果”仅仅视觉上的，与下面将要介绍的动态页面是不同的概念。 我们将静态页面的特点简要归纳如下： （1）静态页面每个页面都有一个固定的URL，且页面URL以.htm、.html、.shtml等常见方式为后缀，而不含有“？”； （2）页面内容一经发布到网站服务器上，无论是否有用户访问，每个静态页面的内容都是保存在网站服务器上的，也就是说，静态页面是实实在在保存在服务器上的文件，每个页面都是一个独立的文件； （3）静态页面的内容相对稳定，因此容易被搜索引擎检索； （4）静态页面没有数据库的支持，在网站制作和维护方面工作量较大，因此当网站信息量很大时完全依靠静态页面制作方法比较困难； （5）静态页面的交互性穿插，在功能方面有较大的限制 好像看懂了,第一看后缀名,第二看是否能与服务器发作交互行为 静态页面是相对于动态页面而言，是指没有后台数据库、不含程序和不行交互的页面。你编的是什么它显现的就是什么、不会有任何改动。 静态页面相对更新起来比较费事，适用于通常更新较少的展示型网站。另外,如果扩展名为.asp但却没有连数据库,完全是静态的页面,那也是静态网站.仅仅.asp扩展名。 动态页面的通常特点简要归纳如下： （1）动态页面以数据库技能为基础，可以大大下降网站维护的工作量； （2）选用动态页面技能的网站可以完成更多的功能，如用户注册、用户登录、在线调查、用户管理、订单管理等等； (3）动态页面实际上并不是独立存在于服务器上的页面文件，只有当用户请求时服务器才返回一个完整的页面； （4）动态页面中的“？”对搜索引擎检索存在一定的问题，搜索引擎通常不行能从一个网站的数据库中访问全部页面，或者出于技能方面的考虑，搜索蜘蛛不去抓取网址中“？”后面的内容，因此选用动态页面的网站在进行搜索引擎推广时需求做一定的技能处理才能适应搜索引擎的要求.]]></content>
      <tags>
        <tag>http</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[简单认识docker]]></title>
    <url>%2F2019%2F02%2F18%2F%E7%AE%80%E5%8D%95%E8%AE%A4%E8%AF%86docker%2F</url>
    <content type="text"><![CDATA[1.Docker溯源 Docker的前身是名为dotCloud的小公司，主要提供的是基于 PaaS（Platform as a Service，平台及服务）平台为开发者或开发商提供技术服务，并提供的开发工具和技术框架。因为其为初创的公司，又生于IT行业，dotCloud受到了IBM，亚马逊，google等公司的挤压，发展举步维艰。于是，在2013年dotCloud 的创始人，年仅28岁的Solomon Hykes做了一个艰难的决定：将dotCloud的核心引擎开源！然而一旦这个基于 LXC（Linux Container）技术的核心管理引擎开源，dotCloud公司就相当于走上了一条”不归路”。可正是这个孤注一掷的举动，却带来了全球技术人员的热潮，众程序员惊呼：太方便了，太方便了。也正是这个决定，让所有的IT巨头也为之一颤。一个新的公司也随之出世，它就是：Docker。可以说，Docker是一夜成名的！！ 2.Docker认识2.1镜像，容器，仓库 首先，需要了解一下几个概念：镜像，容器，仓库 镜像（image）：Docker 镜像就是一个只读的模板，镜像可以用来创建 Docker 容器。Docker 提供了一个很简单的机制来创建镜像或者更新现有的镜像，用户甚至可以直接从其他人那里下载一个已经做好的镜像来直接使用。镜像是一种文件结构。Dockerfile中的每条命令都会在文件系统中创建一个新的层次结构，文件系统在这些层次上构建起来，镜像就构建于这些联合的文件系统之上。Docker官方网站专门有一个页面来存储所有可用的镜像，网址是：index.docker.io。 容器（ Container）：容器是从镜像创建的运行实例。它可以被启动、开始、停止、删除。每个容器都是相互隔离的、保证安全的平台。可以把容器看做是一个简易版的 Linux 环境，Docker 利用容器来运行应用。 仓库：仓库是集中存放镜像文件的场所，仓库注册服务器（Registry）上往往存放着多个仓库，每个仓库中又包含了多个镜像，每个镜像有不同的标签（tag）。目前，最大的公开仓库是 Docker Hub，存放了数量庞大的镜像供用户下载。 2.2Docker定义Docker 是一个开源的应用容器引擎，让开发者可以打包他们的应用以及依赖包到一个可移植的容器中，然后发布到任何流行的 Linux 机器上。Docker是一个重新定义了程序开发测试、交付和部署过程的开放平台，Docker则可以称为构建一次，到处运行，这就是Docker提出的”Build once，Run anywhere” Docker仓库用来保存我们的images，当我们创建了自己的image之后我们就可以使用push命令将它上传到公有或者私有仓库，这样下次要在另外一台机器上使用这个image时候，只需要从仓库上pull下来就可以了。注意：Docker不是容器，而是管理容器的引擎！ Docker中文手册上解释说：Docker是一个开源的引擎，可以轻松的为任何应用创建一个轻量级的、可移植的、自给自足的容器。开发者在笔记本上编译测试通过的容器可以批量地在生产环境中部署，包括VMs（虚拟机）、bare metal、OpenStack 集群和其他的基础应用平台。 从这里我们可以看出，Docker并非是容器，而是管理容器的引擎。Docker是为应用打包、部署的平台，而非单纯的虚拟化技术。]]></content>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mongo常用命令]]></title>
    <url>%2F2019%2F02%2F18%2Fmongo%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[安装查看服务tasklist /FI “IMAGENAME eq mongod.exe” 启动服务mongod –config “C:\Program Files\Mongodb\Server\4.0.4\mongod.conf” 注册到windows服务中mongod –install –config “C:\Program Files\Mongodb\Server\4.0.4\mongod.conf” 重新开启一个命令行窗口 输入 mongo 连接服务 mongod –dbpath “C:\Program Files\Mongodb\Server\4.0.4\data”–logpath “C:\Program Files\Mongodb\Server\4.0.4\log\mongodb.log” –logappend) 连接服务mongo 命令show dbs; #查看全部数据库 show collections; #显示当前数据库中的集合（类似关系数据库中的表） show users; #查看当前数据库的用户信息 use ; #切换数据库跟mysql一样 db;或者db.getName(); #查看当前所在数据库 db.help(); #显示数据库操作命令，里面有很多的命令db.foo.help(); #显示集合操作命令，同样有很多的命令，foo指的是当前数据库下，一个叫foo的集合，并非真正意义上的命令db.foo.find(); #对于当前数据库中的foo集合进行数据查找（由于没有条件，会列出所有数据）db.foo.find( { a : 1 } ); #对于当前数据库中的foo集合进行查找，条件是数据中有一个属性叫a，且a的值为1复制代码 创建一个test数据库例子： 复制代码 use test; #创建数据库switched to db testdb;testshow dbs; #检查数据库admin 0.000GBlocal 0.000GB db.test.insert({“_id”:”520”,”name”:”xiaoming”}) #创建表 WriteResult({ “nInserted” : 1 }) db.createUser({user:”xiaoming”,pwd:”123456”,roles:[{role:”userAdmin”,db:”test”}]}) #创建用户Successfully added user: {“user” : “xiaoming”,“roles” : [{“role” : “userAdmin”,“db” : “test”}]}db.removeUser(“userName”); #删除用户show users; #显示当前所有用户复制代码db.dropDatabase(); #删除当前使用数据库 复制代码 show dbs;admin 0.000GBlocal 0.000GBtest 0.000GBtest_1 0.000GB db;test_1 db.dropDatabase();{ “dropped” : “test_1”, “ok” : 1 } show dbs;admin 0.000GBlocal 0.000GBtest 0.000GB复制代码db.stats(); #显示当前db状态 复制代码 db.stats();{ “db” : “test_1”, “collections” : 0, “views” : 0, “objects” : 0, “avgObjSize” : 0, “dataSize” : 0, “storageSize” : 0, “numExtents” : 0, “indexes” : 0, “indexSize” : 0, “fileSize” : 0, “ok” : 1}复制代码db.version(); #当前db版本 db.version();3.4.10db.getMongo(); #查看当前db的链接机器地址 db.getMongo();connection to 172.16.40.205:27017开启远程访问 复制代码编辑配置文件：vi /etc/mongod.confbindIp: 172.16.40.205 #数据库所在服务器IP地址保存重启数据库！本地登录：mongo 172.16.40.205/admin -uadmin -p123456远程登录： 下载mongodb压缩包mongodb-linux-x86_64-3.4.10.tgz 解压 tar zxvf mongodb-linux-x86_64-3.4.10.tgz 进入bin目录 cd mongodb-linux-x86_64-3.4.10/bin 连接远程数据库 ./mongo 172.16.40.205:27017/admin -u user -p password复制代码 查看服务tasklist /FI “IMAGENAME eq mongod.exe” 启动服务mongod –config “C:\Program Files\Mongodb\Server\4.0.4\mongod.conf” 注册到windows服务中mongod –install –config “C:\Program Files\Mongodb\Server\4.0.4\mongod.conf” 重新开启一个命令行窗口 输入 mongo 连接服务 mongod –dbpath “C:\Program Files\Mongodb\Server\4.0.4\data”–logpath “C:\Program Files\Mongodb\Server\4.0.4\log\mongodb.log” –logappend) 连接服务]]></content>
      <tags>
        <tag>mongo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git常用命令]]></title>
    <url>%2F2019%2F02%2F18%2Fgit%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[git常用命令：git init //初始化本地git环境git clone XXX//克隆一份代码到本地仓库git pull //把远程库的代码更新到工作台git pull –rebase origin master //强制把远程库的代码跟新到当前分支上面git fetch //把远程库的代码更新到本地库git add . //把本地的修改加到stage中git commit -m ‘comments here’ //把stage中的修改提交到本地库git push //把本地库的修改提交到远程库中git branch -r/-a //查看远程分支/全部分支git checkout master/branch //切换到某个分支git checkout -b test //新建test分支git checkout -d test //删除test分支git merge master //假设当前在test分支上面，把master分支上的修改同步到test分支上git merge tool //调用merge工具git stash //把未完成的修改缓存到栈容器中git stash list //查看所有的缓存git stash pop //恢复本地分支到缓存状态git blame someFile //查看某个文件的每一行的修改记录（）谁在什么时候修改的）git status //查看当前分支有哪些修改git log //查看当前分支上面的日志信息git diff //查看当前没有add的内容git diff –cache //查看已经add但是没有commit的内容git diff HEAD //上面两个内容的合并git reset –hard HEAD //撤销本地修改echo $HOME //查看git config的HOME路径export $HOME=/c/gitconfig //配置git config的HOME路径 团队协作git操作流程：克隆一个全新的项目，完成新功能并且提交：git clone XXX //克隆代码库git checkout -b test //新建分支modify some files //完成修改git add . //把修改加入stage中git commit -m ‘’ //提交修改到test分支review代码git checkout master //切换到master分支git pull //更新代码git checkout test //切换到test分支git meger master //把master分支的代码merge到test分支git push origin 分支名//把test分支的代码push到远程库目前正在test分支上面开发某个功能，但是没有完成。突然一个紧急的bug需要处理git add .git stashgit checkout bugFixBranchgit pull –rebase origin masterfix the buggit add .git commit -m ‘’git pushgit checkout testgit stash popcontinue new feature’s development git工作视图]]></content>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[码云生成公钥]]></title>
    <url>%2F2019%2F02%2F18%2F%E7%A0%81%E4%BA%91%E7%94%9F%E6%88%90%E5%85%AC%E9%92%A5%2F</url>
    <content type="text"><![CDATA[clone工程有两种：1）HTTPS (pull和push的时候需要密码) 2）SSH （不需要密码，但是需要创建公钥） 创建公钥的目的： 使用SSH公钥可以让你在你的电脑和码云通讯的时候使用安全连接（git的remote要使用SSH地址） 步骤： 1.打开终端（git）进入.ssh目录 cd ~/.ssh 如果.ssh文件夹不存在，执行指令自动创建 mkdir ~/.ssh 2.生成RSA密钥对 ssh-keygen -t rsa -C “你的邮箱@xxx.com” 为了方便全程回车即可（不用输入ras文件名及密码） Generating public/private rsa key pair…三次回车即可生成 ssh key3.查看公钥内容 cat ~/.ssh/id_rsa.pub 4.将公钥内容（全部）复制并粘贴（注意：公钥内容以ssh-rsa开头） 粘贴地址 https://gitee.com/profile/sshkeys 5.添加公钥完成后进行测试公钥 测试SSH链接 ssh -T git@gitee.com 当终端提示welcome to Gitee.com,yourname!表示链接成功 至此以后只要拷贝ssh链接地址，然后利用git指令即可进行相关操作！]]></content>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[正则表示式中re.S和小括号的作用]]></title>
    <url>%2F2019%2F02%2F18%2F%E6%AD%A3%E5%88%99%E8%A1%A8%E7%A4%BA%E5%BC%8F%E4%B8%ADre-S%E5%92%8C%E5%B0%8F%E6%8B%AC%E5%8F%B7%E7%9A%84%E4%BD%9C%E7%94%A8%2F</url>
    <content type="text"><![CDATA[正则表达式中的小括号用法小括号中的连续字符作为可选： “Nov” -match “\bNov(ember)?\b” 返回true “November” -match “\bNov(ember)?\b” 返回true 正则表达式中的小括号的作用是对字符进行分组，并保存匹配的文本。与位于小括号之间的模式匹配的内容都会被捕获“92/01/2009Description” -match “^(\d)(\d)” 返回值为9 ，2 当小括号中的内容不是想捕获的对象时，即小括号的内容不作为捕获对象，采用非捕获小括号可以提高匹配效率。 “92/01/2009Description” -match “^(\d)(?:\d)” 返回值为9 “92/01/2009Description” -match “^(?:\d)(?:\d)” 返回 2 为每个子表达式定义名称： “92/01/2009Description” -match “^(?\d)(?\d)” $matches.first #返回9 ()小括号就是括号内看成一个整体 ，将基本的单元合成一个大的单元。括号匹配字符串，并记住匹配结果，匹配结果则保存在结果数组中。如果只是用它来做分组，方法是在左括号的后边加上:?，这里第一个圆括弧只是用来分组，而不会占用捕获变量。 中括号就是匹配括号内的其中一个。 大括号就是匹配几次 | 表示 或 例：”Bob and Ted” -match “Alice|Bob” 返回true “Peter and Bob” -match “and (Bob|Willy)” 返回true Python正则表达式中的re.S的作用在Python的正则表达式中，有一个参数为re.S。它表示“.”（不包含外侧双引号，下同）的作用扩展到整个字符串，包括“\n”。看如下代码： 复制代码import rea = ‘’’asdfhellopass:​ 123​ worldaf​ ‘’’b = re.findall(‘hello(.?)world’,a)c = re.findall(‘hello(.?)world’,a,re.S)print ‘b is ‘ , bprint ‘c is ‘ , c复制代码运行结果如下： b is []c is [‘pass:\n\t123\n\t’] 正则表达式中，“.”的作用是匹配除“\n”以外的任何字符，也就是说，它是在一行中进行匹配。这里的“行”是以“\n”进行区分的。a字符串有每行的末尾有一个“\n”，不过它不可见。如果不使用re.S参数，则只在每一行内进行匹配，如果一行没有，就换下一行重新开始，不会跨行。而使用re.S参数以后，正则表达式会将这个字符串作为一个整体，将“\n”当做一个普通的字符加入到这个字符串中，在整体中进行匹配。]]></content>
      <tags>
        <tag>爬虫</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[常用浏览器User_Agent大全]]></title>
    <url>%2F2019%2F02%2F18%2F%E5%B8%B8%E7%94%A8%E6%B5%8F%E8%A7%88%E5%99%A8User-Agent%E5%A4%A7%E5%85%A8%2F</url>
    <content type="text"><![CDATA[常见浏览器User-Agent大全下面是工作中需要用到的常见浏览器User-Agent字符串的收集整理，不断更新中。 OperaMozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36 OPR/26.0.1656.60Opera/8.0 (Windows NT 5.1; U; en)Mozilla/5.0 (Windows NT 5.1; U; en; rv:1.8.1) Gecko/20061208 Firefox/2.0.0 Opera 9.50Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.1; en) Opera 9.50 FirefoxMozilla/5.0 (Windows NT 6.1; WOW64; rv:34.0) Gecko/20100101 Firefox/34.0Mozilla/5.0 (X11; U; Linux x86_64; zh-CN; rv:1.9.2.10) Gecko/20100922 Ubuntu/10.10 (maverick) Firefox/3.6.10 SafariMozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/534.57.2 (KHTML, like Gecko) Version/5.1.7 Safari/534.57.2 chromeMozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.71 Safari/537.36Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.11 (KHTML, like Gecko) Chrome/23.0.1271.64 Safari/537.11Mozilla/5.0 (Windows; U; Windows NT 6.1; en-US) AppleWebKit/534.16 (KHTML, like Gecko) Chrome/10.0.648.133 Safari/534.16 360Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/30.0.1599.101 Safari/537.36Mozilla/5.0 (Windows NT 6.1; WOW64; Trident/7.0; rv:11.0) like Gecko 淘宝浏览器Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/536.11 (KHTML, like Gecko) Chrome/20.0.1132.11 TaoBrowser/2.0 Safari/536.11 猎豹浏览器Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.1 (KHTML, like Gecko) Chrome/21.0.1180.71 Safari/537.1 LBBROWSERMozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; WOW64; Trident/5.0; SLCC2; .NET CLR 2.0.50727; .NET CLR 3.5.30729; .NET CLR 3.0.30729; Media Center PC 6.0; .NET4.0C; .NET4.0E; LBBROWSER)Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.1; SV1; QQDownload 732; .NET4.0C; .NET4.0E; LBBROWSER)” QQ浏览器Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; WOW64; Trident/5.0; SLCC2; .NET CLR 2.0.50727; .NET CLR 3.5.30729; .NET CLR 3.0.30729; Media Center PC 6.0; .NET4.0C; .NET4.0E; QQBrowser/7.0.3698.400)Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.1; SV1; QQDownload 732; .NET4.0C; .NET4.0E) sogou浏览器Mozilla/5.0 (Windows NT 5.1) AppleWebKit/535.11 (KHTML, like Gecko) Chrome/17.0.963.84 Safari/535.11 SE 2.X MetaSr 1.0Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1; Trident/4.0; SV1; QQDownload 732; .NET4.0C; .NET4.0E; SE 2.X MetaSr 1.0) maxthon浏览器Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Maxthon/4.4.3.4000 Chrome/30.0.1599.101 Safari/537.36 UC浏览器Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/38.0.2125.122 UBrowser/4.0.3214.0 Safari/537.36 ==================== 移动浏览器大全 ==================== IPhoneMozilla/5.0 (iPhone; U; CPU iPhone OS 4_3_3 like Mac OS X; en-us) AppleWebKit/533.17.9 (KHTML, like Gecko) Version/5.0.2 Mobile/8J2 Safari/6533.18.5 IPodMozilla/5.0 (iPod; U; CPU iPhone OS 4_3_3 like Mac OS X; en-us) AppleWebKit/533.17.9 (KHTML, like Gecko) Version/5.0.2 Mobile/8J2 Safari/6533.18.5 IPADMozilla/5.0 (iPad; U; CPU OS 4_2_1 like Mac OS X; zh-cn) AppleWebKit/533.17.9 (KHTML, like Gecko) Version/5.0.2 Mobile/8C148 Safari/6533.18.5Mozilla/5.0 (iPad; U; CPU OS 4_3_3 like Mac OS X; en-us) AppleWebKit/533.17.9 (KHTML, like Gecko) Version/5.0.2 Mobile/8J2 Safari/6533.18.5 AndroidMozilla/5.0 (Linux; U; Android 2.2.1; zh-cn; HTC_Wildfire_A3333 Build/FRG83D) AppleWebKit/533.1 (KHTML, like Gecko) Version/4.0 Mobile Safari/533.1Mozilla/5.0 (Linux; U; Android 2.3.7; en-us; Nexus One Build/FRF91) AppleWebKit/533.1 (KHTML, like Gecko) Version/4.0 Mobile Safari/533.1 QQ浏览器 Android版本MQQBrowser/26 Mozilla/5.0 (Linux; U; Android 2.3.7; zh-cn; MB200 Build/GRJ22; CyanogenMod-7) AppleWebKit/533.1 (KHTML, like Gecko) Version/4.0 Mobile Safari/533.1 Android Opera MobileOpera/9.80 (Android 2.3.4; Linux; Opera Mobi/build-1107180945; U; en-GB) Presto/2.8.149 Version/11.10 Android Pad Moto XoomMozilla/5.0 (Linux; U; Android 3.0; en-us; Xoom Build/HRI39) AppleWebKit/534.13 (KHTML, like Gecko) Version/4.0 Safari/534.13 BlackBerryMozilla/5.0 (BlackBerry; U; BlackBerry 9800; en) AppleWebKit/534.1+ (KHTML, like Gecko) Version/6.0.0.337 Mobile Safari/534.1+ WebOS HP TouchpadMozilla/5.0 (hp-tablet; Linux; hpwOS/3.0.0; U; en-US) AppleWebKit/534.6 (KHTML, like Gecko) wOSBrowser/233.70 Safari/534.6 TouchPad/1.0 Nokia N97Mozilla/5.0 (SymbianOS/9.4; Series60/5.0 NokiaN97-1/20.0.019; Profile/MIDP-2.1 Configuration/CLDC-1.1) AppleWebKit/525 (KHTML, like Gecko) BrowserNG/7.1.18124 Windows Phone MangoMozilla/5.0 (compatible; MSIE 9.0; Windows Phone OS 7.5; Trident/5.0; IEMobile/9.0; HTC; Titan) UC浏览器UCWEB7.0.2.37/28/999 NOKIA5700/ UCWEB7.0.2.37/28/999 UCOpenwaveOpenwave/ UCWEB7.0.2.37/28/999 UC OperaMozilla/4.0 (compatible; MSIE 6.0; ) Opera/UCWEB7.0.2.37/28/999]]></content>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql测试题目]]></title>
    <url>%2F2019%2F02%2F18%2Fmysql%E6%B5%8B%E8%AF%95%E9%A2%98%E7%9B%AE%2F</url>
    <content type="text"><![CDATA[1.创建数据库CREATE DATABASE QQDB; 2.创建各表（表结构；约束）/***创建**/USE QQDB; DROP TABLE IF EXISTS QQUser;CREATE TABLE QQUser(qqid BIGINT PRIMARY KEY,PASSWORD VARCHAR(20) NOT NULL,lastlogtime DATETIME NOT NULL,online INT NOT NULL,LEVEL INT NOT NULL); DROP TABLE IF EXISTS baseinfo;CREATE TABLE baseinfo(qqid BIGINT PRIMARY KEY,nickname VARCHAR(50) NOT NULL,sex INT,age INT NOT NULL,province VARCHAR(50),city VARCHAR(50),address VARCHAR(200),phone CHAR(50),CONSTRAINT FK_qqid FOREIGN KEY (qqid) REFERENCES qquser (qqid)); DROP TABLE IF EXISTS relaion;CREATE TABLE relaion(qqid BIGINT NOT NULL,relationqqid BIGINT NOT NULL,relationstatus INT NOT NULL,CONSTRAINT FK_r_qqid FOREIGN KEY (qqid) REFERENCES qquser (qqid),CONSTRAINT FK_r_relationqqid FOREIGN KEY (relationqqid) REFERENCES qquser (qqid)); 3.添加/插入 数据/***添加**/insert into qquser(QQid,Password,lastlogTime,Online,level)values (1,’a123456’,’2017-03-02 00:00:00’,1,6),(2,’b123456’,’2017-03-02 00:00:00’,2,7),(3,’c123456’,’2018-03-01 00:00:00’,2,6),(4,’d123456’,’2018-03-02 00:00:00’,2,8),(7,’g123456’,’2012-02-02 00:00:00’,0,-1),(8855678,’gues0221’,’2008-02-21 16:28:20’,1,6),(54789625,’add512#&amp;’,’2008-02-16 17:01:35’,2,1),(88662753,’admin0219’,’2008-02-19 21:08:35’,0,5); insert into baseinfo(QQID,nickName,Sex,Age,provice,City,Addres,phone)values (1,’小明’,0,18,’山东省’,’济南’,’小村村’,’004’),(2,’小天’,1,15,’山东’,’聊城’,’大村村’,’005’),(3,’小王’,1,16,’河南’,’开封’,’不知奥’,’006’),(4,’嘟嘟鱼’,0,13,’天津’,’塘沽’,’呵呵’,’007’),(8855678,’独行侠,1,38,’北京’,’海淀区’,’解放中路号院123室’,’003’),(54789625,’蝴蝶飞飞’,1,16,’北京’,’海淀区’,’亚运村’,’001’),(88662753,’青青草’,0,20,’河南省’,’安阳’,’汤阴’,’002’); INSERT INTO relaion(qqid,relationqqid,relationstatus)VALUES(54789625,88662753,0),(88662753,8855678,1),(54789625,8855678,0); 4.查询数据##查询数据 #01.查询QQ号码为54789625的所有好友信息，包括QQ号码，昵称，年龄select RelationQQID as QQ号码,NickName as 昵称,Age as 年龄from BaseInfo,Relationwhere BaseInfo.QQID=Relation.RelationQQIDand Relation.QQID=54789625and RelationStatus=0 或者1 #02.查询当前在线用户的信息SELECT NickName,Province FROMBaseInfo,QQUserWHERE BaseInfo.QQID=QQUser.QQID AND Online=0 #03.查询北京的、年龄在18至45岁之间的在线用户的信息SELECT NickName,Province FROMBaseInfo,QQUserWHERE BaseInfo.QQID=QQUser.QQIDAND BaseInfo.Province LIKE ‘%北京%’AND BaseInfo.Age BETWEEN 18 AND 45AND Online=0 #04.查询昵称为青青草的用户信息SELECT NickName,Province,City,AddressFROM BaseInfoWHERE NickName=’青青草’ #05.查询QQ号码为54789625的用户的好友中每个省份的总人数，并且总人数按由大到小排序。SELECT BaseInfo.Province,COUNT(*) AS 总人数 FROM Relation,BaseInfoWHERE Relation.RelationQQID=BaseInfo.QQIDAND Relation.RelationStatus=0AND Relation.QQID=54789625GROUP BY BaseInfo.ProvinceORDER BY 总人数 DESC #06.查询至少有150天未登录QQ账号的用户信息，包括QQ号码，最后一次登录时间、等级、昵称、年龄，并按时间的降序排列SELECT QQUser.QQID,QQUser.LastLogTime,QQUser.Level,BaseInfo.NickName,BaseInfo.AgeFROM BaseInfo,QQUserWHERE BaseInfo.QQID=QQUser.QQIDAND DATEDIFF(NOW(),lastLogTime)&gt;=150ORDER BY DATEDIFF(NOW(),lastLogTime) DESC #07.查询QQ号码为54789625的好友中等级为10级以上的“月亮”级用户信息。SELECT NickName,ProvinceFROM QQUser,Relation,BaseInfoWHERE Relation.RelationQQID=BaseInfo.QQIDAND Relation.QQID=54789625AND Relation.RelationStatus=0AND Relation.RelationQQID=QQUser.QQIDAND QQUser.Level&gt;=10 #08.–查询QQ号码为54789625的好友中隐身的用户信息。SELECT NickName,provinceFROM Relation INNER JOIN BaseInfoON Relation.RelationQQID=BaseInfo.QQIDAND Relation.QQID=54789625INNER JOIN QQUserON QQUser.QQID=RelationQQIDAND Online=2 #2代表隐身AND Relation.RelationStatus=0 #0代表好友 #09.–查询好友超过20个的用户信息。SELECT Nickname,provinceFROM BaseInfo WHERE QQID IN(SELECT QQIDFROM RelationWHERE RelationStatus=0GROUP BY QQIDHAVING COUNT(*)&gt;20) #10.为了查看信誉度，管理员需要查询被当做黑名单人物次数排名前3的用户SELECT RelationQQID,COUNT() AS 次数FROM RelationWHERE RelationStatus=1GROUP BY RelationQQIDORDER BY COUNT() DESCLIMIT 3 5.修改数据##修改数据 #01.假设我的QQ号码为8855678，今天我隐身登录UPDATE QQUser SET Online=2,LastLogTime=NOW()WHERE QQID=8855678 #02.假设我的QQ号码为8855678，修改我的昵称为“被淹死的鱼”，地址为“解放中路号院123室”UPDATE BaseInfo SET NickName=’被淹死的鱼’,Address=’解放中路号院室’WHERE QQID=8855678 #03.假设我的QQ号码为54789625，将我的好友“青青草”拖进黑名单。UPDATE Relation SET RelationStatus=1WHERE QQID=54789625 AND RelationQQID=88662753 #04.为了提高QQ用户的聊天积极性，把等级小于6级的用户的等级都提升1个级别。update QQUser set Level=Level+1where Level&lt;6 #05.管理员将超过365天没有登录过的QQ锁定（即将等级值设定为-1）。UPDATE QQUser SET LEVEL=-1WHERE DATEDIFF(NOW(),lastLogTime)&gt;=365 #06.为了奖励用户，将好友数量超过20的用户等级提升1个级别。UPDATE QQUser SET LEVEL=LEVEL+1WHERE QQID IN(SELECT Relation.QQID FROM RelationWHERE RelationStatus=0GROUP BY Relation.QQIDHAVING COUNT(Relation.RelationQQID)&gt;=20) #07.把QQ号码为54789625的用户的好友“嘟嘟鱼”拖进黑名单中。UPDATE Relation SET RelationStatus=1WHERE QQID=54789625 AND RelationQQID=(SELECT QQID FROM BaseInfo WHERE NickName=’嘟嘟鱼’)AND RelationStatus=0 6.删除数据##删除数据 #1.把QQ号码为54789625的用户黑名单中的用户删除。DELETE FROM Relation WHERE QQID=54789625 AND RelationStatus=1 #2.QQ号码为54789625的用户多次在QQ中发布违法信息，造成了很坏的影响，因此管理员决定将其删除。DELETE FROM Relation WHERE QQID=54789625 OR RelationQQID=54789625DELETE FROM BaseInfo WHERE QQID=54789625DELETE FROM QQUser WHERE QQID=54789625 #3.管理员将超过1000天没有登录过的QQ删除。DELETE FROM Relation WHERE QQID IN( SELECT QQID FROM QQUser WHERE DATEDIFF(NOW(),LastLogTime)&gt;=1000)OR RelationQQID IN( SELECT QQID FROM QQUser WHERE DATEDIFF(NOW(),LastLogTime)&gt;=1000)DELETE FROM BaseInfo WHERE QQID IN( SELECT QQID FROM QQUser WHERE DATEDIFF(NOW(),LastLogTime)&gt;=1000)DELETE FROM QQUserWHERE DATEDIFF(NOW(),LastLogTime)&gt;=1000 辅助blog MySQL 获得当前日期时间 函数获得当前日期+时间（date + time）函数：now() mysql&gt; select now(); +———————+| now() |+———————+| 2008-08-08 22:20:46 |+———————+ 获得当前日期+时间（date + time）函数：sysdate()sysdate() 日期时间函数跟 now() 类似，不同之处在于：now() 在执行开始时值就得到了， sysdate() 在函数执行时动态得到值。看下面的例子就明白了： mysql&gt; select now(), sleep(3), now(); +———————+———-+———————+| now() | sleep(3) | now() |+———————+———-+———————+| 2008-08-08 22:28:21 | 0 | 2008-08-08 22:28:21 |+———————+———-+———————+ sysdate() 日期时间函数，一般情况下很少用到。 MySQL 获得当前时间戳函数：current_timestamp, current_timestamp() mysql&gt; select current_timestamp, current_timestamp(); +———————+———————+| current_timestamp | current_timestamp() |+———————+———————+| 2008-08-09 23:22:24 | 2008-08-09 23:22:24 |+———————+———————+ MySQL 日期转换函数、时间转换函数MySQL Date/Time to Str（日期/时间转换为字符串）函数：date_format(date,format), time_format(time,format) mysql&gt; select date_format(‘2008-08-08 22:23:01’, ‘%Y%m%d%H%i%s’); +—————————————————-+| date_format(‘2008-08-08 22:23:01’, ‘%Y%m%d%H%i%s’) |+—————————————————-+| 20080808222301 |+—————————————————-+ MySQL 日期、时间转换函数：date_format(date,format), time_format(time,format) 能够把一个日期/时间转换成各种各样的字符串格式。它是 str_to_date(str,format) 函数的 一个逆转换。 MySQL Str to Date （字符串转换为日期）函数：str_to_date(str, format) select str_to_date(‘08/09/2008’, ‘%m/%d/%Y’); – 2008-08-09select str_to_date(‘08/09/08’ , ‘%m/%d/%y’); – 2008-08-09select str_to_date(‘08.09.2008’, ‘%m.%d.%Y’); – 2008-08-09select str_to_date(‘08:09:30’, ‘%h:%i:%s’); – 08:09:30select str_to_date(‘08.09.2008 08:09:30’, ‘%m.%d.%Y %h:%i:%s’); – 2008-08-09 08:09:30 可以看到，str_to_date(str,format) 转换函数，可以把一些杂乱无章的字符串转换为日期格式。另外，它也可以转换为时间。“format” 可以参看 MySQL 手册。 MySQL （日期、天数）转换函数：to_days(date), from_days(days) select to_days(‘0000-00-00’); – 0select to_days(‘2008-08-08’); – 733627 MySQL （时间、秒）转换函数：time_to_sec(time), sec_to_time(seconds) select time_to_sec(‘01:00:05’); – 3605select sec_to_time(3605); – ‘01:00:05’ MySQL 拼凑日期、时间函数：makdedate(year,dayofyear), maketime(hour,minute,second) select makedate(2001,31); – ‘2001-01-31’select makedate(2001,32); – ‘2001-02-01’select maketime(12,15,30); – ‘12:15:30’ MySQL （Unix 时间戳、日期）转换函数 unix_timestamp(), unix_timestamp(date), from_unixtime(unix_timestamp), from_unixtime(unix_timestamp,format) 下面是示例： select unix_timestamp(); – 1218290027select unix_timestamp(‘2008-08-08’); – 1218124800select unix_timestamp(‘2008-08-08 12:30:00’); – 1218169800 select from_unixtime(1218290027); – ‘2008-08-09 21:53:47’select from_unixtime(1218124800); – ‘2008-08-08 00:00:00’select from_unixtime(1218169800); – ‘2008-08-08 12:30:00’ select from_unixtime(1218169800, ‘%Y %D %M %h:%i:%s %x’); – ‘2008 8th August 12:30:00 2008’ MySQL 日期时间计算函数 MySQL 为日期增加一个时间间隔：date_add() set @dt = now(); select date_add(@dt, interval 1 day); – add 1 dayselect date_add(@dt, interval 1 hour); – add 1 hourselect date_add(@dt, interval 1 minute); – …select date_add(@dt, interval 1 second);select date_add(@dt, interval 1 microsecond);select date_add(@dt, interval 1 week);select date_add(@dt, interval 1 month);select date_add(@dt, interval 1 quarter);select date_add(@dt, interval 1 year); select date_add(@dt, interval -1 day); – sub 1 day MySQL adddate(), addtime()函数，可以用 date_add() 来替代。下面是 date_add() 实现 addtime() 功能示例： mysql&gt; set @dt = ‘2008-08-09 12:12:33’; mysql&gt; mysql&gt; select date_add(@dt, interval ‘01:15:30’ hour_second); +————————————————+| date_add(@dt, interval ‘01:15:30’ hour_second) |+————————————————+| 2008-08-09 13:28:03 |+————————————————+ mysql&gt; select date_add(@dt, interval ‘1 01:15:30’ day_second); +————————————————-+| date_add(@dt, interval ‘1 01:15:30’ day_second) |+————————————————-+| 2008-08-10 13:28:03 |+————————————————-+ MySQL 为日期减去一个时间间隔：date_sub() mysql&gt; select date_sub(‘1998-01-01 00:00:00’, interval ‘1 1:1:1’ day_second); +—————————————————————-+| date_sub(‘1998-01-01 00:00:00’, interval ‘1 1:1:1’ day_second) |+—————————————————————-+| 1997-12-30 22:58:59 |+—————————————————————-+ MySQL date_sub() 日期时间函数 和 date_add() 用法一致，不再赘述。 MySQL 日期、时间相减函数：datediff(date1,date2), timediff(time1,time2) MySQL datediff(date1,date2)：两个日期相减 date1 - date2，返回天数。select datediff(‘2008-08-08’, ‘2008-08-01’); – 7select datediff(‘2008-08-01’, ‘2008-08-08’); – -7 MySQL timediff(time1,time2)：两个日期相减 time1 - time2，返回 time 差值。 select timediff(‘2008-08-08 08:08:08’, ‘2008-08-08 00:00:00’); – 08:08:08select timediff(‘08:08:08’, ‘00:00:00’); – 08:08:08 注意：timediff(time1,time2) 函数的两个参数类型必须相同。 MySQL 时间戳（timestamp）转换、增、减函数： timestamp(date) – date to timestamptimestamp(dt,time) – dt + time timestampadd(unit,interval,datetime_expr) –timestampdiff(unit,datetime_expr1,datetime_expr2) – 请看示例部分： select timestamp(‘2008-08-08’); – 2008-08-08 00:00:00select timestamp(‘2008-08-08 08:00:00’, ‘01:01:01’); – 2008-08-08 09:01:01select timestamp(‘2008-08-08 08:00:00’, ‘10 01:01:01’); – 2008-08-18 09:01:01 select timestampadd(day, 1, ‘2008-08-08 08:00:00’); – 2008-08-09 08:00:00select date_add(‘2008-08-08 08:00:00’, interval 1 day); – 2008-08-09 08:00:00 MySQL timestampadd() 函数类似于 date_add()。select timestampdiff(year,’2002-05-01’,’2001-01-01’); – -1select timestampdiff(day ,’2002-05-01’,’2001-01-01’); – -485select timestampdiff(hour,’2008-08-08 12:00:00’,’2008-08-08 00:00:00’); – -12 select datediff(‘2008-08-08 12:00:00’, ‘2008-08-01 00:00:00’); – 7 MySQL timestampdiff() 函数就比 datediff() 功能强多了，datediff() 只能计算两个日期（date）之间相差的天数。 MySQL 时区（timezone）转换函数convert_tz(dt,from_tz,to_tz) select convert_tz(‘2008-08-08 12:00:00’, ‘+08:00’, ‘+00:00’); – 2008-08-08 04:00:00 时区转换也可以通过 date_add, date_sub, timestampadd 来实现。 select date_add(‘2008-08-08 12:00:00’, interval -8 hour); – 2008-08-08 04:00:00select date_sub(‘2008-08-08 12:00:00’, interval 8 hour); – 2008-08-08 04:00:00select timestampadd(hour, -8, ‘2008-08-08 12:00:00’); – 2008-08-08 04:00:00]]></content>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python解释器安装]]></title>
    <url>%2F2019%2F02%2F18%2Fpython%E8%A7%A3%E9%87%8A%E5%99%A8%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[python解释器下载Python目前已支持所有主流操作系统 在Linux,Unix,Mac系统上自带Python环境python解释器在Windows系统上需要安装一下，懂我意思吧给各位小捞板详细点的步骤 打开官网 https://www.python.org/downloads/windows/ 下载中心 根据自己的要求选择版本 下图是一个python 3.6.1的例子 python解释器的安装 真好 现在你应该把python解释器成功安装 突然就觉得自己有点小帅 下面的安装步骤是3.6.4的版本 懂我意思吧 1. （1）勾选Add Python 3.6 to PATH是把Python的安装路径添加到系统环境变量的Path变量中（这样我们就少一步自己添加环境变量啦^_^） （2）选择Install Now默认将pythone安装在C盘目录下 （3）选择Customize installation可自定义路径 2. 选择Customize installation后，这一步默认全选，然后点击next 3. 这一步要勾选上Install for all users，路径根据自己的需要选择（我安装在了F盘下的Python36文件夹下） 4.然后点Install就开始安装了 5.安装成功验证打开cmd，输入python，出现以下提示 添加环境变量我的电脑是window10 戴尔笔记本就给小捞板搞个window10的环境变量配置 1,点“我的电脑”，右键选“属性”2，选择“高级系统设置”—&gt;选“环境变量”—&gt;在“系统变量”中选中“Path”,再点“编辑”—&gt;再点“编辑文本” 3,在“变量值”一栏，把自己所安装的python路径拷进去就可以了，我安装的路径是“C:\Python27”这一步要注意：在拷贝路径“C:\Python27”时，前面要加分号，，还要注意，分号一定是英文输入法里的分号，我刚开始没有注意到这一点，有点捞，导致在命令行里输入python命令时，总是失败，会提示‘python’不是内部或外部命令，也不是可运行的程序或批处理文件 到这里就配置完成了 就可以搞事情了 python解释器就安装完成了]]></content>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python常见的异常类型]]></title>
    <url>%2F2019%2F02%2F18%2Fpython%E5%B8%B8%E8%A7%81%E7%9A%84%E5%BC%82%E5%B8%B8%E7%B1%BB%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[python 常见的异常类型python标准异常异常名称 描述BaseException 所有异常的基类SystemExit 解释器请求退出KeyboardInterrupt 用户中断执行(通常是输入^C)Exception 常规错误的基类StopIteration 迭代器没有更多的值GeneratorExit 生成器(generator)发生异常来通知退出StandardError 所有的内建标准异常的基类ArithmeticError 所有数值计算错误的基类FloatingPointError 浮点计算错误OverflowError 数值运算超出最大限制ZeroDivisionError 除(或取模)零 (所有数据类型)AssertionError 断言语句失败AttributeError 对象没有这个属性EOFError 没有内建输入,到达EOF 标记EnvironmentError 操作系统错误的基类IOError 输入/输出操作失败OSError 操作系统错误WindowsError 系统调用失败ImportError 导入模块/对象失败LookupError 无效数据查询的基类IndexError 序列中没有此索引(index)KeyError 映射中没有这个键MemoryError 内存溢出错误(对于Python 解释器不是致命的)NameError 未声明/初始化对象 (没有属性)UnboundLocalError 访问未初始化的本地变量ReferenceError 弱引用(Weak reference)试图访问已经垃圾回收了的对象RuntimeError 一般的运行时错误NotImplementedError 尚未实现的方法SyntaxError Python 语法错误IndentationError 缩进错误TabError Tab 和空格混用SystemError 一般的解释器系统错误TypeError 对类型无效的操作ValueError 传入无效的参数UnicodeError Unicode 相关的错误UnicodeDecodeError Unicode 解码时的错误UnicodeEncodeError Unicode 编码时错误UnicodeTranslateError Unicode 转换时错误Warning 警告的基类DeprecationWarning 关于被弃用的特征的警告FutureWarning 关于构造将来语义会有改变的警告OverflowWarning 旧的关于自动提升为长整型(long)的警告PendingDeprecationWarning 关于特性将会被废弃的警告RuntimeWarning 可疑的运行时行为(runtime behavior)的警告SyntaxWarning 可疑的语法的警告UserWarning 用户代码生成的警告]]></content>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python装饰器]]></title>
    <url>%2F2019%2F02%2F18%2Fpython%E8%A3%85%E9%A5%B0%E5%99%A8%2F</url>
    <content type="text"><![CDATA[python 装饰器 以前你有没有这样一段经历：很久之前你写过一个函数，现在你突然有了个想法就是你想看看，以前那个函数在你数据集上的运行时间是多少，这时候你可以修改之前代码为它加上计时的功能，但是这样的话是不是还要大体读读你之前的这个的代码，稍微搞清楚一点它的逻辑，才敢给它添加新的东西。这样是不是很繁琐，要是你之前写的代码足够乱足够长，再去读它是不是很抓狂…。实际工作中，我们常常会遇到这样的场景，可能你的需求还不只是这么简单。那么有没有一种可以不对源码做任何修改，并且可以很好的实现你所有需求的手段呢？答案当然是有，这就是今天我们要介绍的python装饰器。有了装饰器，你除了不用担心前面提到的问题，并且还可以很好的处理接下来要做的事：那就是现在你又有了一个新的需求，比如为另一个函数添加计时功能，这时就非常简单了，把要装饰的函数丢给装饰器就好了，它会自动给你添加完功能并返回给你。是不是很神奇？下面我们将一层层剥开它的神秘面纱。 1. 闭包函数 在看装饰器之前，我们先来搞清楚什么是闭包函数。python是一种面向对象的编程语言，在python中一切皆对象，这样就使得变量所拥有的属性，函数也同样拥有。这样我们就可以理解在函数内创建一个函数的行为是完全合法的。这种函数被叫做内嵌函数，这种函数只可以在外部函数的作用域内被正常调用，在外部函数的作用域之外调用会报错，例如： 而如果内部函数里引用了外部函数里定义的对象（甚至是外层之外，但不是全局变量），那么此时内部函数就被称为闭包函数。闭包函数所引用的外部定义的变量被叫做自由变量。闭包从语法上看非常简单，但是却有强大的作用。闭包可以将其自己的代码和作用域以及外部函数的作用结合在一起。下面给出一个简单的闭包的例子： ;) 1234567def count(): a = 1 b = 1 def sum(): c = 1 return a + c # a - 自由变量 return sum ;) 总结：什么函数可以被称为闭包函数呢？主要是满足两点：函数内部定义的函数；引用了外部变量但非全局变量。 2. python装饰器 有了闭包函数的概念，我们再去理解装饰器会相对容易一些。python装饰器本质上就是一个函数，它可以让其他函数在不需要做任何代码变动的前提下增加额外的功能，装饰器的返回值也是一个函数对象（函数的指针）。装饰器函数的外部函数传入我要装饰的函数名字，返回经过修饰后函数的名字；内层函数（闭包）负责修饰被修饰函数。从上面这段描述中我们需要记住装饰器的几点属性，以便后面能更好的理解： 实质： 是一个函数 参数：是你要装饰的函数名（并非函数调用） 返回：是装饰完的函数名（也非函数调用） 作用：为已经存在的对象添加额外的功能 特点：不需要对对象做任何的代码上的变动 python装饰器有很多经典的应用场景，比如：插入日志、性能测试、事务处理、权限校验等。装饰器是解决这类问题的绝佳设计。并且从引入中的列子中我们也可以归纳出：装饰器最大的作用就是对于我们已经写好的程序，我们可以抽离出一些雷同的代码组建多个特定功能的装饰器，这样我们就可以针对不同的需求去使用特定的装饰器，这时因为源码去除了大量泛化的内容而使得源码具有更加清晰的逻辑。 2.1 函数装饰器函数的函数装饰器我们还是以为函数添加计时功能为例，讲述函数装饰器。 ;) 1234567891011121314151617import timedef decorator(func): def wrapper(*args, **kwargs): start_time = time.time() func() end_time = time.time() print(end_time - start_time) return wrapper@decorator def func(): time.sleep(0.8)func() # 函数调用# 输出：0.800644397735595 ;) 在上面代码中 func是我要装饰器的函数，我想用装饰器显示func函数运行的时间。@decorator这个语法相当于 执行 func = decorator(func)，为func函数装饰并返回。在来看一下我们的装饰器函数 - decorator，该函数的传入参数是func （被装饰函数），返回参数是内层函数。这里的内层函数-wrapper，其实就相当于闭包函数，它起到装饰给定函数的作用，wrapper参数为args, **kwargs。args表示的参数以列表的形式传入；**kwargs表示的参数以字典的形式传入： 从图中我们可以看到：凡是以key=value形式的参数均存在kwargs中，剩下的所有参数都以列表的形式存于args中。这里要注意的是：为了不破坏原函数的逻辑，我们要保证内层函数wrapper和被装饰函数func的传入参数和返回值类型必须保持一致。 类方法的函数装饰器 类方法的函数装饰器和函数的函数装饰器类似。 ;) 123456789101112131415161718import timedef decorator(func): def wrapper(me_instance): start_time = time.time() func(me_instance) end_time = time.time() print(end_time - start_time) return wrapperclass Method(object): @decorator def func(self): time.sleep(0.8)p1 = Method()p1.func() # 函数调用 ;) 对于类方法来说，都会有一个默认的参数self，它实际表示的是类的一个实例，所以在装饰器的内部函数wrapper也要传入一个参数 - me_instance就表示将类的实例p1传给wrapper，其他的用法都和函数装饰器相同。 2.2 类装饰器 前面我们提到的都是让 函数作为装饰器去装饰其他的函数或者方法，那么可不可以让 一个类发挥装饰器的作用呢？答案肯定是可以的，一切皆对象嚒，函数和类本质没有什么不一样。类的装饰器是什么样子的呢？ ;) 12345678910111213class Decorator(object): def __init__(self, f): self.f = f def __call__(self): print(&quot;decorator start&quot;) self.f() print(&quot;decorator end&quot;)@Decoratordef func(): print(&quot;func&quot;)func() ;) 这里有注意的是：call()是一个特殊方法，它可将**一个类实例变成一个可调用对象**: 12p = Decorator(func) # p是类Decorator的一个实例p() # 实现了__call__()方法后，p可以被调用 要使用类装饰器必须实现类中的call()方法，就相当于将实例变成了一个方法。 2.3 装饰器链 一个python函数也可以被多个装饰器修饰，要是有多个装饰器时，这些装饰器的执行顺序是怎么样的呢？ 可见，多个装饰器的执行顺序：是从近到远依次执行。 2.4 python装饰器库 - functools;) 123456789101112def decorator(func): def inner_function(): pass return inner_function@decoratordef func(): passprint(func.__name__)# 输出： inner_function ;) 上述代码最后执行的结果不是 func，而是 inner_function！这表示被装饰函数自身的信息丢失了！怎么才能避免这种问题的发生呢？ 可以借助functools.wraps()函数： ;) 1234567891011121314from functools import wrapsdef decorator(func): @wraps(func) def inner_function(): pass return inner_function@decoratordef func(): passprint(func.__name__)#输出： func ;)]]></content>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql命令大全]]></title>
    <url>%2F2019%2F02%2F18%2Fmysql%E5%91%BD%E4%BB%A4%E5%A4%A7%E5%85%A8%2F</url>
    <content type="text"><![CDATA[安装命令mysqld –defaults-file=C:\my.ini –initialize –console 初始文件和root密码mysqld –console 开启服务ALTER USER “root”@“localhost”IDENTIFIED BY “trclyy20010320”; 改名字\q 退出mysqld –install MySQL80 –defaults-file=”C:\my.ini” 注册window服务net start mysql 开启数据库 mysql -u root -ptrc 我的密码 操作指令1、MySQL常用命令create database name; 创建数据库 use databasename; 选择数据库 drop database name 直接删除数据库，不提醒 show tables; 显示表 describe tablename; 表的详细描述 select 中加上distinct去除重复字段 mysqladmin drop databasename 删除数据库前，有提示。 显示当前mysql版本和当前日期 select version(),current_date; 2、修改mysql中root的密码：shell&gt;mysql -u root -p mysql&gt; update user set password=password(”xueok654123″) where user=’root’; mysql&gt; flush privileges //刷新数据库 mysql&gt;use dbname； 打开数据库： mysql&gt;show databases; 显示所有数据库 mysql&gt;show tables; 显示数据库mysql中所有的表：先use mysql；然后 mysql&gt;describe user; 显示表mysql数据库中user表的列信息）； 3、grant创建一个可以从任何地方连接服务器的一个完全的超级用户，但是必须使用一个口令something做这个 mysql&gt; grant all privileges on . to user@localhost identified by ’something’ with 增加新用户 格式：grant select on 数据库.* to 用户名@登录主机 identified by “密码” GRANT ALL PRIVILEGES ON . TO monty@localhost IDENTIFIED BY ’something’ WITH GRANT OPTION; GRANT ALL PRIVILEGES ON . TO monty@”%” IDENTIFIED BY ’something’ WITH GRANT OPTION; 删除授权： mysql&gt; revoke all privileges on . from root@”%”; mysql&gt; delete from user where user=”root” and host=”%”; mysql&gt; flush privileges; 创建一个用户custom在特定客户端it363.com登录，可访问特定数据库fangchandb mysql &gt;grant select, insert, update, delete, create,drop on fangchandb.* to custom@ it363.com identified by ‘ passwd’ 重命名表: mysql &gt; alter table t1 rename t2; 4、mysqldump备份数据库 shell&gt; mysqldump -h host -u root -p dbname &gt;dbname_backup.sql 恢复数据库 shell&gt; mysqladmin -h myhost -u root -p create dbname shell&gt; mysqldump -h host -u root -p dbname &lt; dbname_backup.sql 如果只想卸出建表指令，则命令如下： shell&gt; mysqladmin -u root -p -d databasename &gt; a.sql 如果只想卸出插入数据的sql命令，而不需要建表命令，则命令如下： shell&gt; mysqladmin -u root -p -t databasename &gt; a.sql 那么如果我只想要数据，而不想要什么sql命令时，应该如何操作呢？ mysqldump -T./ phptest driver 其中，只有指定了-T参数才可以卸出纯文本文件，表示卸出数据的目录，./表示当前目录，即与mysqldump同一目录。如果不指定driver 表，则将卸出整个数据库的数据。每个表会生成两个文件，一个为.sql文件，包含建表执行。另一个为.txt文件，只包含数据，且没有sql指令。 数据库常用基本命令_增删改查 、排序数据库常用基本命令：show databases； #查看数据库 use + 数据库名称； #进入数据库 show tables； #查看对应数据库中的表 select from info； #查看info表中的数据， 代表所有数据 select 字段 from 表； #查看指定的数据，从表中查看 创建数据库create database school ; #创建school数据库 创建表：一定要进入到数据库中举例： create table info (id int not null primary key auto_increment,name char (10) not null,score decimal(5,2),hobby int (2)) ; #创建一个名为info的数据表，表的属性（id 类型为int 不能为空null 为主键 自增列，name char（字符串长度为10）不为null空值，成绩 最大5位数字其中两位小数，hobby 类型为int（2字节））; PS详解： 创建表（表的属性） not null：不为空值 primary key：主键 auto_increment: 自增列 char：定长字符串类型 说明:M为最大可存储字节数 汉子占两个字节，通过指定m，来限制存储的最大字符数长度，char(20)和varchar(20)将最多只能存储20个字符，超过的字符将会被截掉。m必须小于该类型允许的最大字符数。 decimal(5,2)：定点精度和小数位数。【最大5位数字，其中两位小数】 5是(有效位数：可储存的最大十进位数总数，小数点左右两侧都包括在内。有效位数必须是 1 至最大有效位数 38 之间的值。） 2是 (小数位数：小数点右侧所能储存的最大十进位数。小数位数必须是从 0 到 4 的值。只有在指定了有效位数时，才能指定小数位数。预设小数位数是 0；因此，0 &lt;= 1 &lt;= 4。最大储存体大小会随著有效位数而不同。) 常用基本命令insert into info(id,name,score,hobby) values(1,’zhangsan’,95,1); #表后面插入数据 语法 ：insert into 表名(列,列,列) values(填入的数据,‘填入的数据’, 填入的数据); select * from info where id=2; #条件筛选，where代表的是条件 update info set score=75 where id=6; #修改表中的信息 ，set代表的是列，where代表的是条件 delete from info where name=’test’; #删除条件为name=‘test’的行 alter table test01 rename info01; #修改表名 alter table info change name username varchar(10) unique key; #修改信息名，并设置约束 insert into info(id,name,score) values(6,’test’,null); #插入数据 insert into hob (sid,hobname) values (2,’聊天’),(3,’运动’)，(4,’游戏’); #连续添加 Select * from info where id=6; #条件筛选 delete from info where name=’test’; #删除条件为name=’test’的那一行的全部信息。 select * from info where 1=1 order by score(asc升序)（desc降序）; #排序（升序/降序） desc info; #查看表结构 select info.name,info.score,hob.hobname from info inner join hob where info.hobby=hob.id; select username from info where hobby=(select sid from hob where hobname=’游泳’); #多表查询 select a.name,a.score,b.hobname from info a inner join hob b where a.hobby=b.id; #别名查询 create table infos select a.name,a.score,b.hobname from info a inner join hob b where a.hobby=b.id; #新建表infos内容为多表查询结果 drop database infos; #删除infos表 排序：升序 order by asc select * from info where 1=1 order by score asc; # where 1=1 order by score 默认是asc升序。 降序order by desc select * from info where 1=1 order by score desc; ===========查询============ desc info ; 查看info表结构 select #查询 多表相连查询 select * from info inner join hob where info.hobby=hob.id; #表示查询info表和hob表，inner join是固定语法。 #多表查询，查看info的name列和红包列 select info.name,info.score,hob.hobname from info inner join hob where info.hobby #多表查询结果创建为新的表格 名为infos create tables infos select info.name,info.score,hob.hobname from info inner join hob where info.hobby #创建别名查询 select a.name,a.score,b.hobname from info a inner join hob b where a.hobby=b.id;]]></content>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python常用的数据库之_mysql基础篇]]></title>
    <url>%2F2019%2F02%2F18%2Fpython%E5%B8%B8%E7%94%A8%E7%9A%84%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B9%8B%E4%B8%80mysql%E5%9F%BA%E7%A1%80%E7%AF%87%2F</url>
    <content type="text"><![CDATA[一 、数据表的设计1.原理：在表中为了更加准确的存储数据，保证数据的正确有效，可以在创建表的时候，为表添加一些强制性的验证，包括数据字段的类型、约束。 1） 字段类型​ 在mysql中包含的数据类型很多，这里主要列出来常用的几种 数字：int,decimal(小数的)；例如decimal(5,2)的意思是，最大5位数，其中小数2位，1.2和2.33都行，但10000.21就不行，超出位数了 字符串：char ,varchar,texttext存储比较多的字符串，比如商品的描述信息 char存储的是固定的字符串数据 varchar存储的是可变的数据 存储的是字符char(8)存储的数据不满8个字符会在右侧自动补上空格字符–&gt;”abcd “ 使用场景存手机号码固定的就可以使用char(11)varchar(8)存储数据不满8个字符，不会自动空格字符–&gt;“abcd”例如:存姓名用varchar(8)日期：datetime,date,time 1987-07-24布尔：bit(比如性别，数据是否删除) bit(8)八个二进制位存储性别的时候：存储0或者1开销少如果存储male和female开销大两个状态存储的时间建议使用存储0和1方式2） 约束–主键、非空、惟一，默认值，外键，自动增长 约束就是限制的条件主键primary key；不能重复，唯一标识，物理的存储方式，速度快非空not null；比如要姓名不能为空，当保存为null的时候就会报错。惟一unique；这个值是唯一的。有重复的了会报错（比如身份证）默认default；如果不写就会有个默认值，这种叫默认,只有类型。外键foreign key 二 、数据库的安装安装MySQL服务端和客户端 1.检查mysql安装情况 ps -ajx|grep mysql 查看进程方式查看 Mysql -uroot -p你的密码 进入mysql代表安装成功sudo service mysql start 开启服务sudo service mysql stop 停止服务Sudo service mysql restart 重启服务 2&gt;1、 进入数据库mysql –u用户名 –p你的密码2、 查看所有的数据库show databases3、使用mysql数据库use mysql4、查看mysql库中所有的表show tables5、在user 这个表里面查看用户和用户权限字段select user,host from user;6、为数据库创建新用户并且赋予权限允许外部链接grant all privileges on . to 用户名@”%” identified by “用户名密码” with grant option;7、 删除原来初始创建的root用户delete from user where user=’root’ and host = ‘localhost’;8、刷新数据库特权flush privileges;9、打开配置文件，将bind_address修改为0.0.0.0sudo vi /etc/mysql/mysql.conf.d/mysqld.conf10.重启mysql服务，使用windows下客户端进行连接 3&gt;数据库命令行操作1.查看所有数据库show databases;2.切换数据库use [数据库名];3.创建数据库create database [数据库名] ;4.删除数据库drop database [数据库名];5.对表的操作查看所有表show tables;6.创建表create table [表名]（字段1 类型1 约束1，字段2 类型2 约束2）;7.删除表drop table [表名]8.修改表名字rename table [表名] to [新名] 对字段的操作9.查询字段(表结构)desc [表名]10.增加表的字段alter table [表明]add [字段名 类型 约束]11.删除字段alter table [表名]drop[字段名]12.修改字段alter table [表名] change [字段名] [新字段名 类型 约束]① 、alter table students change id id int;②、alter table students drop primary key; 对数据的操作13.增加数据插入一个全字段insert into students values(0,’xxx’,31,1)插入多个全字段insert into students values(0,’liudehua’,24,0),(0,’yangmi’,31,0)插入一个部分字段insert into students(id,name) values(0,’zhaoliying’)插入多个部分字段insert into students(id,name) values(0,’liushishi’),(0,’linzhiling’)14.删除某一条delete from students where id=1;15.清空delete from students;16.修改数据update student set name=’xxx’ where name=’liudehua’17.查找所有数据select * from students18.数据库备份和恢复备份： sudo mysqldump –u数据库名 –p数据库密码 备份文件夹名&gt; ~/Desktop/文件夹名back.sql恢复：进入mysql先要创建一个新的数据库，注意字符集然后退出mysql sudo mysql –u数据库名 –p数据库密码 &lt; ~/Desktop/备份文件夹名back.sql]]></content>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python3数据库分类和比较（入门）]]></title>
    <url>%2F2019%2F02%2F18%2Fpython3%E6%95%B0%E6%8D%AE%E5%BA%93%E5%88%86%E7%B1%BB%E5%92%8C%E6%AF%94%E8%BE%83%EF%BC%88%E5%85%A5%E9%97%A8%EF%BC%89%2F</url>
    <content type="text"><![CDATA[目录：一、关系型数据库（一）常用关系型数据库：二、非关系型数据库（一）常用非关系型数据库：（二）分类：文档型key-value型列式数据库图形数据库一、关系型数据库（一）常用关系型数据库：MySQL、SQL-Server、SQLite、MariaDB、ORACLE、PostgreSQL、…二、非关系型数据库（一）常用非关系型数据库：CouchDB、MongoDB、 Redis、Voldemort、Oracle、Cassandra、HBase、Riak、Neo4j、InfoGrid、Infinite Graph、 …（二）分类：文档型举例 CouchDB、MongoDB典型应用场景 Web应用（与Key-Value类似，Value是结构化的，不同的是数据库能够了解Value的内容）数据模型 Key-Value为对应的键值对，Value为结构化数据强项 数据结构要求不严格，表结构可变，不需要预先定于表结构弱项 查询性能不高，而且缺乏统一的查询语法key-value型举例 Redis、Voldemort、Oracle Berkeley DB典型应用场景 内容缓存，主要用于处理大量数据的高访问负载，也用于一些日志系统等数据模型 Key指向Value的键值对，通常用hash table来实现强项 查询速度快弱项 数据无结构化，通常只被当作字符串或者二进制数据列式数据库举例 Cassandra、HBase、Riak典型应用场景 分布式的文件系统数据模型 以列簇式存储，将同一列数据存在一起强项 查询速度快，可扩展性强，更容易进行分布式扩展弱项 功能相对局限图形数据库举例 Neo4j、InfoGrid、Infinite Graph典型应用场景 专注于构建关系图谱，如社交网络，推荐系统等数据模型 图结构强项 利用图结构相关算法。如最短路径寻址、N度关系查找等 弱项 很多时候需要对整个图做计算才能得出需要的信息，而且这种结构不太好做分布式的集群方案]]></content>
      <tags>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[请求包含哪几个部分（请求行、请求头、请求体）]]></title>
    <url>%2F2019%2F02%2F18%2F%E8%AF%B7%E6%B1%82%E5%8C%85%E5%90%AB%E5%93%AA%E5%87%A0%E4%B8%AA%E9%83%A8%E5%88%86%EF%BC%88%E8%AF%B7%E6%B1%82%E8%A1%8C%E3%80%81%E8%AF%B7%E6%B1%82%E5%A4%B4%E3%80%81%E8%AF%B7%E6%B1%82%E4%BD%93%EF%BC%89%2F</url>
    <content type="text"><![CDATA[http 请求包含哪几个部分（请求行、请求头、请求体）http协议报文 ​ 1.请求报文(请求行/请求头/请求数据/空行) ​ 请求行 ​ 求方法字段、URL字段和HTTP协议版本 ​ 例如：GET /index.html HTTP/1.1 ​ get方法将数据拼接在url后面，传递参数受限 ​ 请求方法： ​ GET、POST、HEAD、PUT、DELETE、OPTIONS、TRACE、CONNECT ​ 请求头(key value形式) ​ User-Agent：产生请求的浏览器类型。 ​ Accept：客户端可识别的内容类型列表。 ​ Host：主机地址 ​ 请求数据 ​ post方法中，会把数据以key value形式发送请求 ​ 空行 ​ 发送回车符和换行符，通知服务器以下不再有请求头 ​ 2.响应报文(状态行、消息报头、响应正文) ​ 状态行 ​ 消息报头 ​ 响应正文 例如请求数据： 1 GET/sample.jspHTTP/1.1 2 Accept:image/gif.image/jpeg,/ 3 Accept-Language:zh-cn 4 Connection:Keep-Alive 5 Host:localhost 6 User-Agent:Mozila/4.0(compatible;MSIE5.01;Window NT5.0) 7 Accept-Encoding:gzip,deflate 8 9 username=jinqiao&amp;password=1234 第一行为http请求行，包含方法，URI 和http版本 2-7为请求头，包含浏览器，主机，接受的编码方式和压缩方式 第8行表示一个空行 表示请求头结束 这个空行是必须的 第9行是数据体，比如是需要查询的信息。 http响应体由三部分组成： http响应由三个部分组成分别是状态行，响应头，响应正文。 状态行是由：HTTP-Version+Status-Code+Reason-Phrase 比如：HTTP/1.1 200 ok 分别表示http版本 + 状态码 + 状态代码的文本描述 状态码： 1xx 指示信息–表示请求已接收，继续处理 2xx 成功–表示请求已被成功接收、理解、接受 3xx 重定向–要完成请求必须进行更进一步的操作。 4xx 客户端错误–请求有语法错误或请求无法实现。 5xx 服务器端错误–服务器未能实现合法的请求。 响应头：包含服务器类型，日期，长度，内容类型等 Server:Apache Tomcat/5.0.12 Date:Mon,6Oct2003 13:13:33 GMT Content-Type:text/html Last-Moified:Mon,6 Oct 2003 13:23:42 GMT Content-Length:112 响应正文响应正文就是服务器返回的HTML页面或者json数据 一次完整的HTTP请求过程当我们在浏览器的地址栏输入 www.linux178.com ，然后回车，回车这一瞬间到看到页面到底发生了什么呢？ 以下过程仅是个人理解： 域名解析 –&gt; 发起TCP的3次握手 –&gt; 建立TCP连接后发起http请求 –&gt; 服务器响应http请求，浏览器得到html代码 –&gt; 浏览器解析html代码，并请求html代码中的资源（如js、css、图片等） –&gt; 浏览器对页面进行渲染呈现给用户 关于HTTP协议可以参考以下： HTTP协议漫谈 http://kb.cnblogs.com/page/140611/ HTTP协议概览 http://www.cnblogs.com/vamei/archive/2013/05/11/3069788.html 了解HTTP Headers的方方面面 http://kb.cnblogs.com/page/55442/ 以下就是上面过程的一一分析，我们就以Chrome浏览器为例： 1.域名解析 首先Chrome浏览器会解析 www.linux178.com 这个域名（准确的叫法应该是主机名）对应的IP地址。怎么解析到对应的IP地址？ ① Chrome浏览器 会首先搜索浏览器自身的DNS缓存（缓存时间比较短，大概只有1分钟，且只能容纳1000条缓存），看自身的缓存中是否有www.linux178.com 对应的条目，而且没有过期，如果有且没有过期则解析到此结束。 ​ 注：我们怎么查看Chrome自身的缓存？可以使用 chrome://net-internals/#dns 来进行查看 ② 如果浏览器自身的缓存里面没有找到对应的条目，那么Chrome会搜索操作系统自身的DNS缓存,如果找到且没有过期则停止搜索解析到此结束. ​ 注：怎么查看操作系统自身的DNS缓存，以Windows系统为例，可以在命令行下使用 ipconfig /displaydns 来进行查看 ③ 如果在Windows系统的DNS缓存也没有找到，那么尝试读取hosts文件（位于C:\Windows\System32\drivers\etc），看看这里面有没有该域名对应的IP地址，如果有则解析成功。 ④ 如果在hosts文件中也没有找到对应的条目，浏览器就会发起一个DNS的系统调用，就会向本地配置的首选DNS服务器（一般是电信运营商提供的，也可以使用像Google提供的DNS服务器）发起域名解析请求（通过的是UDP协议向DNS的53端口发起请求，这个请求是递归的请求，也就是运营商的DNS服务器必须得提供给我们该域名的IP地址），运营商的DNS服务器首先查找自身的缓存，找到对应的条目，且没有过期，则解析成功。如果没有找到对应的条目，则有运营商的DNS代我们的浏览器发起迭代DNS解析请求，它首先是会找根域的DNS的IP地址（这个DNS服务器都内置13台根域的DNS的IP地址），找打根域的DNS地址，就会向其发起请求（请问www.linux178.com这个域名的IP地址是多少啊？），根域发现这是一个顶级域com域的一个域名，于是就告诉运营商的DNS我不知道这个域名的IP地址，但是我知道com域的IP地址，你去找它去，于是运营商的DNS就得到了com域的IP地址，又向com域的IP地址发起了请求（请问www.linux178.com这个域名的IP地址是多少?）,com域这台服务器告诉运营商的DNS我不知道www.linux178.com这个域名的IP地址，但是我知道linux178.com这个域的DNS地址，你去找它去，于是运营商的DNS又向linux178.com这个域名的DNS地址（这个一般就是由域名注册商提供的，像万网，新网等）发起请求（请问www.linux178.com这个域名的IP地址是多少？），这个时候linux178.com域的DNS服务器一查，诶，果真在我这里，于是就把找到的结果发送给运营商的DNS服务器，这个时候运营商的DNS服务器就拿到了www.linux178.com这个域名对应的IP地址，并返回给Windows系统内核，内核又把结果返回给浏览器，终于浏览器拿到了www.linux178.com 对应的IP地址，该进行一步的动作了。 注：一般情况下是不会进行以下步骤的 如果经过以上的4个步骤，还没有解析成功，那么会进行如下步骤（以下是针对Windows操作系统）： ⑤ 操作系统就会查找NetBIOS name Cache（NetBIOS名称缓存，就存在客户端电脑中的），那这个缓存有什么东西呢？凡是最近一段时间内和我成功通讯的计算机的计算机名和Ip地址，就都会存在这个缓存里面。什么情况下该步能解析成功呢？就是该名称正好是几分钟前和我成功通信过，那么这一步就可以成功解析。 ⑥ 如果第⑤步也没有成功，那会查询WINS 服务器（是NETBIOS名称和IP地址对应的服务器） ⑦ 如果第⑥步也没有查询成功，那么客户端就要进行广播查找 ⑧ 如果第⑦步也没有成功，那么客户端就读取LMHOSTS文件（和HOSTS文件同一个目录下，写法也一样） 如果第八步还没有解析成功，那么就宣告这次解析失败，那就无法跟目标计算机进行通信。只要这八步中有一步可以解析成功，那就可以成功和目标计算机进行通信。 看下图抓包截图： Linux虚拟机测试，使用命令 wget www.linux178.com 来请求，发现直接使用chrome浏览器请求时，干扰请求比较多，所以就使用wget命令来请求，不过使用wget命令只能把index.html请求回来，并不会对index.html中包含的静态资源（js、css等文件）进行请求。 抓包分析： ① 号包，这个是那台虚拟机在广播，要获取192.168.100.254（也就是网关）的MAC地址，因为局域网的通信靠的是MAC地址，它为什么需要跟网关进行通信是因为我们的DNS服务器IP是外围IP，要出去必须要依靠网关帮我们出去才行。 ② 号包，这个是网关收到了虚拟机的广播之后，回应给虚拟机的回应，告诉虚拟机自己的MAC地址，于是客户端找到了路由出口。 ③ 号包，这个包是wget命令向系统配置的DNS服务器提出域名解析请求（准确的说应该是wget发起了一个DNS解析的系统调用），请求的域名www.linux178.com,期望得到的是IP6的地址（AAAA代表的是IPv6地址） ④ 号包，这个DNS服务器给系统的响应，很显然目前使用IPv6的还是极少数，所以得不到AAAA记录的 ⑤ 号包，这个还是请求解析IPv6地址，但是www.linux178.com.leo.com这个主机名是不存在的，所以得到结果就是no such name ⑥ 号包，这个才是请求的域名对应的IPv4地址（A记录） ⑦ 号包，DNS服务器不管是从缓存里面，还是进行迭代查询最终得到了域名的IP地址，响应给了系统，系统再给了wget命令，wget于是得到了www.linux178.com的IP地址，这里也可以看出客户端和本地的DNS服务器是递归的查询（也就是服务器必须给客户端一个结果）这就可以开始下一步了，进行TCP的三次握手。 2.发起TCP的3次握手 拿到域名对应的IP地址之后，User-Agent（一般是指浏览器）会以一个随机端口（1024 &lt; 端口 &lt; 65535）向服务器的WEB程序（常用的有httpd,nginx等）80端口发起TCP的连接请求。这个连接请求（原始的http请求经过TCP/IP4层模型的层层封包）到达服务器端后（这中间通过各种路由设备，局域网内除外），进入到网卡，然后是进入到内核的TCP/IP协议栈（用于识别该连接请求，解封包，一层一层的剥开），还有可能要经过Netfilter防火墙（属于内核的模块）的过滤，最终到达WEB程序（本文就以Nginx为例），最终建立了TCP/IP的连接。 如下图： 1） Client首先发送一个连接试探，ACK=0 表示确认号无效，SYN = 1 表示这是一个连接请求或连接接受报文，同时表示这个数据报不能携带数据，seq = x 表示Client自己的初始序号（seq = 0 就代表这是第0号包），这时候Client进入syn_sent状态，表示客户端等待服务器的回复 2） Server监听到连接请求报文后，如同意建立连接，则向Client发送确认。TCP报文首部中的SYN 和 ACK都置1 ，ack = x + 1表示期望收到对方下一个报文段的第一个数据字节序号是x+1，同时表明x为止的所有数据都已正确收到（ack=1其实是ack=0+1,也就是期望客户端的第1个包），seq = y 表示Server 自己的初始序号（seq=0就代表这是服务器这边发出的第0号包）。这时服务器进入syn_rcvd，表示服务器已经收到Client的连接请求，等待client的确认。 3） Client收到确认后还需再次发送确认，同时携带要发送给Server的数据。ACK 置1 表示确认号ack= y + 1 有效（代表期望收到服务器的第1个包），Client自己的序号seq= x + 1（表示这就是我的第1个包，相对于第0个包来说的），一旦收到Client的确认之后，这个TCP连接就进入Established状态，就可以发起http请求了。 看抓包截图： ⑨ 号包 这个就是对应上面的步骤 1） ⑩ 号包 这个对应的上面的步骤 2） 号包 这个对应的上面的步骤 3） TCP 为什么需要3次握手？ 举个例子： 假设一个老外在故宫里面迷路了，看到了小明，于是就有下面的对话： 老外： Excuse me，Can you Speak English? 小明： yes 。 老外： OK,I want … 在问路之前，老外先问小明是否会说英语，小明回答是的，这时老外才开始问路 2个计算机通信是靠协议（目前流行的TCP/IP协议）来实现,如果2个计算机使用的协议不一样，那是不能进行通信的，所以这个3次握手就相当于试探一下对方是否遵循TCP/IP协议，协商完成后就可以进行通信了，当然这样理解不是那么准确。 为什么HTTP协议要基于TCP来实现？ 目前在Internet中所有的传输都是通过TCP/IP进行的，HTTP协议作为TCP/IP模型中应用层的协议也不例外，TCP是一个端到端的可靠的面向连接的协议，所以HTTP基于传输层TCP协议不用担心数据的传输的各种问题。 3.建立TCP连接后发起http请求 进过TCP3次握手之后，浏览器发起了http的请求（看第包），使用的http的方法 GET 方法，请求的URL是 / ,协议是HTTP/1.0 下面是第12号包的详细内容： 以上的报文是HTTP请求报文。 那么HTTP请求报文和响应报文会是什么格式呢？ 起始行：如 GET / HTTP/1.0 （请求的方法 请求的URL 请求所使用的协议） 头部信息：User-Agent Host等成对出现的值 主体 不管是请求报文还是响应报文都会遵循以上的格式。 那么起始行中的请求方法有哪些种呢？ GET: 完整请求一个资源 （常用） HEAD: 仅请求响应首部 POST：提交表单 （常用） PUT: (webdav) 上传文件（但是浏览器不支持该方法） DELETE：(webdav) 删除 OPTIONS：返回请求的资源所支持的方法的方法 TRACE: 追求一个资源请求中间所经过的代理（该方法不能由浏览器发出） 那什么是URL、URI、URN？ URI Uniform Resource Identifier 统一资源标识符 URL Uniform Resource Locator 统一资源定位符 ​ 格式如下： scheme://[username:password@]HOST:port/path/to/source ​ http://www.magedu.com/downloads/nginx-1.5.tar.gz URN Uniform Resource Name 统一资源名称 URL和URN 都属于 URI 为了方便就把URL和URI暂时都通指一个东西 请求的协议有哪些种？ 有以下几种： http/0.9: stateless http/1.0: MIME, keep-alive (保持连接), 缓存 http/1.1: 更多的请求方法，更精细的缓存控制，持久连接(persistent connection) 比较常用 下面是Chrome发起的http请求报文头部信息 其中 Accept 就是告诉服务器端，我接受那些MIME类型 Accept-Encoding 这个看起来是接受那些压缩方式的文件 Accept-Lanague 告诉服务器能够发送哪些语言 Connection 告诉服务器支持keep-alive特性 Cookie 每次请求时都会携带上Cookie以方便服务器端识别是否是同一个客户端 Host 用来标识请求服务器上的那个虚拟主机，比如Nginx里面可以定义很多个虚拟主机 ​ 那这里就是用来标识要访问那个虚拟主机。 User-Agent 用户代理，一般情况是浏览器，也有其他类型，如：wget curl 搜索引擎的蜘蛛等 条件请求首部： If-Modified-Since 是浏览器向服务器端询问某个资源文件如果自从什么时间修改过，那么重新发给我，这样就保证服务器端资源 ​ 文件更新时，浏览器再次去请求，而不是使用缓存中的文件 安全请求首部： Authorization: 客户端提供给服务器的认证信息； 什么是MIME？ MIME（Multipurpose Internet Mail Extesions 多用途互联网邮件扩展）是一个互联网标准，它扩展了电子邮件标准，使其能够支持非ASCII字符、二进制格式附件等多种格式的邮件消息，这个标准被定义在RFC 2045、RFC 2046、RFC 2047、RFC 2048、RFC 2049等RFC中。 由RFC 822转变而来的RFC 2822，规定电子邮件标准并不允许在邮件消息中使用7位ASCII字符集以外的字符。正因如此，一些非英语字符消息和二进制文件，图像，声音等非文字消息都不能在电子邮件中传输。MIME规定了用于表示各种各样的数据类型的符号化方法。 此外，在万维网中使用的HTTP协议中也使用了MIME的框架，标准被扩展为互联网媒体类型。 MIME 遵循以下格式：major/minor 主类型/次类型 例如： 1`image``/jpg``image``/gif``text``/html``video``/quicktime``appliation``/x-httpd-php` 4.服务器端响应http请求，浏览器得到html代码 看下图 第12号包是http请求包，第32包是http响应包 服务器端WEB程序接收到http请求以后，就开始处理该请求，处理之后就返回给浏览器html文件。 第32号包 是服务器返回给客户端http响应包（200 ok 响应的MIME类型是text/html），代表这一次客户端发起的http请求已成功响应。200 代表是的 响应成功的状态码，还有其他的状态码如下： 1xx: 信息性状态码 ​ 100, 101 2xx: 成功状态码 ​ 200：OK 3xx: 重定向状态码 ​ 301: 永久重定向, Location响应首部的值仍为当前URL，因此为隐藏重定向; ​ 302: 临时重定向，显式重定向, Location响应首部的值为新的URL ​ 304：Not Modified 未修改，比如本地缓存的资源文件和服务器上比较时，发现并没有修改，服务器返回一个304状态码， ​ 告诉浏览器，你不用请求该资源，直接使用本地的资源即可。 4xx: 客户端错误状态码 ​ 404: Not Found 请求的URL资源并不存在 5xx: 服务器端错误状态码 ​ 500: Internal Server Error 服务器内部错误 ​ 502: Bad Gateway 前面代理服务器联系不到后端的服务器时出现 ​ 504：Gateway Timeout 这个是代理能联系到后端的服务器，但是后端的服务器在规定的时间内没有给代理服务器响应 用Chrome浏览器看到的响应头信息： Connection 使用keep-alive特性 Content-Encoding 使用gzip方式对资源压缩 Content-type MIME类型为html类型，字符集是 UTF-8 Date 响应的日期 Server 使用的WEB服务器 Transfer-Encoding:chunked 分块传输编码 是http中的一种数据传输机制，允许HTTP由网页服务器发送给客户端应用（通常是网页浏览器）的数据可以分成多个部分，分块传输编码只在HTTP协议1.1版本（HTTP/1.1）中提供 Vary 这个可以参考（http://blog.csdn.NET/tenfyguo/article/details/5939000） X-Pingback 参考（http://blog.sina.com.cn/s/blog_bb80041c0101fmfz.html） 那到底服务器端接收到http请求后是怎么样生成html文件？ 假设服务器端使用nginx+PHP(fastcgi)架构提供服务 ① nginx读取配置文件 我们在浏览器的地址栏里面输入的是 http://www.linux178.com （http://可以不用输入，浏览器会自动帮我们添加），其实完整的应该是http://www.linux178.com./ 后面还有个点（这个点代表就是根域，一般情况下我们不用输入，也不显示）,后面的/也是不用添加，浏览器会自动帮我们添加（且看第3部那个图里面的URL），那么实际请求的URL是http://www.linux178.com/，那么好了Nginx在收到 浏览器 GET / 请求时，会读取http请求里面的头部信息，根据Host来匹配 自己的所有的虚拟主机的配置文件的server_name,看看有没有匹配的，有匹配那么就读取该虚拟主机的配置，发现如下配置： 1`root ``/web/echo` 通过这个就知道所有网页文件的就在这个目录下 这个目录就是/ 当我们http://www.linux178.com/时就是访问这个目录下面的文件，例如访问http://www.linux178.com/index.html,那么代表/web/echo下面有个文件叫index.html 1`index index.html index.htm index.php` 通过这个就能得知网站的首页文件是那个文件，也就是我们在入http://www.linux178.com/ ，nginx就会自动帮我们把index.html（假设首页是index.php 当然是会尝试的去找到该文件，如果没有找到该文件就依次往下找，如果这3个文件都没有找到，那么就抛出一个404错误）加到后面，那么添加之后的URL是/index.php,然后根据后面的配置进行处理 1`location ~ .*\.php(\/.*)*$ &#123;`` ``root ``/web/echo``;`` ``fastcgi_pass 127.0.0.1:9000;`` ``fastcgi_index index.php;`` ``astcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name;`` ``include fastcgi_params;``&#125;` 这一段配置指明凡是请求的URL中匹配（这里是启用了正则表达式进行匹配） *.php后缀的（后面跟的参数）都交给后端的fastcgi进程进行处理。 ② 把php文件交给fastcgi进程去处理 于是nginx把/index.php这个URL交给了后端的fastcgi进程处理，等待fastcgi处理完成后（结合数据库查询出数据，填充模板生成html文件）返回给nginx一个index.html文档，Nginx再把这个index.html返回给浏览器，于是乎浏览器就拿到了首页的html代码，同时nginx写一条访问日志到日志文件中去。 注1：nginx是怎么找index.php文件的？ 当nginx发现需要/web/echo/index.php文件时，就会向内核发起IO系统调用(因为要跟硬件打交道，这里的硬件是指硬盘，通常需要靠内核来操作，而内核提供的这些功能是通过系统调用来实现的)，告诉内核，我需要这个文件,内核从/开始找到web目录，再在web目录下找到echo目录，最后在echo目录下找到index.php文件，于是把这个index.php从硬盘上读取到内核自身的内存空间，然后再把这个文件复制到nginx进程所在的内存空间，于是乎nginx就得到了自己想要的文件了。 注2：寻找文件在文件系统层面是怎么操作的？ 比如nginx需要得到/web/echo/index.php这个文件 每个分区（像ext3 ext3等文件系统，block块是文件存储的最小单元 默认是4096字节）都是包含元数据区和数据区，每一个文件在元数据区都有元数据条目（一般是128字节大小），每一个条目都有一个编号，我们称之为inode（index node 索引节点），这个inode里面包含 文件类型、权限、连接次数、属主和数组的ID、时间戳、这个文件占据了那些磁盘块也就是块的编号（block，每个文件可以占用多个block,并且block不一定是连续的，每个block是有编号的），如下图所示： 还有一个要点：目录其实也普通是文件，也需要占用磁盘块，目录不是一个容器。你看默认创建的目录就是4096字节，也就说只需要占用一个磁盘块，但这是不确定的。所以要找到目录也是需要到元数据区里面找到对应的条目，只有找到对应的inode就可找到目录所占用的磁盘块。 那到底目录里面存放着什么，难道不是文件或者其他目录吗？ 其实目录存着这么一张表（姑且这么理解），里面放着 目录或者文件的名称和对应的inode号（暂时称之为映射表）,如下图： 假设 / 在数据区占据 1、2号block ，/其实也是一个目录 里面有3个目录 web 111 web 占据 5号block 是目录 里面有2个目录 echo data echo 占据 11号 block 是目录 里面有1个文件 index.php index.php 占据 15 16号 block 是文件 其在文件系统中分布如下图所示 那么内核究竟是怎么找到index.php这个文件的呢？ 内核拿到nginx的IO系统调用要获取/web/echo/index.php这个文件请求之后 ① 内核读取元数据区 / 的inode，从inode里面读取/所对应的数据块的编号，然后在数据区找到其对应的块（1 2号块），读取1号块上的映射表找到web这个名称在元数据区对应的inode号 ② 内核读取web对应的inode（3号），从中得知web在数据区对应的块是5号块，于是到数据区找到5号块，从中读取映射表，知道echo对应的inode是5号，于是到元数据区找到5号inode ③ 内核读取5号inode，得到echo在数据区对应的是11号块，于是到数据区读取11号块得到映射表，得到index.php对应的inode是9号 ④ 内核到元数据区读取9号inode，得到index.php对应的是15和16号数据块，于是就到数据区域找到15 16号块，读取其中的内容，得到index.php的完整内容 \5. 浏览器解析html代码，并请求html代码中的资源 浏览器拿到index.html文件后，就开始解析其中的html代码，遇到js/css/image等静态资源时，就向服务器端去请求下载（会使用多线程下载，每个浏览器的线程数不一样），这个时候就用上keep-alive特性了，建立一次HTTP连接，可以请求多个资源，下载资源的顺序就是按照代码里的顺序，但是由于每个资源大小不一样，而浏览器又多线程请求请求资源，所以从下图看出，这里显示的顺序并不一定是代码里面的顺序。 浏览器在请求静态资源时（在未过期的情况下），向服务器端发起一个http请求（询问自从上一次修改时间到现在有没有对资源进行修改），如果服务器端返回304状态码（告诉浏览器服务器端没有修改），那么浏览器会直接读取本地的该资源的缓存文件。 详细的浏览器工作原理请看：http://kb.cnblogs.com/page/129756/ 6.浏览器对页面进行渲染呈现给用户 最后，浏览器利用自己内部的工作机制，把请求到的静态资源和html代码进行渲染，渲染之后呈现给用户。 自此一次完整的HTTP事务宣告完成.]]></content>
      <tags>
        <tag>http</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JSON的三种解析方式]]></title>
    <url>%2F2019%2F02%2F18%2FJSON%E7%9A%84%E4%B8%89%E7%A7%8D%E8%A7%A3%E6%9E%90%E6%96%B9%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[一、什么是JSON？JSON是一种取代XML的数据结构,和xml相比,它更小巧但描述能力却不差,由于它的小巧所以网络传输数据将减少更多流量从而加快速度。 JSON就是一串字符串 只不过元素会使用特定的符号标注。 {} 双括号表示对象 [] 中括号表示数组 “” 双引号内是属性或值 : 冒号表示后者是前者的值(这个值可以是字符串、数字、也可以是另一个数组或对象) 所以 {“name”: “Michael”} 可以理解为是一个包含name为Michael的对象 而[{“name”: “Michael”},{“name”: “Jerry”}]就表示包含两个对象的数组 当然了,你也可以使用{“name”:[“Michael”,”Jerry”]}来简化上面一部,这是一个拥有一个name数组的对象 二、JSON解析之传统的JSON解析1、生成json字符串12345public static String createJsonString(String key, Object value) &#123; JSONObject jsonObject = new JSONObject(); jsonObject.put(key, value); return jsonObject.toString();&#125; 2、解析JSON字符串分为以下三种情况，一个JavaBean，一个List数组，一个嵌套Map的List数组： ;) 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293import java.util.ArrayList;import java.util.HashMap;import java.util.Iterator;import java.util.List;import java.util.Map;import org.json.JSONArray;import org.json.JSONObject;import com.android.myjson.domain.Person;/** * 完成对json数据的解析 * */public class JsonTools &#123; public static Person getPerson(String key, String jsonString) &#123; Person person = new Person(); try &#123; JSONObject jsonObject = new JSONObject(jsonString); JSONObject personObject = jsonObject.getJSONObject(&quot;person&quot;); person.setId(personObject.getInt(&quot;id&quot;)); person.setName(personObject.getString(&quot;name&quot;)); person.setAddress(personObject.getString(&quot;address&quot;)); &#125; catch (Exception e) &#123; // TODO: handle exception &#125; return person; &#125; public static List getPersons(String key, String jsonString) &#123; List list = new ArrayList(); try &#123; JSONObject jsonObject = new JSONObject(jsonString); // 返回json的数组 JSONArray jsonArray = jsonObject.getJSONArray(key); for (int i = 0; i &lt; jsonArray.length(); i++) &#123; JSONObject jsonObject2 = jsonArray.getJSONObject(i); Person person = new Person(); person.setId(jsonObject2.getInt(&quot;id&quot;)); person.setName(jsonObject2.getString(&quot;name&quot;)); person.setAddress(jsonObject2.getString(&quot;address&quot;)); list.add(person); &#125; &#125; catch (Exception e) &#123; // TODO: handle exception &#125; return list; &#125; public static List getList(String key, String jsonString) &#123; List list = new ArrayList(); try &#123; JSONObject jsonObject = new JSONObject(jsonString); JSONArray jsonArray = jsonObject.getJSONArray(key); for (int i = 0; i &lt; jsonArray.length(); i++) &#123; String msg = jsonArray.getString(i); list.add(msg); &#125; &#125; catch (Exception e) &#123; // TODO: handle exception &#125; return list; &#125; public static List&gt; listKeyMaps(String key, String jsonString) &#123; List&gt; list = new ArrayList&gt;(); try &#123; JSONObject jsonObject = new JSONObject(jsonString); JSONArray jsonArray = jsonObject.getJSONArray(key); for (int i = 0; i &lt; jsonArray.length(); i++) &#123; JSONObject jsonObject2 = jsonArray.getJSONObject(i); Map map = new HashMap(); Iterator iterator = jsonObject2.keys(); while (iterator.hasNext()) &#123; String json_key = iterator.next(); Object json_value = jsonObject2.get(json_key); if (json_value == null) &#123; json_value = &quot;&quot;; &#125; map.put(json_key, json_value); &#125; list.add(map); &#125; &#125; catch (Exception e) &#123; // TODO: handle exception &#125; return list; &#125;&#125; ;) 三、JSON解析之GSON1、生成JSON字符串;) 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192import com.google.gson.Gson;public class JsonUtils &#123; public static String createJsonObject(Object obj) &#123; Gson gson = new Gson(); String str = gson.toJson(obj); return str; &#125;&#125;二、解析JSONimport java.util.ArrayList;import java.util.List;import java.util.Map;import com.google.gson.Gson;import com.google.gson.reflect.TypeToken;;public class GsonTools &#123; public GsonTools() &#123; // TODO Auto-generated constructor stub &#125; /** * @param * @param jsonString * @param cls * @return */ public static T getPerson(String jsonString, Class cls) &#123; T t = null; try &#123; Gson gson = new Gson(); t = gson.fromJson(jsonString, cls); &#125; catch (Exception e) &#123; // TODO: handle exception &#125; return t; &#125; /** * 使用Gson进行解析 List * * @param * @param jsonString * @param cls * @return */ public static List getPersons(String jsonString, Class cls) &#123; List list = new ArrayList(); try &#123; Gson gson = new Gson(); list = gson.fromJson(jsonString, new TypeToken&gt;() &#123; &#125;.getType()); &#125; catch (Exception e) &#123; &#125; return list; &#125; /** * @param jsonString * @return */ public static List getList(String jsonString) &#123; List list = new ArrayList(); try &#123; Gson gson = new Gson(); list = gson.fromJson(jsonString, new TypeToken&gt;() &#123; &#125;.getType()); &#125; catch (Exception e) &#123; // TODO: handle exception &#125; return list; &#125; public static List&gt; listKeyMaps(String jsonString) &#123; List&gt; list = new ArrayList&gt;(); try &#123; Gson gson = new Gson(); list = gson.fromJson(jsonString, new TypeToken&gt;&gt;() &#123; &#125;.getType()); &#125; catch (Exception e) &#123; // TODO: handle exception &#125; return list; &#125;&#125; ;) 三、JSON解析之FastJSON;) 1234567891011121314151617181920212223242526272829303132333435363738394041424344import java.util.ArrayList;import java.util.List;import java.util.Map;import com.alibaba.fastjson.JSON;import com.alibaba.fastjson.TypeReference;public class JsonTool &#123; public static T getPerson(String jsonstring, Class cls) &#123; T t = null; try &#123; t = JSON.parseObject(jsonstring, cls); &#125; catch (Exception e) &#123; // TODO: handle exception &#125; return t; &#125; public static List getPersonList(String jsonstring, Class cls) &#123; List list = new ArrayList(); try &#123; list = JSON.parseArray(jsonstring, cls); &#125; catch (Exception e) &#123; // TODO: handle exception &#125; return list; &#125; public static List&gt; getPersonListMap1( String jsonstring) &#123; List&gt; list = new ArrayList&gt;(); try &#123; list = JSON.parseObject(jsonstring, new TypeReference&gt;&gt;() &#123; &#125;.getType()); &#125; catch (Exception e) &#123; // TODO: handle exception &#125; return list; &#125;&#125; ;) 总结：JSON对于移动设备来说，尤其对于网络环境较差和流量限制的情况下，相对于XML格式的数据传输会更节省流量，传输效率更高。在这三种解析方式中FastJson是效率最高的，推荐使用。]]></content>
      <tags>
        <tag>json</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[提高数据库查询速度的方法]]></title>
    <url>%2F2019%2F02%2F18%2F%E6%8F%90%E9%AB%98%E6%95%B0%E6%8D%AE%E5%BA%93%E6%9F%A5%E8%AF%A2%E9%80%9F%E5%BA%A6%E7%9A%84%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[处理百万级以上的数据提高查询速度的方法： 1.应尽量避免在 where 子句中使用!=或&lt;&gt;操作符，否则将引擎放弃使用索引而进行全表扫描。 2.对查询进行优化，应尽量避免全表扫描，首先应考虑在 where 及 order by 涉及的列上建立索引。 3.应尽量避免在 where 子句中对字段进行 null 值判断，否则将导致引擎放弃使用索引而进行全表扫描，如： ​ select id from t where num is null ​ 可以在num上设置默认值0，确保表中num列没有null值，然后这样查询： ​ select id from t where num=0 4.应尽量避免在 where 子句中使用 or 来连接条件，否则将导致引擎放弃使用索引而进行全表扫描，如： ​ select id from t where num=10 or num=20 ​ 可以这样查询： ​ select id from t where num=10 ​ union all ​ select id from t where num=20 5.下面的查询也将导致全表扫描：(不能前置百分号) ​ select id from t where name like ‘%abc%’ ​ 若要提高效率，可以考虑全文检索。 6.in 和 not in 也要慎用，否则会导致全表扫描，如： ​ select id from t where num in(1,2,3) ​ 对于连续的数值，能用 between 就不要用 in 了： ​ select id from t where num between 1 and 3 8.应尽量避免在 where 子句中对字段进行表达式操作，这将导致引擎放弃使用索引而进行全表扫描。如： ​ select id from t where num/2=100 ​ 应改为: ​ select id from t where num=100*2 9.应尽量避免在where子句中对字段进行函数操作，这将导致引擎放弃使用索引而进行全表扫描。如： ​ select id from t where substring(name,1,3)=’abc’–name以abc开头的id ​ select id from t where datediff(day,createdate,’2005-11-30′)=0–’2005-11-30′生成的id ​ 应改为: ​ select id from t where name like ‘abc%’ ​ select id from t where createdate&gt;=’2005-11-30′ and createdate&lt;’2005-12-1′ 10.不要在 where 子句中的“=”左边进行函数、算术运算或其他表达式运算，否则系统将可能无法正确使用索引。 11.在使用索引字段作为条件时，如果该索引是复合索引，那么必须使用到该索引中的第一个字段作为条件时才能保证系统使用该索引，否则该索引将不会被使 用，并且应尽可能的让字段顺序与索引顺序相一致。 12.不要写一些没有意义的查询，如需要生成一个空表结构： ​ select col1,col2 into #t from t where 1=0 ​ 这类代码不会返回任何结果集，但是会消耗系统资源的，应改成这样： ​ create table #t(…) 13.很多时候用 exists 代替 in 是一个好的选择： ​ select num from a where num in(select num from b) ​ 用下面的语句替换： ​ select num from a where exists(select 1 from b where num=a.num) 14.并不是所有索引对查询都有效，SQL是根据表中数据来进行查询优化的，当索引列有大量数据重复时，SQL查询可能不会去利用索引，如一表中有字段 sex，male、female几乎各一半，那么即使在sex上建了索引也对查询效率起不了作用。 15.索引并不是越多越好，索引固然可以提高相应的 select 的效率，但同时也降低了 insert 及 update 的效率，因为 insert 或 update 时有可能会重建索引，所以怎样建索引需要慎重考虑，视具体情况而定。一个表的索引数最好不要超过6个，若太多则应考虑一些不常使用到的列上建的索引是否有 必要。 16.应尽可能的避免更新 clustered 索引数据列，因为 clustered 索引数据列的顺序就是表记录的物理存储顺序，一旦该列值改变将导致整个表记录的顺序的调整，会耗费相当大的资源。若应用系统需要频繁更新 clustered 索引数据列，那么需要考虑是否应将该索引建为 clustered 索引。 17.尽量使用数字型字段，若只含数值信息的字段尽量不要设计为字符型，这会降低查询和连接的性能，并会增加存储开销。这是因为引擎在处理查询和连接时会 逐个比较字符串中每一个字符，而对于数字型而言只需要比较一次就够了。 18.尽可能的使用 varchar/nvarchar 代替 char/nchar ，因为首先变长字段存储空间小，可以节省存储空间，其次对于查询来说，在一个相对较小的字段内搜索效率显然要高些。 19.任何地方都不要使用 select from t ，用具体的字段列表代替“”，不要返回用不到的任何字段。 20.尽量使用表变量来代替临时表。如果表变量包含大量数据，请注意索引非常有限（只有主键索引）。 21.避免频繁创建和删除临时表，以减少系统表资源的消耗。 22.临时表并不是不可使用，适当地使用它们可以使某些例程更有效，例如，当需要重复引用大型表或常用表中的某个数据集时。但是，对于一次性事件，最好使 用导出表。 23.在新建临时表时，如果一次性插入数据量很大，那么可以使用 select into 代替 create table，避免造成大量 log ，以提高速度；如果数据量不大，为了缓和系统表的资源，应先create table，然后insert。 24.如果使用到了临时表，在存储过程的最后务必将所有的临时表显式删除，先 truncate table ，然后 drop table ，这样可以避免系统表的较长时间锁定。 25.尽量避免使用游标，因为游标的效率较差，如果游标操作的数据超过1万行，那么就应该考虑改写。 26.使用基于游标的方法或临时表方法之前，应先寻找基于集的解决方案来解决问题，基于集的方法通常更有效。 27.与临时表一样，游标并不是不可使用。对小型数据集使用 FAST_FORWARD 游标通常要优于其他逐行处理方法，尤其是在必须引用几个表才能获得所需的数据时。在结果集中包括“合计”的例程通常要比使用游标执行的速度快。如果开发时 间允许，基于游标的方法和基于集的方法都可以尝试一下，看哪一种方法的效果更好。 28.在所有的存储过程和触发器的开始处设置 SET NOCOUNT ON ，在结束时设置 SET NOCOUNT OFF 。无需在执行存储过程和触发器的每个语句后向客户端发送 DONE_IN_PROC 消息。 29.尽量避免向客户端返回大数据量，若数据量过大，应该考虑相应需求是否合理。 30.尽量避免大事务操作，提高系统并发能力。 查询速度慢的原因： 1、没有索引或者没有用到索引(这是查询慢最常见的问题，是程序设计的缺陷) 2、I/O吞吐量小，形成了瓶颈效应。 3、没有创建计算列导致查询不优化。 4、内存不足 5、网络速度慢 6、查询出的数据量过大（可以采用多次查询，其他的方法降低数据量） 7、锁或者死锁(这也是查询慢最常见的问题，是程序设计的缺陷) 8、sp_lock,sp_who,活动的用户查看,原因是读写竞争资源。 9、返回了不必要的行和列 10、查询语句不好，没有优化 可以通过如下方法来优化查询 1、把数据、日志、索引放到不同的I/O设备上，增加读取速度，以前可以将Tempdb应放在RAID0上，SQL2000不在支持。数据量（尺寸）越大，提高I/O越重要. 2、纵向、横向分割表，减少表的尺寸(sp_spaceuse) 3、升级硬件 4、根据查询条件,建立索引,优化索引、优化访问方式，限制结果集的数据量。注意填充因子要适当（最好是使用默认值0）。索引应该尽量小，使用字节数小的列建索引好（参照索引的创建）,不要对有限的几个值的字段建单一索引如性别字段 5、提高网速; 6、扩大服务器的内存,Windows 2000和SQL server 2000能支持4-8G的内存。配置虚拟内存：虚拟内存大小应基于计算机上并发运行的服务进行配置。运行 Microsoft SQL Server? 2000 时，可考虑将虚拟内存大小设置为计算机中安装的物理内存的 1.5 倍。如果另外安装了全文检索功能，并打算运行 Microsoft 搜索服务以便执行全文索引和查询，可考虑：将虚拟内存大小配置为至少是计算机中安装的物理内存的 3 倍。将 SQL Server max server memory 服务器配置选项配置为物理内存的 1.5 倍（虚拟内存大小设置的一半）。 7、增加服务器CPU个数;但是必须明白并行处理串行处理更需要资源例如内存。使用并行还是串行程是MsSQL自动评估选择的。单个任务分解成多个 任务，就可以在处理器上运行。例如耽搁查询的排序、连接、扫描和GROUP BY字句同时执行，SQL SERVER根据系统的负载情况决定最优的并行等级，复杂的需要消耗大量的CPU的查询最适合并行处理。但是更新操作UPDATE,INSERT， DELETE还不能并行处理。 8、如果是使用like进行查询的话，简单的使用index是不行的，但是全文索引，耗空间。 like ‘a%’ 使用索引 like ‘%a’ 不使用索引用 like ‘%a%’ 查询时，查询耗时和字段值总长度成正比,所以不能用CHAR类型，而是VARCHAR。对于字段的值很长的建全文索引。 9、DB Server 和APPLication Server 分离；OLTP和OLAP分离 10、分布式分区视图可用于实现数据库服务器联合体。联合体是一组分开管理的服务器，但它们相互协作分担系统的处理负荷。这种通过分区数据形成数据 库服务器联合体的机制能够扩大一组服务器，以支持大型的多层 Web 站点的处理需要。有关更多信息，参见设计联合数据库服务器。（参照SQL帮助文件’分区视图’） ​ a、在实现分区视图之前，必须先水平分区表 ​ b、在创建成员表后，在每个成员服务器上定义一个分布式分区视图，并且每个视图具有相同的名称。这样，引用分布式分区视图名的查询可以在任何一个成员服务 器上运行。系统操作如同每个成员服务器上都有一个原始表的复本一样，但其实每个服务器上只有一个成员表和一个分布式分区视图。数据的位置对应用程序是透明 的。 11、重建索引 DBCC REINDEX ,DBCC INDEXDEFRAG,收缩数据和日志 DBCC SHRINKDB,DBCC SHRINKFILE. 设置自动收缩日志.对于大的数据库不要设置数据库自动增长，它会降低服务器的性能。 在T-sql的写法上有很大的讲究，下面列出常见的要点：首先，DBMS处理查询计划的过程是这样的： ​ 1、 查询语句的词法、语法检查 ​ 2、 将语句提交给DBMS的查询优化器 ​ 3、 优化器做代数优化和存取路径的优化 ​ 4、 由预编译模块生成查询规划 ​ 5、 然后在合适的时间提交给系统处理执行 ​ 6、 最后将执行结果返回给用户其次，看一下SQL SERVER的数据存放的结构：一个页面的大小为8K(8060)字节，8个页面为一个盘区，按照B树存放。 12、Commit和rollback的区别 Rollback:回滚所有的事物。 Commit:提交当前的事物. 没有必要在动态SQL里写事物，如果要写请写在外面如： begin tran exec(@s) commit trans 或者将动态SQL 写成函数或者存储过程。 13、在查询Select语句中用Where字句限制返回的行数,避免表扫描,如果返回不必要的数据，浪费了服务器的I/O资源，加重了网络的负担降低性能。如果表很大，在表扫描的期间将表锁住，禁止其他的联接访问表,后果严重。 14、SQL的注释申明对执行没有任何影响 15、尽可能不使用游标，它占用大量的资源。如果需要row-by-row地执行，尽量采用非光标技术,如：在客户端循环，用临时表，Table变 量，用子查询，用Case语句等等。游标可以按照它所支持的提取选项进行分类： 只进 必须按照从第一行到最后一行的顺序提取行。FETCH NEXT 是唯一允许的提取操作,也是默认方式。可滚动性 可以在游标中任何地方随机提取任意行。游标的技术在SQL2000下变得功能很强大，他的目的是支持循环。 有四个并发选项 READ_ONLY：不允许通过游标定位更新(Update)，且在组成结果集的行中没有锁。 OPTIMISTIC WITH valueS:乐观并发控制是事务控制理论的一个标准部分。乐观并发控制用于这样的情形，即在打开游标及更新行的间隔中，只有很小的机会让第二个用户更新 某一行。当某个游标以此选项打开时，没有锁控制其中的行，这将有助于最大化其处理能力。如果用户试图修改某一行，则此行的当前值会与最后一次提取此行时获 取的值进行比较。如果任何值发生改变，则服务器就会知道其他人已更新了此行，并会返回一个错误。如果值是一样的，服务器就执行修改。 选择这个并发选项OPTIMISTIC WITH ROW VERSIONING:此乐观并发控制选项基于行版本控制。使用行版本控制，其中的表必须具有某种版本标识符，服务器可用它来确定该行在读入游标后是否有 所更改。 在 SQL Server 中，这个性能由 timestamp 数据类型提供，它是一个二进制数字，表示数据库中更改的相对顺序。每个数据库都有一个全局当前时间戳值：@@DBTS。每次以任何方式更改带有 timestamp 列的行时，SQL Server 先在时间戳列中存储当前的 @@DBTS 值，然后增加 @@DBTS 的值。如果某 个表具有 timestamp 列，则时间戳会被记到行级。服务器就可以比较某行的当前时间戳值和上次提取时所存储的时间戳值，从而确定该行是否已更新。服务器不必比较所有列的值，只需 比较 timestamp 列即可。如果应用程序对没有 timestamp 列的表要求基于行版本控制的乐观并发，则游标默认为基于数值的乐观并发控制。 SCROLL LOCKS 这个选项实现悲观并发控制。在悲观并发控制中，在把数据库的行读入游标结果集时，应用程序将试图锁定数据库行。在使用服务器游标时，将行读入游标时会在其 上放置一个更新锁。如果在事务内打开游标，则该事务更新锁将一直保持到事务被提交或回滚；当提取下一行时，将除去游标锁。如果在事务外打开游标，则提取下 一行时，锁就被丢弃。因此，每当用户需要完全的悲观并发控制时，游标都应在事务内打开。更新锁将阻止任何其它任务获取更新锁或排它锁，从而阻止其它任务更 新该行。 然而，更新锁并不阻止共享锁，所以它不会阻止其它任务读取行，除非第二个任务也在要求带更新锁的读取。滚动锁根据在游标定义的 SELECT 语句中指定的锁提示，这些游标并发选项可以生成滚动锁。滚动锁在提取时在每行上获取，并保持到下次提取或者游标关闭，以先发生者为准。下次提取时，服务器 为新提取中的行获取滚动锁，并释放上次提取中行的滚动锁。滚动锁独立于事务锁，并可以保持到一个提交或回滚操作之后。如果提交时关闭游标的选项为关， 则 COMMIT 语句并不关闭任何打开的游标，而且滚动锁被保留到提交之后，以维护对所提取数据的隔离。所获取滚动锁的类型取决于游标并发选项和游标 SELECT 语句中的锁提示。 锁提示 只读 乐观数值 乐观行版本控制 锁定无提示 未锁定 未锁定 未锁定 更新 NOLOCK 未锁定 未锁定 未锁定 未锁定 HOLDLOCK 共享 共享 共享 更新 UPDLOCK 错误 更新 更新 更新 TABLOCKX 错误 未锁定 未锁定 更新其它 未锁定 未锁定 未锁定 更新 *指定 NOLOCK 提示将使指定了该提示的表在游标内是只读的。 16、用Profiler来跟踪查询，得到查询所需的时间，找出SQL的问题所在;用索引优化器优化索引 17、注意UNion和UNion all 的区别。UNION all好 18、注意使用DISTINCT，在没有必要时不要用，它同UNION一样会使查询变慢。重复的记录在查询里是没有问题的 19、查询时不要返回不需要的行、列 20、用sp_configure ‘query governor cost limit’或者SET QUERY_GOVERNOR_COST_LIMIT来限制查询消耗的资源。当评估查询消耗的资源超出限制时，服务器自动取消查询,在查询之前就扼杀掉。 SET LOCKTIME设置锁的时间 21、用select top 100 / 10 Percent 来限制用户返回的行数或者SET ROWCOUNT来限制操作的行 22、在SQL2000以前，一般不要用如下的字句 “IS NULL”, “ &lt;&gt; “, “!=”, “!&gt; “, “! &lt;”, “NOT”, “NOT EXISTS”, “NOT IN”, “NOT LIKE”, and “LIKE ‘%500’”，因为他们不走索引全是表扫描。 也不要在WHere字句中的列名加函数，如 Convert，substring等,如果必须用函数的时候，创建计算列再创建索引来替代.还可以变通写法：WHERE SUBSTRING(firstname,1,1) = ‘m’改为WHERE firstname like ‘m%’（索引扫描），一定要将函数和列名分开。并且索引不能建得太多和太大。 NOT IN会多次扫描表，使用EXISTS、NOT EXISTS ，IN , LEFT OUTER JOIN 来替代，特别是左连接,而Exists比IN更快，最慢的是NOT操作.如果列的值含有空，以前它的索引不起作用，现在2000的优化器能够处理了。相同 的是IS NULL，“NOT”, “NOT EXISTS”, “NOT IN”能优化她，而” &lt;&gt; ”等还是不能优化，用不到索引。 23、使用Query Analyzer，查看SQL语句的查询计划和评估分析是否是优化的SQL。一般的20%的代码占据了80%的资源，我们优化的重点是这些慢的地方。 24、如果使用了IN或者OR等时发现查询没有走索引，使用显示申明指定索引： SELECT * FROM PersonMember (INDEX = IX_Title) WHERE processid IN (‘男’，‘女’) 25、将需要查询的结果预先计算好放在表中，查询的时候再SELECT。这在SQL7.0以前是最重要的手段。例如医院的住院费计算。 26、MIN() 和 MAX()能使用到合适的索引 27、数据库有一个原则是代码离数据越近越好，所以优先选择Default,依次为Rules,Triggers, Constraint（约束如外健主健CheckUNIQUE……,数据类型的最大长度等等都是约束）,Procedure.这样不仅维护工作小，编写程 序质量高，并且执行的速度快。 28、如果要插入大的二进制值到Image列，使用存储过程，千万不要用内嵌INsert来插入(不知JAVA是否)。因为这样应用程序首先将二进 制值转换成字符串（尺寸是它的两倍），服务器受到字符后又将他转换成二进制值.存储过程就没有这些动作: 方法：Create procedure p_insert as insert into table(Fimage) values (@image), 在前台调用这个存储过程传入二进制参数，这样处理速度明显改善。 29、Between在某些时候比IN速度更快,Between能够更快地根据索引找到范围。用查询优化器可见到差别。 select from chineseresume where title in (‘男’,’女’) Select from chineseresume where between ‘男’ and ‘女’ 是一样的。由于in会在比较多次，所以有时会慢些。 30、在必要是对全局或者局部临时表创建索引，有时能够提高速度，但不是一定会这样，因为索引也耗费大量的资源。他的创建同是实际表一样。 31、不要建没有作用的事物例如产生报表时，浪费资源。只有在必要使用事物时使用它。 32、用OR的字句可以分解成多个查询，并且通过UNION 连接多个查询。他们的速度只同是否使用索引有关,如果查询需要用到联合索引，用UNION all执行的效率更高.多个OR的字句没有用到索引，改写成UNION的形式再试图与索引匹配。一个关键的问题是否用到索引。 33、尽量少用视图，它的效率低。对视图操作比直接对表操作慢,可以用stored procedure来代替她。特别的是不要用视图嵌套,嵌套视图增加了寻找原始资料的难度。我们看视图的本质：它是存放在服务器上的被优化好了的已经产生 了查询规划的SQL。对单个表检索数据时，不要使用指向多个表的视图，直接从表检索或者仅仅包含这个表的视图上读，否则增加了不必要的开销,查询受到干 扰.为了加快视图的查询，MsSQL增加了视图索引的功能。 34、没有必要时不要用DISTINCT和ORDER BY，这些动作可以改在客户端执行。它们增加了额外的开销。这同UNION 和UNION ALL一样的道理。 SELECT top 20 ad.companyname,comid,position,ad.referenceid,worklocation, convert(varchar(10),ad.postDate,120) as postDate1,workyear,degreedescription FROM jobcn_query.dbo.COMPANYAD_query ad where referenceID in(‘JCNAD00329667’,’JCNAD132168’,’JCNAD00337748’,’JCNAD00338345’,’JCNAD00333138’,’JCNAD00303570’, ‘JCNAD00303569’,’JCNAD00303568’,’JCNAD00306698’,’JCNAD00231935’,’JCNAD00231933’,’JCNAD00254567’, ‘JCNAD00254585’,’JCNAD00254608’,’JCNAD00254607’,’JCNAD00258524’,’JCNAD00332133’,’JCNAD00268618’, ‘JCNAD00279196’,’JCNAD00268613’) order by postdate desc 35、在IN后面值的列表中，将出现最频繁的值放在最前面，出现得最少的放在最后面，减少判断的次数 36、当用SELECT INTO时，它会锁住系统表(sysobjects，sysindexes等等)，阻塞其他的连接的存取。创建临时表时用显示申明语句，而不是 select INTO. drop table t_lxh begin tran select into t_lxh from chineseresume where name = ‘XYZ’ –commit 在另一个连接中SELECT from sysobjects可以看到 SELECT INTO 会锁住系统表，Create table 也会锁系统表(不管是临时表还是系统表)。所以千万不要在事物内使用它！！！这样的话如果是经常要用的临时表请使用实表，或者临时表变量。 37、一般在GROUP BY 个HAVING字句之前就能剔除多余的行，所以尽量不要用它们来做剔除行的工作。他们的执行顺序应该如下最优：select 的Where字句选择所有合适的行，Group By用来分组个统计行，Having字句用来剔除多余的分组。这样Group By 个Having的开销小，查询快.对于大的数据行进行分组和Having十分消耗资源。如果Group BY的目的不包括计算，只是分组，那么用Distinct更快 38、一次更新多条记录比分多次更新每次一条快,就是说批处理好 39、少用临时表，尽量用结果集和Table类性的变量来代替它,Table 类型的变量比临时表好 40、在SQL2000下，计算字段是可以索引的，需要满足的条件如下： a、计算字段的表达是确定的 b、不能用在TEXT,Ntext，Image数据类型 c、必须配制如下选项 ANSI_NULLS = ON, ANSI_PADDINGS = ON, ……. 41、尽量将数据的处理工作放在服务器上，减少网络的开销，如使用存储过程。存储过程是编译好、优化过、并且被组织到一个执行规划里、且存储在数据 库中的 SQL语句，是控制流语言的集合，速度当然快。反复执行的动态SQL,可以使用临时存储过程，该过程（临时表）被放在Tempdb中。以前由于SQL SERVER对复杂的数学计算不支持，所以不得不将这个工作放在其他的层上而增加网络的开销。SQL2000支持UDFs,现在支持复杂的数学计算，函数 的返回值不要太大，这样的开销很大。用户自定义函数象光标一样执行的消耗大量的资源，如果返回大的结果采用存储过程 42、不要在一句话里再三的使用相同的函数，浪费资源,将结果放在变量里再调用更快 43、SELECT COUNT(*)的效率教低，尽量变通他的写法，而EXISTS快.同时请注意区别： select count(Field of null) from Table 和 select count(Field of NOT null) from Table 的返回值是不同的。 44、当服务器的内存够多时，配制线程数量 = 最大连接数+5，这样能发挥最大的效率；否则使用 配制线程数量 &lt;最大连接数启用SQL SERVER的线程池来解决,如果还是数量 = 最大连接数+5，严重的损害服务器的性能。 45、按照一定的次序来访问你的表。如果你先锁住表A，再锁住表B，那么在所有的存储过程中都要按照这个顺序来锁定它们。如果你（不经意的）某个存储过程中先锁定表B，再锁定表A，这可能就会导致一个死锁。如果锁定顺序没有被预先详细的设计好，死锁很难被发现 46、通过SQL Server Performance Monitor监视相应硬件的负载 Memory: Page Faults / sec计数器如果该值偶尔走高，表明当时有线程竞争内存。如果持续很高，则内存可能是瓶颈。 Process: ​ 1、% DPC Time 指在范例间隔期间处理器用在缓延程序调用(DPC)接收和提供服务的百分比。(DPC 正在运行的为比标准间隔优先权低的间隔)。 由于 DPC 是以特权模式执行的，DPC 时间的百分比为特权时间 百分比的一部分。这些时间单独计算并且不属于间隔计算总数的一部 分。这个总数显示了作为实例时间百分比的平均忙时。 ​ 2、%Processor Time计数器 如果该参数值持续超过95%，表明瓶颈是CPU。可以考虑增加一个处理器或换一个更快的处理器。 ​ 3、% Privileged Time 指非闲置处理器时间用于特权模式的百分比。(特权模式是为操作系统组件和操纵硬件驱动程序而设计的一种处理模式。它允许直接访问硬件和所有内存。另一种模 式为用户模式，它是一种为应用程序、环境分系统和整数分系统设计的一种有限处理模式。操作系统将应用程序线程转换成特权模式以访问操作系统服务)。 特权时间的 % 包括为间断和 DPC 提供服务的时间。特权时间比率高可能是由于失败设备产生的大数量的间隔而引起的。这个计数器将平均忙时作为样本时间的一部分显示。 ​ 4、% User Time表示耗费CPU的数据库操作，如排序，执行aggregate functions等。如果该值很高，可考虑增加索引，尽量使用简单的表联接，水平分割大表格等方法来降低该值。 Physical Disk: Curretn Disk Queue Length计数器该值应不超过磁盘数的1.5~2倍。要提高性能，可增加磁盘。 SQLServer:Cache Hit Ratio计数器该值越高越好。如果持续低于80%，应考虑增加内存。 注意该参数值是从SQL Server启动后，就一直累加记数，所以运行经过一段时间后，该值将不能反映系统当前值。 47、分析select emp_name form employee where salary &gt; 3000 在此语句中若salary是Float类型的，则优化器对其进行优化为Convert(float,3000)，因为3000是个整数，我们应在编程时使 用3000.0而不要等运行时让DBMS进行转化。同样字符和整型数据的转换。]]></content>
      <tags>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据库索引和mysql数据库索引类型和原理]]></title>
    <url>%2F2019%2F02%2F18%2F%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B4%A2%E5%BC%95%E5%92%8Cmysql%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B4%A2%E5%BC%95%E7%B1%BB%E5%9E%8B%E5%92%8C%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[什么是数据库索引索引是对数据库表中一列或多列的值进行排序的一种结构，使用索引可快速访问数据库表中的特定信息。如果想按特定职员的姓来查找他或她，则与在表中搜索所有的行相比，索引有助于更快地获取信息。 索引的一个主要目的就是加快检索表中数据，亦即能协助信息搜索者尽快的找到符合限制条件的记录ID的辅助数据结构。 Mysql几种索引类型的区别及适用情况如大家所知道的，Mysql目前主要有以下几种索引类型：FULLTEXT，HASH，BTREE，RTREE。 那么，这几种索引有什么功能和性能上的不同呢？ FULLTEXT 即为全文索引，目前只有MyISAM引擎支持。其可以在CREATE TABLE ，ALTER TABLE ，CREATE INDEX 使用，不过目前只有 CHAR、VARCHAR ，TEXT 列上可以创建全文索引。值得一提的是，在数据量较大时候，现将数据放入一个没有全局索引的表中，然后再用CREATE INDEX创建FULLTEXT索引，要比先为一张表建立FULLTEXT然后再将数据写入的速度快很多。 全文索引并不是和MyISAM一起诞生的，它的出现是为了解决WHERE name LIKE “%word%”这类针对文本的模糊查询效率较低的问题。在没有全文索引之前，这样一个查询语句是要进行遍历数据表操作的，可见，在数据量较大时是极其的耗时的，如果没有异步IO处理，进程将被挟持，很浪费时间，当然这里不对异步IO作进一步讲解，想了解的童鞋，自行谷哥。 全文索引的使用方法并不复杂： 创建ALTER TABLE table ADD INDEX FULLINDEX USING FULLTEXT(cname1[,cname2…]); 使用SELECT * FROM table WHERE MATCH(cname1[,cname2…]) AGAINST (‘word’ MODE ); 其中， MODE为搜寻方式（IN BOOLEAN MODE ，IN NATURAL LANGUAGE MODE ，IN NATURAL LANGUAGE MODE WITH QUERY EXPANSION / WITH QUERY EXPANSION）。 关于这三种搜寻方式，愚安在这里也不多做交代，简单地说，就是，布尔模式，允许word里含一些特殊字符用于标记一些具体的要求，如+表示一定要有，-表示一定没有，*表示通用匹配符，是不是想起了正则，类似吧；自然语言模式，就是简单的单词匹配；含表达式的自然语言模式，就是先用自然语言模式处理，对返回的结果，再进行表达式匹配。 对搜索引擎稍微有点了解的同学，肯定知道分词这个概念，FULLTEXT索引也是按照分词原理建立索引的。西文中，大部分为字母文字，分词可以很方便的按照空格进行分割。但很明显，中文不能按照这种方式进行分词。那又怎么办呢？这个向大家介绍一个Mysql的中文分词插件Mysqlcft，有了它，就可以对中文进行分词，想了解的同学请移步Mysqlcft，当然还有其他的分词插件可以使用。 HASH Hash这个词，可以说，自打我们开始码的那一天起，就开始不停地见到和使用到了。其实，hash就是一种（key=&gt;value）形式的键值对，如数学中的函数映射，允许多个key对应相同的value，但不允许一个key对应多个value。正是由于这个特性，hash很适合做索引，为某一列或几列建立hash索引，就会利用这一列或几列的值通过一定的算法计算出一个hash值，对应一行或几行数据（这里在概念上和函数映射有区别，不要混淆）。在java语言中，每个类都有自己的hashcode()方法，没有显示定义的都继承自object类，该方法使得每一个对象都是唯一的，在进行对象间equal比较，和序列化传输中起到了很重要的作用。hash的生成方法有很多种，足可以保证hash码的唯一性，例如在MongoDB中，每一个document都有系统为其生成的唯一的objectID（包含时间戳，主机散列值，进程PID，和自增ID）也是一种hash的表现。额，我好像扯远了-_-! 由于hash索引可以一次定位，不需要像树形索引那样逐层查找,因此具有极高的效率。那为什么还需要其他的树形索引呢？ 在这里愚安就不自己总结了。引用下园子里其他大神的文章：来自 14的路 的MySQL的btree索引和hash索引的区别 （1）Hash 索引仅仅能满足”=”,”IN”和”&lt;=&gt;”查询，不能使用范围查询。由于 Hash 索引比较的是进行 Hash 运算之后的 Hash 值，所以它只能用于等值的过滤，不能用于基于范围的过滤，因为经过相应的 Hash 算法处理之后的 Hash 值的大小关系，并不能保证和Hash运算前完全一样。（2）Hash 索引无法被用来避免数据的排序操作。由于 Hash 索引中存放的是经过 Hash 计算之后的 Hash 值，而且Hash值的大小关系并不一定和 Hash 运算前的键值完全一样，所以数据库无法利用索引的数据来避免任何排序运算；（3）Hash 索引不能利用部分索引键查询。对于组合索引，Hash 索引在计算 Hash 值的时候是组合索引键合并后再一起计算 Hash 值，而不是单独计算 Hash 值，所以通过组合索引的前面一个或几个索引键进行查询的时候，Hash 索引也无法被利用。（4）Hash 索引在任何时候都不能避免表扫描。前面已经知道，Hash 索引是将索引键通过 Hash 运算之后，将 Hash运算结果的 Hash 值和所对应的行指针信息存放于一个 Hash 表中，由于不同索引键存在相同 Hash 值，所以即使取满足某个 Hash 键值的数据的记录条数，也无法从 Hash 索引中直接完成查询，还是要通过访问表中的实际数据进行相应的比较，并得到相应的结果。（5）Hash 索引遇到大量Hash值相等的情况后性能并不一定就会比B-Tree索引高。对于选择性比较低的索引键，如果创建 Hash 索引，那么将会存在大量记录指针信息存于同一个 Hash 值相关联。这样要定位某一条记录时就会非常麻烦，会浪费多次表数据的访问，而造成整体性能低下。 愚安我稍作补充，讲一下HASH索引的过程，顺便解释下上面的第4,5条： 当我们为某一列或某几列建立hash索引时（目前就只有MEMORY引擎显式地支持这种索引），会在硬盘上生成类似如下的文件： hash值 存储地址 1db54bc745a1 77#45b5 4bca452157d4 76#4556,77#45cc… … hash值即为通过特定算法由指定列数据计算出来，磁盘地址即为所在数据行存储在硬盘上的地址（也有可能是其他存储地址，其实MEMORY会将hash表导入内存）。 这样，当我们进行WHERE age = 18 时，会将18通过相同的算法计算出一个hash值==&gt;在hash表中找到对应的储存地址==&gt;根据存储地址取得数据。 所以，每次查询时都要遍历hash表，直到找到对应的hash值，如（4），数据量大了之后，hash表也会变得庞大起来，性能下降，遍历耗时增加，如（5）。 BTREE BTREE索引就是一种将索引值按一定的算法，存入一个树形的数据结构中，相信学过数据结构的童鞋都对当初学习二叉树这种数据结构的经历记忆犹新，反正愚安我当时为了软考可是被这玩意儿好好地折腾了一番，不过那次考试好像没怎么考这个。如二叉树一样，每次查询都是从树的入口root开始，依次遍历node，获取leaf。 BTREE在MyISAM里的形式和Innodb稍有不同 在 Innodb里，有两种形态：一是primary key形态，其leaf node里存放的是数据，而且不仅存放了索引键的数据，还存放了其他字段的数据。二是secondary index，其leaf node和普通的BTREE差不多，只是还存放了指向主键的信息. 而在MyISAM里，主键和其他的并没有太大区别。不过和Innodb不太一样的地方是在MyISAM里，leaf node里存放的不是主键的信息，而是指向数据文件里的对应数据行的信息. RTREE RTREE在mysql很少使用，仅支持geometry数据类型，支持该类型的存储引擎只有MyISAM、BDb、InnoDb、NDb、Archive几种。 相对于BTREE，RTREE的优势在于范围查找. 各种索引的使用情况 （1）对于BTREE这种Mysql默认的索引类型，具有普遍的适用性 （2）由于FULLTEXT对中文支持不是很好，在没有插件的情况下，最好不要使用。其实，一些小的博客应用，只需要在数据采集时，为其建立关键字列表，通过关键字索引，也是一个不错的方法，至少愚安我是经常这么做的。 （3）对于一些搜索引擎级别的应用来说，FULLTEXT同样不是一个好的处理方法，Mysql的全文索引建立的文件还是比较大的，而且效率不是很高，即便是使用了中文分词插件，对中文分词支持也只是一般。真要碰到这种问题，Apache的Lucene或许是你的选择。 （4）正是因为hash表在处理较小数据量时具有无可比拟的素的优势，所以hash索引很适合做缓存（内存数据库）。如mysql数据库的内存版本Memsql，使用量很广泛的缓存工具Mencached，NoSql数据库redis等，都使用了hash索引这种形式。当然，不想学习这些东西的话Mysql的MEMORY引擎也是可以满足这种需求的。 （5）至于RTREE，愚安我至今还没有使用过，它具体怎么样，我就不知道了。有RTREE使用经历的同学，到时可以交流下！ mysql数据库索引的类型和原理索引初识：最普通的情况，是为出现在where子句的字段建一个索引。为方便讲述，我们先建立一个如下的表。 123456CREATE TABLE mytable ( id serial primary key, category_id int not null default 0, user_id int not null default 0, adddate int not null default 0); 很简单吧，不过对于要说明这个问题，已经足够了。如果你在查询时常用类似以下的语句： 1SELECT * FROM mytable WHERE category_id=1; 最直接的应对之道，是为category_id建立一个简单的索引： 1CREATE INDEX mytable_categoryid ON mytable (category_id); OK，搞定？先别高兴，如果你有不止一个选择条件呢？例如： 1SELECT * FROM mytable WHERE category_id=1 AND user_id=2; 你的第一反应可能是，再给user_id建立一个索引。不好，这不是一个最佳的方法。你可以建立多重的索引。 1CREATE INDEX mytable_categoryid_userid ON mytable (category_id,user_id); 注意到我在命名时的习惯了吗？我使用”表名字段1名字段2名”的方式。你很快就会知道我为什么这样做了。 现在你已经为适当的字段建立了索引，不过，还是有点不放心吧，你可能会问，数据库会真正用到这些索引吗？测试一下就OK，对于大多数的数据库来说，这是很容易的，只要使用EXPLAIN命令： ;) 12345678910111213EXPLAIN SELECT * FROM mytable WHERE category_id=1 AND user_id=2;This is what Postgres 7.1 returns (exactly as I expected) NOTICE: QUERY PLAN:Index Scan using mytable_categoryid_userid on mytable (cost=0.00..2.02 rows=1 width=16)EXPLAIN ;) 以上是postgres的数据，可以看到该数据库在查询的时候使用了一个索引（一个好开始），而且它使用的是我创建的第二个索引。看到我上面命名的好处了吧，你马上知道它使用适当的索引了。 接着，来个稍微复杂一点的，如果有个ORDER BY字句呢？不管你信不信，大多数的数据库在使用order by的时候，都将会从索引中受益。 1SELECT * FROM mytable WHERE category_id=1 AND user_id=2 ORDER BY adddate DESC; 有点迷惑了吧？很简单，就象为where字句中的字段建立一个索引一样，也为ORDER BY的字句中的字段建立一个索引： 1CREATE INDEX mytable_categoryid_userid_adddate ON mytable (category_id,user_id,adddate); 注意: “mytable_categoryid_userid_adddate” 将会被截短为“mytable_categoryid_userid_addda” ;) 12345678910111213CREATE EXPLAIN SELECT * FROM mytable WHERE category_id=1 AND user_id=2 ORDER BY adddate DESC; NOTICE: QUERY PLAN: Sort (cost=2.03..2.03 rows=1 width=16) -&gt; Index Scan using mytable_categoryid_userid_addda on mytable (cost=0.00..2.02 rows=1 width=16)EXPLAIN ;) 看看EXPLAIN的输出，好象有点恐怖啊，数据库多做了一个我们没有要求的排序，这下知道性能如何受损了吧，看来我们对于数据库的自身运作是有点过于乐观了，那么，给数据库多一点提示吧。 为了跳过排序这一步，我们并不需要其它另外的索引，只要将查询语句稍微改一下。这里用的是postgres，我们将给该数据库一个额外的提示–在ORDER BY语句中，加入where语句中的字段。这只是一个技术上的处理，并不是必须的，因为实际上在另外两个字段上，并不会有任何的排序操作，不过如果加入，postgres将会知道哪些是它应该做的。 ;) 1234567891011EXPLAIN SELECT * FROM mytable WHERE category_id=1 AND user_id=2 ORDER BY category_id DESC,user_id DESC,adddate DESC;NOTICE: QUERY PLAN:Index Scan Backward using mytable_categoryid_userid_addda on mytable (cost=0.00..2.02 rows=1 width=16)EXPLAIN ;) 现在使用我们料想的索引了，而且它还挺聪明，知道可以从索引后面开始读，从而避免了任何的排序。 以上说得细了一点，不过如果你的数据库非常巨大，并且每日的页面请求达上百万算，我想你会获益良多的。不过，如果你要做更为复杂的查询呢，例如将多张表结合起来查询，特别是where限制字句中的字段是来自不止一个表格时，应该怎样处理呢？我通常都尽量避免这种做法，因为这样数据库要将各个表中的东西都结合起来，然后再排除那些不合适的行，搞不好开销会很大。 如果不能避免，你应该查看每张要结合起来的表，并且使用以上的策略来建立索引，然后再用EXPLAIN命令验证一下是否使用了你料想中的索引。如果是的话，就OK。不是的话，你可能要建立临时的表来将他们结合在一起，并且使用适当的索引。 要注意的是，建立太多的索引将会影响更新和插入的速度，因为它需要同样更新每个索引文件。对于一个经常需要更新和插入的表格，就没有必要为一个很少使用的where字句单独建立索引了，对于比较小的表，排序的开销不会很大，也没有必要建立另外的索引。 以上介绍的只是一些十分基本的东西，其实里面的学问也不少，单凭EXPLAIN我们是不能判定该方法是否就是最优化的，每个数据库都有自己的一些优化器，虽然可能还不太完善，但是它们都会在查询时对比过哪种方式较快，在某些情况下，建立索引的话也未必会快， 例如索引放在一个不连续的存储空间时，这会增加读磁盘的负担，因此，哪个是最优，应该通过实际的使用环境来检验。 在刚开始的时候，如果表不大，没有必要作索引，我的意见是在需要的时候才作索引，也可用一些命令来优化表，例如MySQL可用”OPTIMIZE TABLE”。 综上所述，在如何为数据库建立恰当的索引方面，你应该有一些基本的概念了。 -————————————————————– 关于MySQL索引的好处，如果正确合理设计并且使用索引的MySQL是一辆兰博基尼的话，那么没有设计和使用索引的MySQL就是一个人力三轮车。对于没有索引的表，单表查询可能几十万数据就是瓶颈，而通常大型网站单日就可能会产生几十万甚至几百万的数据，没有索引查询会变的非常缓慢。还是以WordPress来说，其多个数据表都会对经常被查询的字段添加索引，比如wp_comments表中针对5个字段设计了BTREE索引。 一个简单的对比测试以我去年测试的数据作为一个简单示例，20多条数据源随机生成200万条数据，平均每条数据源都重复大概10万次，表结构比较简单，仅包含一个自增ID，一个char类型，一个text类型和一个int类型，单表2G大小，使用MyIASM引擎。开始测试未添加任何索引。 执行下面的SQL语句： 1SELECT id,FROM_UNIXTIME(time) FROM article WHERE a.title=&apos;测试标题&apos;； 查询需要的时间非常恐怖的，如果加上联合查询和其他一些约束条件，数据库会疯狂的消耗内存，并且会影响前端程序的执行。这时给title字段添加一个BTREE索引： 1ALTER TABLE article ADD INDEX index_article_title ON title(200); 再次执行上述查询语句，其对比非常明显： MySQL索引的概念索引是一种特殊的文件(InnoDB数据表上的索引是表空间的一个组成部分)，它们包含着对数据表里所有记录的引用指针。更通俗的说，数据库索引好比是一本书前面的目录，能加快数据库的查询速度。上述SQL语句，在没有索引的情况下，数据库会遍历全部200条数据后选择符合条件的；而有了相应的索引之后，数据库会直接在索引中查找符合条件的选项。如果我们把SQL语句换成“SELECT * FROM article WHERE id=2000000”，那么你是希望数据库按照顺序读取完200万行数据以后给你结果还是直接在索引中定位呢？上面的两个图片鲜明的用时对比已经给出了答案（注：一般数据库默认都会为主键生成索引）。 索引分为聚簇索引和非聚簇索引两种，聚簇索引是按照数据存放的物理位置为顺序的，而非聚簇索引就不一样了；聚簇索引能提高多行检索的速度，而非聚簇索引对于单行的检索很快。 MySQL索引的类型1. 普通索引 这是最基本的索引，它没有任何限制，比如上文中为title字段创建的索引就是一个普通索引，MyIASM中默认的BTREE类型的索引，也是我们大多数情况下用到的索引。 ;) 123456789101112131415–直接创建索引CREATE INDEX index_name ON table(column(length))–修改表结构的方式添加索引ALTER TABLE table_name ADD INDEX index_name ON (column(length))–创建表的时候同时创建索引CREATE TABLE `table` (`id` int(11) NOT NULL AUTO_INCREMENT ,`title` char(255) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL ,`content` text CHARACTER SET utf8 COLLATE utf8_general_ci NULL ,`time` int(10) NULL DEFAULT NULL ,PRIMARY KEY (`id`),INDEX index_name (title(length)))–删除索引DROP INDEX index_name ON table ;) 2. 唯一索引 与普通索引类似，不同的就是：索引列的值必须唯一，但允许有空值（注意和主键不同）。如果是组合索引，则列值的组合必须唯一，创建方法和普通索引类似。 ;) 12345678910111213–创建唯一索引CREATE UNIQUE INDEX indexName ON table(column(length))–修改表结构ALTER TABLE table_name ADD UNIQUE indexName ON (column(length))–创建表的时候直接指定CREATE TABLE `table` (`id` int(11) NOT NULL AUTO_INCREMENT ,`title` char(255) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL ,`content` text CHARACTER SET utf8 COLLATE utf8_general_ci NULL ,`time` int(10) NULL DEFAULT NULL ,PRIMARY KEY (`id`),UNIQUE indexName (title(length))); ;) 3. 全文索引（FULLTEXT） MySQL从3.23.23版开始支持全文索引和全文检索，FULLTEXT索引仅可用于 MyISAM 表；他们可以从CHAR、VARCHAR或TEXT列中作为CREATE TABLE语句的一部分被创建，或是随后使用ALTER TABLE 或CREATE INDEX被添加。////对于较大的数据集，将你的资料输入一个没有FULLTEXT索引的表中，然后创建索引，其速度比把资料输入现有FULLTEXT索引的速度更为快。不过切记对于大容量的数据表，生成全文索引是一个非常消耗时间非常消耗硬盘空间的做法。 ;) 12345678910111213–创建表的适合添加全文索引CREATE TABLE `table` (`id` int(11) NOT NULL AUTO_INCREMENT ,`title` char(255) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL ,`content` text CHARACTER SET utf8 COLLATE utf8_general_ci NULL ,`time` int(10) NULL DEFAULT NULL ,PRIMARY KEY (`id`),FULLTEXT (content));–修改表结构添加全文索引ALTER TABLE article ADD FULLTEXT index_content(content)–直接创建索引CREATE FULLTEXT INDEX index_content ON article(content) ;) 4. 单列索引、多列索引 多个单列索引与单个多列索引的查询效果不同，因为执行查询时，MySQL只能使用一个索引，会从多个索引中选择一个限制最为严格的索引。 5. 组合索引（最左前缀） 平时用的SQL查询语句一般都有比较多的限制条件，所以为了进一步榨取MySQL的效率，就要考虑建立组合索引。例如上表中针对title和time建立一个组合索引：ALTER TABLE article ADD INDEX index_titme_time (title(50),time(10))。建立这样的组合索引，其实是相当于分别建立了下面两组组合索引： –title,time –title 为什么没有time这样的组合索引呢？这是因为MySQL组合索引“最左前缀”的结果。简单的理解就是只从最左面的开始组合。并不是只要包含这两列的查询都会用到该组合索引，如下面的几个SQL所示： 12345–使用到上面的索引SELECT * FROM article WHREE title=&apos;测试&apos; AND time=1234567890;SELECT * FROM article WHREE utitle=&apos;测试&apos;;–不使用上面的索引SELECT * FROM article WHREE time=1234567890; MySQL索引的优化上面都在说使用索引的好处，但过多的使用索引将会造成滥用。因此索引也会有它的缺点：虽然索引大大提高了查询速度，同时却会降低更新表的速度，如对表进行INSERT、UPDATE和DELETE。因为更新表时，MySQL不仅要保存数据，还要保存一下索引文件。建立索引会占用磁盘空间的索引文件。一般情况这个问题不太严重，但如果你在一个大表上创建了多种组合索引，索引文件的会膨胀很快。索引只是提高效率的一个因素，如果你的MySQL有大数据量的表，就需要花时间研究建立最优秀的索引，或优化查询语句。下面是一些总结以及收藏的MySQL索引的注意事项和优化方法。 1. 何时使用聚集索引或非聚集索引？ 动作描述 使用聚集索引 使用非聚集索引 列经常被分组排序 使用 使用 返回某范围内的数据 使用 不使用 一个或极少不同值 不使用 不使用 小数目的不同值 使用 不使用 大数目的不同值 不使用 使用 频繁更新的列 不使用 使用 外键列 使用 使用 主键列 使用 使用 频繁修改索引列 不使用 使用 事实上，我们可以通过前面聚集索引和非聚集索引的定义的例子来理解上表。如：返回某范围内的数据一项。比如您的某个表有一个时间列，恰好您把聚合索引建立在了该列，这时您查询2004年1月1日至2004年10月1日之间的全部数据时，这个速度就将是很快的，因为您的这本字典正文是按日期进行排序的，聚类索引只需要找到要检索的所有数据中的开头和结尾数据即可；而不像非聚集索引，必须先查到目录中查到每一项数据对应的页码，然后再根据页码查到具体内容。其实这个具体用法我还不是很理解，只能等待后期的项目开发中慢慢学学了。 2. 索引不会包含有NULL值的列 只要列中包含有NULL值都将不会被包含在索引中，复合索引中只要有一列含有NULL值，那么这一列对于此复合索引就是无效的。所以我们在数据库设计时不要让字段的默认值为NULL。 3. 使用短索引 对串列进行索引，如果可能应该指定一个前缀长度。例如，如果有一个CHAR(255)的列，如果在前10个或20个字符内，多数值是惟一的，那么就不要对整个列进行索引。短索引不仅可以提高查询速度而且可以节省磁盘空间和I/O操作。 4. 索引列排序 MySQL查询只使用一个索引，因此如果where子句中已经使用了索引的话，那么order by中的列是不会使用索引的。因此数据库默认排序可以符合要求的情况下不要使用排序操作；尽量不要包含多个列的排序，如果需要最好给这些列创建复合索引。 5. like语句操作 一般情况下不鼓励使用like操作，如果非使用不可，如何使用也是一个问题。like “%aaa%” 不会使用索引而like “aaa%”可以使用索引。 6. 不要在列上进行运算 例如：select from users where YEAR(adddate)&lt;2007，将在每个行上进行运算，这将导致索引失效而进行全表扫描，因此我们可以改成：select from users where adddate&lt;’2007-01-01′。关于这一点可以围观：一个单引号引发的MYSQL性能损失。 最后总结一下，MySQL只对一下操作符才使用索引：&lt;,&lt;=,=,&gt;,&gt;=,between,in,以及某些时候的like(不以通配符%或_开头的情形)。而理论上每张表里面最多可创建16个索引，不过除非是数据量真的很多，否则过多的使用索引也不是那么好玩的，比如我刚才针对text类型的字段创建索引的时候，系统差点就卡死了。 -——————————————————————— 建立索引的优缺点:为什么要创建索引呢？ ​ 这是因为，创建索引可以大大提高系统的性能。​ 第一、通过创建唯一性索引，可以保证数据库表中每一行数据的唯一性。​ 第二、可以大大加快 数据的检索速度，这也是创建索引的最主要的原因。​ 第三、可以加速表和表之间的连接，特别是在实现数据的参考完整性方面特别有意义。​ 第四、在使用分组和排序子句进行数据检索时，同样可以显著减少查询中分组和排序的时间。​ 第五、通过使用索引，可以在查询的过程中，使用优化隐藏器，提高系统的性能。 ​ 也许会有人要问：增加索引有如此多的优点，为什么不对表中的每一个列创建一个索引呢？这种想法固然有其合理性，然而也有其片面性。虽然，索引有许多优点， 但是，为表中的每一个列都增加索引，是非常不明智的。 ​ 这是因为，增加索引也有许多不利的一个方面: ​ 第一、创建索引和维护索引要耗费时间，这种时间随着数据量的增加而增加。 ​ 第二、索引需要占物理空间，除了数据表占数据空间之外，每一个索引还要占一定的物理空间。如果要建立聚簇索引，那么需要的空间就会更大。 ​ 第三、当对表中的数据进行增加、删除和修改的时候，索引也要动态的维护，这样就降低了数据的维护速度。 什么样的字段适合创建索引: 索引是建立在数据库表中的某些列的上面。因此，在创建索引的时候，应该仔细考虑在哪些列上可以创建索引，在哪些列上不能创建索引。 ​ 一般来说，应该在这些列上创建索引，例如： ​ 第一、在经常需要搜索的列上，可以加快搜索的速度； ​ 第二、在作为主键的列上，强制该列的唯一性和组织表中数据的排列结构； ​ 第三、在经常用在连接的列上，这些列主要是一些外键，可以加快连接的速度； ​ 第四、在经常需要根据范围进行搜索的列上创建索引，因为索引已经排序，其指定的范围是连续的； ​ 第五、在经常需要排序的列上创建索引，因为索引已经排序，这样查询可以利用索引的排序，加快排序查询时间； ​ 第六、在经常使用在WHERE子句中的列上面创建索引，加快条件的判断速度。 ​ 建立索引，一般按照select的where条件来建立，比如： select的条件是where f1 and f2，那么如果我们在字段f1或字段f2上简历索引是没有用的，只有在字段f1和f2上同时建立索引才有用等。 什么样的字段不适合创建索引: 同样，对于有些列不应该创建索引。一般来说，不应该创建索引的的这些列具有下列特点： 第一，对于那些在查询中很少使用或者参考的列不应该创建索引。这是因为，既然这些列很少使用到，因此有索引或者无索引， 并不能提高查询速度。相反，由于增加了索引，反而降低了系统的维护速度和增大了空间需求。​ 第二，对于那些只有很少数据值的列也不应该增加索引。这是因为，由于这些列的取值很少，例如人事表的性别列， 在查询的结果中，结果集的数据行占了表中数据行的很大比 例，即需要在表中搜索的数据行的比例很大。 增加索引，并不能明显加快检索速度。​ 第三，对于那些定义为text, image和bit数据类型的列不应该增加索引。这是因为，这些列的数据量要么相当大，要么取值很少。​ 第四，当修改性能远远大于检索性能时，不应该创建索 引。这是因为，修改性能和检索性能是互相矛盾的。 当增加索引时，会提高检索性能，但是会降低修改性能。当减少索引时，会提高修改性能，降低检索性能。 因此，当修改性能远远大于检索性能时，不应该创建索引。 创建索引的方法:: 1、创建索引，例如 create index &lt;索引的名字&gt; on table_name (列的列表);​ 2、修改表，例如 alter table table_name add index[索引的名字] (列的列表);​ 3、创建表的时候指定索引，例如create table table_name ( […], INDEX [索引的名字] (列的列表) ); 查看表中索引的方法: show index from table_name; 查看索引 索引的类型及创建例子:: 1.PRIMARY KEY （主键索引） 1MySQL&gt; alter table table_name add primary key ( `column` ) 2.UNIQUE 或 UNIQUE KEY (唯一索引) 1mysql&gt; alter table table_name add unique (`column`) 3.FULLTEXT (全文索引) 1mysql&gt; alter table table_name add fulltext (`column` ) 4.INDEX (普通索引) 1mysql&gt; alter table table_name add index index_name ( `column` ) 5.多列索引 (聚簇索引) 1mysql&gt; alter table `table_name` add index index_name ( `column1`, `column2`, `column3` )]]></content>
      <tags>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[什么是前端框架与后端框架和常用的前后端框架]]></title>
    <url>%2F2019%2F02%2F18%2F%E4%BB%80%E4%B9%88%E6%98%AF%E5%89%8D%E7%AB%AF%E6%A1%86%E6%9E%B6%E4%B8%8E%E5%90%8E%E7%AB%AF%E6%A1%86%E6%9E%B6%E5%92%8C%E5%B8%B8%E7%94%A8%E7%9A%84%E5%89%8D%E5%90%8E%E7%AB%AF%E6%A1%86%E6%9E%B6%2F</url>
    <content type="text"><![CDATA[什么是框架 框架（Framework）是整个或部分系统的可重用设计，表现为一组抽象构件及构件实例间交互的方法;另一种定义认为，框架是可被应用开发者定制的应用骨架。前者是从应用方面而后者是从目的方面给出的定义。可以说，一个框架是一个可复用的设计构件，它规定了应用的体系结构，阐明了整个设计、协作构件之间的依赖关系、责任分配和控制流程，表现为一组抽象类以及其实例之间协作的方法，它为构件复用提供了上下文(Context)关系。因此构件库的大规模重用也需要框架。构件领域框架方法在很大程度上借鉴了硬件技术发展的成就，它是构件技术、软件体系结构研究和应用软件开发三者发展结合的产物。在很多情况下，框架通常以构件库的形式出现，但构件库只是框架的一个重要部分。框架的关键还在于框架内对象间的交互模式和控制流模式。框架比构件可定制性强。在某种程度上，将构件和框架看成两个不同但彼此协作的技术或许更好。框架为构件提供重用的环境，为构件处理错误、交换数据及激活操作提供了标准的方法。应用框架的概念也很简单。它并不是包含构件应用程序的小片程序，而是实现了某应用领域通用完备功能（除去特殊应用的部分）的底层服务。使用这种框架的编程人员可以在一个通用功能已经实现的基础上开始具体的系统开发。框架提供了所有应用期望的默认行为的类集合。具体的应用通过重写子类(该子类属于框架的默认行为)或组装对象来支持应用专用的行为。应用框架强调的是软件的设计重用性和系统的可扩充性,以缩短大型应用软件系统的开发周期，提高开发质量。与传统的基于类库的面向对象重用技术比较，应用框架更注重于面向专业领域的软件重用。应用框架具有领域相关性，构件根据框架进行复合而生成可运行的系统。框架的粒度越大，其中包含的领域知识就更加完整。框架，即framework。其实就是某种应用的半成品，就是一组组件，供你选用完成你自己的系统。简单说就是使用别人搭好的舞台，你来做表演。而且，框架一般是成熟的，不断升级的软件。 框架的概念最早起源于Smalltalk环境，其中最著名的框架是Smalltalk 80的用户界面框架MVC(Model-View-Controller)。随着用户界面框架Interviews 【Linton 89】和ET++ 【Weinand 89】 的开发和发布，框架研究越来越受到研究人员的重视。虽然框架研究最初起源于用户界面领域，但它还被成功地应用到其他领域中，如操作系统、火警系统 等。Taligent公司于1992年成立后，框架研究受到了广泛的重视。该公司计划基于框架来开发一个完整的面向对象操作系统。另外，该公司还发布了一套支持快速应用开发的工具集CommonPoint，其中包括了上百个面向对象框架 【Andert 94,Cotter 95】。框架还没有统一的定义，其中Ralph Johnson所给出的定义基本上为大多数研究人员所接受：一个框架是一个可复用设计，它是由一组抽象类及其实例间协作关系来表达的。这个定义是从框架内涵的角度来定义框架的，当然也可以从框架用途的角度来给出框架的定义：一个框架是在一个给定的问题领域内，一个应用程序的一部分设计与实现。从以上两个定义可以看出，框架是对特定应用领域中的应用系统的部分设计和实现的整体结构。框架将应用系统划分为类和对象，定义类和对象的责任，类和对象如何互相协作，以及对象之间的控制线程。这些共有的设计因素由框架预先定义，应用开发人员只须关注于特定的应用系统特有部分。框架刻画了其应用领域所共有的设计决策，所以说框架着重于设计复用，尽管框架中可能包含用某种程序设计语言实现的具体类。一个基于框架开发的应用系统包含一个或多个框架，与框架相关的构件类，以及与应用系统相关的功能扩展。与应用系统相关的扩展包括与应用系统相关的类和对象。应用系统可能仅仅复用了面向对象框架的一部分，或者说，它可能需要对框架进行一些适应性修改，以满足系统需求。面向对象的框架作为一种可复用的软件，在基于框架的软件开发过程中会涉及到框架的开发和利用两个方面的工作。框架的开发阶段在于产生领域中可复用的设计。该阶段的主要结果是框架以及与框架相关的构件类。该阶段的一个重要活动是框架的演变和维护。象所有软件一样，框架也易于变化。产生变化的原因很多，如应用出错，业务领域变化，等等。不论是哪一种技术，最终都是为业务发展而服务的。从业务的角度来讲。首先，框架的是为了企业的业务发展和战略规划而服务的，他服从于企业的愿景；其次，框架最重要的目标是提高企业的竞争能力，包括降低成本、提高质量、改善客户满意程度，控制进度等方面。最后，框架实现这一目标的方式是进行有效的知识积累。软件开发是一种知识活动，因此知识的聚集和积累是至关重要的。框架能够采用一种结构化的方式对某个特定的业务领域进行描述，也就是将这个领域相关的技术以代码、文档、模型等方式固化下来。 为什么要用框架 因为软件系统发展到今天已经很复杂了，特别是服务器端软件，涉及到的知识，内容，问题太多。在某些方面使用别人成熟的框架，就相当于让别人帮你完成一些基础工作，你只需要集中精力完成系统的业务逻辑设计。而且框架一般是成熟，稳健的，他可以处理系统很多细节问题，比如，事物处理，安全性，数据流控制等问题。还有框架一般都经过很多人使用，所以结构很好，所以扩展性也很好，而且它是不断升级的，你可以直接享受别人升级代码带来的好处。框架一般处在低层应用平台（如J2EE）和高层业务逻辑之间的中间层。软件为什么要分层？ 为了实现“高内聚、低耦合”。把问题划分开来各个解决，易于控制，易于延展，易于分配资源…总之好处很多啦：）。 解决问题 框架要解决的最重要的一个问题是技术整合的问题，在J2EE的框架中，有着各种各样的技术，不同的软件企业需要从J2EE中选择不同的技术，这就使得软件企业最终的应用依赖于这些技术，技术自身的复杂性和技术的风险性将会直接对应用造成冲击。而应用是软件企业的核心，是竞争力的关键所在，因此应该将应用自身的设计和具体的实现技术解耦。这样，软件企业的研发将集中在应用的设计上，而不是具体的技术实现，技术实现是应用的底层支撑，它不应该直接对应用产生影响。 要理解这一点，我们来举一些例子：一个做视频流应用的软件企业，他为电广行业提供整体的解决方案。他的优势在于将各种各样的视频硬件、服务器、和管理结合起来，因此他扮演的是一个集成商的角色。因此他的核心价值在于使用软件技术将不同的硬件整合起来，并在硬件的整合层面上提供一个统一的管理平台。所以他的精力应该放在解决两个问题：如何找到一种方法，将不同的硬件整合起来，注意，这里的整合并不是技术整合，而是一种思路上的整合。首先要考虑的绝对不是要使用什么技术，而是这些硬件需要提供哪些服务，需要以什么样的方式进行管理。因此，这时候做的事情实际上是对领域进行建模。例如，我们定义任何一种硬件都需要提供两种能力，一种是统一的管理接口，用于对所有硬件统一管理；另一种是服务接口，系统平台可以查询硬件所能够提供的服务，并调用这些服务。所以，设计的规范将会针对两种能力进行。另一个问题是如何描述这个管理系统的规范。你需要描述各种管理活动，以及管理中所涉及的不同实体。因为管理系统是针对硬件的管理，所以它是构架在硬件整合平台之上的。在完成业务层面的设计之后，我们再来看看具体的技术实现。光有规范和设计是不够的，我们还需要选择一个优秀的技术。由于是对不同硬件的整合，我们想到采用Java提供的JMX技术。JMX技术适合用来进行系统整合，它定义了一个通用的规范，并给出了远程管理端口的一些默认实现。JMX已经经过了实践的检验，不少的应用服务器都采用了以JMX为基础的结构，例如有名的JBoss。JMX已经是一个很好的开始了，但是我们还需要在JMX的基础上再做一些工作。 网页设计中的框架概念 框架是网页中经常使用的页面设计方式，框架的作用就是把网页在一个浏览器窗口下分割成几个不同的区 域，实现在一个浏览器窗口中显示多个HTML页面。使用框架可以非常方便的完成导航工作，让网站的结构更加清晰，而且各个框架之间决不存在干扰问题。利用框架最大的特点就是使网站的风格一致。通常把一个网站中页面相同的部分单独制作成一个页面，作为框架结构的一个子框架的内容给整个网站公用。一个框架结构有两部分网页文件构成：框架Frame：框架是浏览器窗口中的一个区域，它可以显示与浏览器窗口的其余部分中所显示内容无关的网页文件。框架集Frameset：框架集也是一个网页文件，它将一个窗口通过行和列的方式分割成多个框架，框架的多少根据具体有多少网页来决定，每个框架中要显示的就是不同的网页文件。所谓框架[4] 就是把网页分成几个框窗，同时取得多个 URL。用来划分框窗，每一框窗有一个，必须在范围中使用。如： 123&lt;frameset cols=&quot;50%,*&quot;&gt; &lt;frame name=&quot;hello&quot; src=&quot;1.html&quot;&gt; &lt;frame name=&quot;hi&quot; src=&quot;2.html&quot;&gt;&lt;/frameset&gt;123 此例中 把画面分成左右两相等部分，左面显示 1.html，右面显示 2.html程序设计中的框架概念程序设计中的框架包含DoitPHP(原Tommyframework)是一个基于BSD开源协议发布的轻量级PHP框架，还包含如thinkphp、codeigniter（简称CI）、yii framework、doophp、qeephp、等主流的程序设计框架，根据个人习惯和性能要求，其各也有不同的优缺点！从软件设计角度，框架是一个可复用的软件架构解决方案，规定了应用的体系结构，阐明软件体系结构中各层次间及其层次内部各组件间的毅力关系，责任分配和控制流程，表现为一组接口，抽象类以及实例间协作的方法。 前端框架Web前端框架就是为了节约开发成本和时间，一般开发一个项目都会用到前端框架（除非自己有前端开发团队），根据我经验找的几款web前端框架做出了分析。都是个人意见，仁者见仁智者见智。 QUICK UI QUICK UI是一套完整的企业级web前端开发解决方案，由基础框架、UI组件库、皮肤包、示例工程和文档等组成。使用QUICKUI开发者可以极大地减少工作量，提高开发效率，快速构建功能强大、美观、兼容的web应用系统。 QUICK UI优势： ①功能最为强大 QUICKUI经历了7年的迭代更新，不断从客户的各种业务中对组件的需求进行归纳和抽离，从而打造新的组件和功能。现在最新的4.0版本框架包含了一百多种组件，一千多个应用场景示例。可以说在前端框架领域中，QUICKUI拥有功能最强大组件库。 ②运行最为稳定 很多其他的第三方UI控件在简单场合使用OK，到了复杂的场景中就会出现很多问题，这种现象很常见，因为在组件设计时无法预料到所有的应用场合。而QUICKUI在7年间经历了数千个项目实际检验，在各种复杂场景都应用过，并根据客户的反馈不断完善和调整。目前的第四代可以说是最稳定、最完美的版本。 ③丰富精美的界面皮肤 跟其他web前端框架仅仅是一套组件库不同，QUICKUI是一整套前端解决方案，拥有丰富的外观界面解决方案。采用现今流行的扁平化设计理念，推出了包括登录、响应式web、工作桌面、地图类、门户风格、大屏展示风格等等几百套制作精美、用户体验优秀的界面。这些界面是以QUICKUI皮肤包的形式发布，使用和更换都非常方便。 ④事无巨细的开发文档 QUICKUI拥有16万字+的开发文档，框架和组件的每一个功能点都有详细的讲解和代码示例，用于开发过程中随时查阅。除了框架机制讲解和组件使用教程，文档还涉及web前端开发的很多知识。仔细阅读并结合框架使用的话，你很快就能成为web开发的高手。 ⑤上手开发非常容易 QUICKUI采用组件化思想来构建组件，一个组件就是一两句html的标签，使用起来非常简单。将开发人员从繁琐的JS编码中解脱出来，很大程度减少前台编码的出错率；保留了HTML的布局方式，从而快速进行页面布局。对开发者前台技术要求也非常低，只需要了解html语法和一些简单的JS即可，从而把更多精力放在业务功能的实现上，极大地提高开发效率。 ⑥浏览器兼容性非常好 QUICKUI4.0使用了很多HTML5，CSS3技术用于提高表现力和用户体验，这些新的特性在现代浏览器中会有很好的效果。但是，国内依然有大量的用户在使用IE7、IE8等旧时代的浏览器，为照顾这部分用户，框架采用了渐进式思想，确保低版本浏览器也能正常使用。所以，QUICKUI兼容IE7以上所有主流浏览器。 flex Apache基金会今天发布了Flex4.8版本，这是Adobe将Flex捐献给Apache基金会后发布的第一个版本。 需要注意的是，Flex目前还在孵化阶段，还不是Apache的正式项目，Flex4.8也不是一个正式的Apache版本。 Apache称，该版本标志着Flex新时代的开始，Flex的未来将由社区来驱动，而不是由一个公司驱动。开发者可以通过贡献代码，来帮助改进Flex，如修复bug、增加功能等。 从Macromedia卖给Adobe，然后又捐给apache，不知道搞什么名堂。不过还好没有经过大幅重构，否则就真的是悲哀了！ extjs ExtJS是一种主要用于创建前端用户界面，是一个基本与后台技术无关的前端ajax框架。 功能丰富，无人能出其右。 无论是界面之美，还是功能之强，ext的表格控件都高居榜首。 华丽的界面，灵活的功能，还有开发工具都是配套的，但有个最大的问题，用就得花钱！ easyui easyui帮助你构建你的web应用更加容易。 它是一个基于jquery的插件，开发出来的一套轻量级的ui框架，非常小巧而且功能丰富。 但是她有一个最大的问题就是代码只能找到以前的开源的版本，到了1.2以后的版本源代码都是经过混淆的，如果遇到问题修改起来会非常麻烦！不过一个比较大的优势是开源免费，并且界面做的还说的过去！ jQueryUI jQueryUI是一套jQuery的页面UI插件，包含很多种常用的页面空间，例如Tabs（如本站首页右上角部分）、拉帘效果（本站首页左上角）、对话框、拖放效果、日期选择、颜色选择、数据排序、窗体大小调整等等非常多的内容。 功能非常全面，界面也挺漂亮的，可以整体使用，也可以分开使用其中的几个模块，免费开源！ MiniUI 又一个基于jquery的框架，开发的界面功能都很丰富。 jQueryMiniUI–快速开发WebUI。 它能缩短开发时间，减少代码量，使开发者更专注于业务和服务端，轻松实现界面开发，带来绝佳的用户体验。 使用MiniUI，开发者可以快速创建Ajax无刷新、B/S快速录入数据、CRUD、Master-Detail、菜单工具栏、弹出面板、布局导航、数据验证、分页表格、树、树形表格等典型WEB应用系统界面。 界面做的挺不错，功能也挺丰富，但是有两个比较大的问题，一个是收费，一个是没有源码，说白了，不开源！基于这个开发如果想对功能做扩展就需要找他们的团队进行升级！ DWZ DWZ富客户端框架(jQueryRIAframework),是中国人自己开发的基于jQuery实现的AjaxRIA开源框架. 设计目标是简单实用,快速开发,降低ajax开发成本。 欢迎大家提出建议，我们将在下一版本中进一步调整和完善功能．共同推进国内整体ajax开发水平。 毕竟是国产的，支持一下，而且源码完全公开，可以选择一下！不过性能怎么样不敢确定！ YUI Yahoo!UILibrary (YUI)是一个开放源代码的JavaScript函数库，为了能建立一个高互动的网页，它采用了AJAX,DHTML和DOM等程式码技术。它也包含了许多CSS资源。使用授权为 BSD许可证，基本上没怎么研究过！YUICompressor倒是挺出名的，这套UI库不知道应用的情况怎么样！ Sencha Sencha是由ExtJS、jQTouch以及Raphael三个项目合并而成的一个新项目。 大公司的框架，并且是几样库的强强联合，值得推荐！ OperaMasks-UI OperaMasks-UI是OperaMasks团队2011下半年打造的一款轻量级前端JS组件库，旨在提供一款学习曲线低、定制性灵活、样式统一，且多浏览器支持、覆盖企业业务场景的前端JavaScriptUI组件库。目前，该团队已将这一产品以LGPL开源协议开放给社区。 后端框架web网站发展至今，特别是服务器端，涉及到的知识、内容，非常广泛。这对程序员的要求会越来越高。如果采用成熟，稳健的框架，那么一些基础的工作，比如，安全性，数据流控制等都可以让框架来处理，那么程序开发人员可以把精力放在具体的业务逻辑上面。使用框架的优点： 稳定性和可扩展性强可以降低开发难度，提高开发效率。在 Python 中常用的 Web 框架有: Flask 、Django、Tornad]]></content>
      <tags>
        <tag>框架</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HTML基础之HTML常用标签]]></title>
    <url>%2F2019%2F02%2F18%2FHTML%E5%9F%BA%E7%A1%80%E4%B9%8BHTML%E5%B8%B8%E7%94%A8%E6%A0%87%E7%AD%BE%2F</url>
    <content type="text"><![CDATA[HTML基础之HTML常用标签 HTML是一种用来描述网页的标记性语言。学习HTML可能并不难，主要是要记一些HTML标签和标签代表的含义。下面PHP程序员雷雪松根据使用的情况，整理出平时常用的HTML标签。 1、最基本的HTML结构 &lt;!DOCTYPE html&gt; 网页标题L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"debug":false,"model":{"jsonPath":"/live2dw/assets/assets/shizuku.model.json"},"display":{"position":"right","width":130,"height":260},"mobile":{"show":false},"log":false}); 2、最常用的HTML标签a、布局标签 div标签定义文档中的分区或节（division/section），可以把文档分割为独立的、不同的部分，主要用于布局。 aside标签的内容可用作文章的侧栏，html5新增标签。 header标签定义页面的头部（介绍信息），html5新增标签。 section标签定义文档中的节（section、区段）。比如章节、页眉、页脚或文档中的其他部分，html5新增标签。 footer 标签定义文档或节的页脚，通常包含文档的作者、版权信息、使用条款链接、联系信息等等，html5新增标签。 article标签规定文章独立的其他内容，比如：标题、内容、评论，html5新增标签。 b、文本标签 h1-h6标签可定义标题 p标签定义段落 b/strong标签加粗 em标签来表示强调的文本，斜体 strong标签表示重要文本 u标签下划线 s标签删除线 br标签表示回车换行 hr标签表示水平线 span标签被用来组合文档中的行内元素。 blockquote标签表示块引用 pre标签可定义预格式化的文本，保持原有格式的一种标签。 sub标签下标， sup&gt;标签上标 表示一个空格 ©表示版权符 &lt;表示&lt; >表示&gt; c、a标签定义超链接，指定页面间的跳转。链接可以指向外部链接或者页面内部id锚点，可以在当前页面打开，新开窗口。 百度 d、多媒体标签 img标签主要在网页中插入图像，可以定义图片替换文本、显示宽度和高度、是否带边框，建议等比例设置，否则图像会变形。 audio标签定义声音，比如音乐或其他音频流。html5新增标签。 您的浏览器不支持 audio 标签。 video标签定义视频，比如电影片段或其他视频流。html5新增标签。 您的浏览器不支持 video 标签。 e、序列化标签 ul和li无序列表标签 HTMLJSPHP ol和li有序列表标签，可以使用type属性规定有序列表符号的类型。1 按数字有序排列，为默认值，（1、2、3、4）；a 按小写字母有序排列，（a、b、c、d）；A 按字母大写有序排列，（A、B、C、D）。i 按小写罗马字母有序，（i, ii, iii, iv）；I 按小写罗马字母有序，（I, II, III, IV）。 HTMLJSPHP dl标签定义了定义列表（definition list），dl标签用于结合 dt（定义列表中的项目）和 dd（描述列表中的项目）。 计算机用来计算的仪器 … … f、表格标签 table标签和tr标签，th标签和td标签，合并单元格。 标题标题&nbsp; g、表单标签 form标签定义提交方式、提交地址、表单字符集以及如何对其进行编码，需要提交的表单一定要放在form标签内。 input标签用于搜集用户信息 密码，输入的字符会被掩码（显示为星号或原点） 文件类型的表单，上传文件时，form表单一定要设置为enctype=”multipart/form-data” 隐藏表单 提交 重置 radio单选 男 女 checkbox多选 PHP 前端 数据库 注：checked=”checked”可以简写成checked label标签为input元素定义标注，如果您点击label元素文本，就会触发此input控件。 textarea标签，设置文本区内的可见行数和宽度 大段文本输入框 button标签定义一个按钮 提交按钮 提交 重置按钮 重置 select标签和option标签下拉列表 单选菜单列表框 rayraykaeso 多选列表下拉框，shift加鼠标单击，可以连续选择多个选择，CTRL+鼠标点击，可以点击多个。 雷雪松rayraykaeso 注:selected=”selected”可简写成selected，表示选中 3、其他HTML事项a、HTML标签和属性是不区分大小写的，建议HTML标签和属性都小写，属性值必须用双引号包围。 b、HTML标签都是以开始标签起始，以结束标签终止。大部分HTML标签都是成对出现的，称为双标签，比如：p标签、div标签，也有的HTML标签在开始标签中结束的标签，称为单标签，比如：hr标签、br标签。大多数 HTML 元素可拥有属性，文本内容都是写在开始标签与结束标签之间。 c、HTML标签之间尽量缩进与换行，每行代码不要过长，方便阅读和维护。 d、HTML标签使用必须符合标签嵌套规则。禁止a标签嵌套a标签，p标签嵌套div标签。 e、建议不使用HTML已经废弃的或者不赞成使用的标签，少使用table布局、iframe框架嵌套以及flash播放器。]]></content>
      <tags>
        <tag>http</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx的启动、停止与重启]]></title>
    <url>%2F2019%2F02%2F16%2FNginx%E7%9A%84%E5%90%AF%E5%8A%A8%E3%80%81%E5%81%9C%E6%AD%A2%E4%B8%8E%E9%87%8D%E5%90%AF%2F</url>
    <content type="text"><![CDATA[Nginx的启动、停止与重启启动 启动代码格式：nginx安装目录地址 -c nginx配置文件地址 例如： 1[root@LinuxServer sbin]# /usr/local/nginx/sbin/nginx -c /usr/local/nginx/conf/nginx.conf 停止 nginx的停止有三种方式： 从容停止 1、查看进程号 1[root@LinuxServer ~]# ps -ef|grep nginx 2、杀死进程 1[root@LinuxServer ~]# kill -QUIT 2072 快速停止 1、查看进程号 1[root@LinuxServer ~]# ps -ef|grep nginx 2、杀死进程 12[root@LinuxServer ~]# kill -TERM 2132或 [root@LinuxServer ~]# kill -INT 2132 强制停止 1[root@LinuxServer ~]# pkill -9 nginx 重启1、验证nginx配置文件是否正确方法一：进入nginx安装目录sbin下，输入命令./nginx -t看到如下显示nginx.conf syntax is ok nginx.conf test is successful 说明配置文件正确！ 方法二：在启动命令-c前加-t 2、重启Nginx服务方法一：进入nginx可执行目录sbin下，输入命令./nginx -s reload 即可 方法二：查找当前nginx进程号，然后输入命令：kill -HUP 进程号 实现重启nginx服务 12345678910总结的一些nginx vue常用命令cnpm install 自动安装依赖包npm run dev 开启npm run build 翻译 生成dist目录ps -ef 查看wsgi进程 ps -ef | grep gunicornnginx -s reload 每次修改完nginx后都要运行这个命令重启一下ps -ef 查看wsgi进程 ps -ef | grep gunicornkill -9 进程号 杀死进程ps -A ps -a查看进程]]></content>
      <tags>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[npm 和 cnpm区别]]></title>
    <url>%2F2019%2F02%2F16%2Fnpm%20%E5%92%8C%20cnpm%20%E5%8C%BA%E5%88%AB%2F</url>
    <content type="text"><![CDATA[NPM介绍： 说明：NPM（节点包管理器）是的NodeJS的包管理器，用于节点插件管理（包括安装，卸载，管理依赖等） 使用NPM安装插件：命令提示符执行npm install &lt;name&gt; [-g] [--save-dev]&lt;name&gt;：节点插件名称。例：npm install gulp-less --save-dev -g：全局安装。 将会安装在C：\ Users \ Administrator \ AppData \ Roaming \ npm，并且写入系统环境变量;非全局安装：将会安装在当前定位目录;全局安装可以通过命令行任何地方调用它，本地安装将安装在定位目录的node_modules文件夹下，通过要求（）调用; --save：将保存至的package.json（的package.json是的NodeJS项目配置文件） -dev;：保存至的package.json的devDependencies节点，不指定-dev将保存至依赖节点 为什么要保存至的的package.json？因为节点插件包相对来说非常庞大，所以不加入版本管理，将配置信息写入的的package.json并将其加入版本管理，其他开发者对应下载即可（命令提示符执行npm install，则会根据package.json下载所有需要的包）。 \6. 使用 npm 卸载插件： npm uninstall [ -g ] [ –save-dev ] \7. 使用 npm 更新插件： npm update [ -g ] [ –save-dev ] \8. 更新全部插件： npm update [ –save-dev ] \9. 查看 NPM帮助： NPM帮助 10.查看当前目录已安装插件：npm list PS：NPM安装插件过程：从 http://registry.npmjs.org 下载对应的插件包（该网站服务器位于国外，所以经常下载缓慢或出现异常），解决办法往下看↓↓↓↓↓↓。 CNPM介绍： 说明：因为故宫安装插件是从国外服务器下载，受网络影响大，可能出现异常，如果故宫的服务器在中国就好了，所以我们乐于分享的淘宝团队干了这事来自官网：“这是一个完整npmjs.org镜像，你可以用此代替官方版本（只读），同步频率目前为10分钟一次以保证尽量与官方服务同步“。 官方网址：http://npm.taobao.org 安装：命令提示符执行npm install cnpm -g --registry=https://registry.npm.taobao.org 注意：安装完后最好查看其版本cnpm -v或关闭命令提示符重新打开，安装完直接使用有可能会出现错误 注：CNPM跟NPM用法完全一致，只是在执行命令时将故宫改为CNPM。]]></content>
      <tags>
        <tag>vue</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[浅谈HTTP中Get、Post、Put与Delete的区别]]></title>
    <url>%2F2019%2F02%2F14%2F%E6%B5%85%E8%B0%88HTTP%E4%B8%ADGet%E3%80%81Post%E3%80%81Put%E4%B8%8EDelete%E7%9A%84%E5%8C%BA%E5%88%AB%2F</url>
    <content type="text"><![CDATA[先具体说下get和post区别GET和POST两种基本请求方法的区别GET和POST是HTTP请求的两种基本方法，要说它们的区别，接触过WEB开发的人都能说出一二。 最直观的区别就是GET把参数包含在URL中，POST通过request body传递参数。 你可能自己写过无数个GET和POST请求，或者已经看过很多权威网站总结出的他们的区别，你非常清楚知道什么时候该用什么。 当你在面试中被问到这个问题，你的内心充满了自信和喜悦。 你轻轻松松的给出了一个“标准答案”： GET在浏览器回退时是无害的，而POST会再次提交请求。 GET产生的URL地址可以被Bookmark，而POST不可以。 GET请求会被浏览器主动cache，而POST不会，除非手动设置。 GET请求只能进行url编码，而POST支持多种编码方式。 GET请求参数会被完整保留在浏览器历史记录里，而POST中的参数不会被保留。 GET请求在URL中传送的参数是有长度限制的，而POST么有。 对参数的数据类型，GET只接受ASCII字符，而POST没有限制。 GET比POST更不安全，因为参数直接暴露在URL上，所以不能用来传递敏感信息。 GET参数通过URL传递，POST放在Request body中。 （本标准答案参考自w3schools） “很遗憾，这不是我们要的回答！” 请告诉我真相。。。 如果我告诉你GET和POST本质上没有区别你信吗？ 让我们扒下GET和POST的外衣，坦诚相见吧！ GET和POST是什么？HTTP协议中的两种发送请求的方法。 HTTP是什么？HTTP是基于TCP/IP的关于数据如何在万维网中如何通信的协议。 HTTP的底层是TCP/IP。所以GET和POST的底层也是TCP/IP，也就是说，GET/POST都是TCP链接。GET和POST能做的事情是一样一样的。你要给GET加上request body，给POST带上url参数，技术上是完全行的通的。 那么，“标准答案”里的那些区别是怎么回事？ 在我大万维网世界中，TCP就像汽车，我们用TCP来运输数据，它很可靠，从来不会发生丢件少件的现象。但是如果路上跑的全是看起来一模一样的汽车，那这个世界看起来是一团混乱，送急件的汽车可能被前面满载货物的汽车拦堵在路上，整个交通系统一定会瘫痪。为了避免这种情况发生，交通规则HTTP诞生了。HTTP给汽车运输设定了好几个服务类别，有GET, POST, PUT, DELETE等等，HTTP规定，当执行GET请求的时候，要给汽车贴上GET的标签（设置method为GET），而且要求把传送的数据放在车顶上（url中）以方便记录。如果是POST请求，就要在车上贴上POST的标签，并把货物放在车厢里。当然，你也可以在GET的时候往车厢内偷偷藏点货物，但是这是很不光彩；也可以在POST的时候在车顶上也放一些数据，让人觉得傻乎乎的。HTTP只是个行为准则，而TCP才是GET和POST怎么实现的基本。 但是，我们只看到HTTP对GET和POST参数的传送渠道（url还是requrest body）提出了要求。“标准答案”里关于参数大小的限制又是从哪来的呢？ 在我大万维网世界中，还有另一个重要的角色：运输公司。不同的浏览器（发起http请求）和服务器（接受http请求）就是不同的运输公司。 虽然理论上，你可以在车顶上无限的堆货物（url中无限加参数）。但是运输公司可不傻，装货和卸货也是有很大成本的，他们会限制单次运输量来控制风险，数据量太大对浏览器和服务器都是很大负担。业界不成文的规定是，（大多数）浏览器通常都会限制url长度在2K个字节，而（大多数）服务器最多处理64K大小的url。超过的部分，恕不处理。如果你用GET服务，在request body偷偷藏了数据，不同服务器的处理方式也是不同的，有些服务器会帮你卸货，读出数据，有些服务器直接忽略，所以，虽然GET可以带request body，也不能保证一定能被接收到哦。 好了，现在你知道，GET和POST本质上就是TCP链接，并无差别。但是由于HTTP的规定和浏览器/服务器的限制，导致他们在应用过程中体现出一些不同。 你以为本文就这么结束了？ 我们的大BOSS还等着出场呢。。。 这位BOSS有多神秘？当你试图在网上找“GET和POST的区别”的时候，那些你会看到的搜索结果里，从没有提到他。他究竟是什么呢。。。 GET和POST还有一个重大区别，简单的说： GET产生一个TCP数据包；POST产生两个TCP数据包。 长的说： 对于GET方式的请求，浏览器会把http header和data一并发送出去，服务器响应200（返回数据）； 而对于POST，浏览器先发送header，服务器响应100 continue，浏览器再发送data，服务器响应200 ok（返回数据）。 也就是说，GET只需要汽车跑一趟就把货送到了，而POST得跑两趟，第一趟，先去和服务器打个招呼“嗨，我等下要送一批货来，你们打开门迎接我”，然后再回头把货送过去。 因为POST需要两步，时间上消耗的要多一点，看起来GET比POST更有效。因此Yahoo团队有推荐用GET替换POST来优化网站性能。但这是一个坑！跳入需谨慎。为什么？ \1. GET与POST都有自己的语义，不能随便混用。 \2. 据研究，在网络环境好的情况下，发一次包的时间和发两次包的时间差别基本可以无视。而在网络环境差的情况下，两次包的TCP在验证数据包完整性上，有非常大的优点。 \3. 并不是所有浏览器都会在POST中发送两次包，Firefox就只发送一次。 现在，当面试官再问你“GET与POST的区别”的时候，你的内心是不是这样的？ 1、GET请求会向数据库发索取数据的请求，从而来获取信息，该请求就像数据库的select操作一样，只是用来查询一下数据，不会修改、增加数据，不会影响资源的内容，即该请求不会产生副作用。无论进行多少次操作，结果都是一样的。2、与GET不同的是，PUT请求是向服务器端发送数据的，从而改变信息，该请求就像数据库的update操作一样，用来修改数据的内容，但是不会增加数据的种类等，也就是说无论进行多少次PUT操作，其结果并没有不同。3、POST请求同PUT请求类似，都是向服务器端发送数据的，但是该请求会改变数据的种类等资源，就像数据库的insert操作一样，会创建新的内容。几乎目前所有的提交操作都是用POST请求的。4、DELETE请求顾名思义，就是用来删除某一个资源的，该请求就像数据库的delete操作。就像前面所讲的一样，既然PUT和POST操作都是向服务器端发送数据的，那么两者有什么区别呢。。。POST主要作用在一个集合资源之上的（url），而PUT主要作用在一个具体资源之上的（url/xxx），通俗一下讲就是，如URL可以在客户端确定，那么可使用PUT，否则用POST。 综上所述，我们可理解为以下：1、POST /url 创建2、DELETE /url/xxx 删除3、PUT /url/xxx 更新4、GET /url/xxx 查看 Http定义了与服务器交互的不同方法，最基本的方法有4种，分别是GET，POST，PUT，DELETE。URL全称是统一资源定位符，我们可以这样认为：一个URL地址，它用于描述一个网络上的资源，而HTTP中的GET，POST，PUT，DELETE就对应着对这个资源的查，改，增，删4个操作。到这里，大家应该有个大概的了解了，GET一般用于获取/查询资源信息，而POST一般用于更新资源信息。 1.根据HTTP规范，GET用于信息获取，而且应该是安全的和幂等的。(1).所谓安全的意味着该操作用于获取信息而非修改信息。换句话说，GET 请求一般不应产生副作用。就是说，它仅仅是获取资源信息，就像数据库查询一样，不会修改，增加数据，不会影响资源的状态。 注意：这里安全的含义仅仅是指是非修改信息。 (2).幂等的意味着对同一URL的多个请求应该返回同样的结果。这里我再解释一下幂等这个概念： 幂等（idempotent、idempotence）是一个数学或计算机学概念，常见于抽象代数中。 幂等有一下几种定义： 对于单目运算，如果一个运算对于在范围内的所有的一个数多次进行该运算所得的结果和进行一次该运算所得的结果是一样的，那么我们就称该运算是幂等的。比如绝对值运算就是一个例子，在实数集中，有abs(a)=abs(abs(a))。 对于双目运算，则要求当参与运算的两个值是等值的情况下，如果满足运算结果与参与运算的两个值相等，则称该运算幂等，如求两个数的最大值的函数，有在在实数集中幂等，即max(x,x) = x。 看完上述解释后，应该可以理解GET幂等的含义了。 但在实际应用中，以上2条规定并没有这么严格。引用别人文章的例子：比如，新闻站点的头版不断更新。虽然第二次请求会返回不同的一批新闻，该操作仍然被认为是安全的和幂等的，因为它总是返回当前的新闻。从根本上说，如果目标是当用户打开一个链接时，他可以确信从自身的角度来看没有改变资源即可。 2.根据HTTP规范，POST表示可能修改变服务器上的资源的请求。继续引用上面的例子：还是新闻以网站为例，读者对新闻发表自己的评论应该通过POST实现，因为在评论提交后站点的资源已经不同了，或者说资源被修改了。 上面大概说了一下HTTP规范中GET和POST的一些原理性的问题。但在实际的做的时候，很多人却没有按照HTTP规范去做，导致这个问题的原因有很多，比如说： 1.很多人贪方便，更新资源时用了GET，因为用POST必须要到FORM（表单），这样会麻烦一点。 2.对资源的增，删，改，查操作，其实都可以通过GET/POST完成，不需要用到PUT和DELETE。 3.另外一个是，早期的Web MVC框架设计者们并没有有意识地将URL当作抽象的资源来看待和设计，所以导致一个比较严重的问题是传统的Web MVC框架基本上都只支持GET和POST两种HTTP方法，而不支持PUT和DELETE方法。 简单解释一下MVC：MVC本来是存在于Desktop程序中的，M是指数据模型，V是指用户界面，C则是控制器。使用MVC的目的是将M和V的实现代码分离，从而使同一个程序可以使用不同的表现形式。 以上3点典型地描述了老一套的风格（没有严格遵守HTTP规范），随着架构的发展，现在出现REST(Representational State Transfer)，一套支持HTTP规范的新风格，这里不多说了，可以参考《RESTful Web Services》。 说完原理性的问题，我们再从表面现像上面看看GET和POST的区别：1.GET请求的数据会附在URL之后（就是把数据放置在HTTP协议头中），以?分割URL和传输数据，参数之间以&amp;相连，如：login.action?name=hyddd&amp;password=idontknow&amp;verify=%E4%BD%A0%E5%A5%BD。如果数据是英文字母/数字，原样发送，如果是空格，转换为+，如果是中文/其他字符，则直接把字符串用BASE64加密，得出如：%E4%BD%A0%E5%A5%BD，其中％XX中的XX为该符号以16进制表示的ASCII。 POST把提交的数据则放置在是HTTP包的包体中。 2.”GET方式提交的数据最多只能是1024字节，理论上POST没有限制，可传较大量的数据，IIS4中最大为80KB，IIS5中为100KB”？？！ 以上这句是我从其他文章转过来的，其实这样说是错误的，不准确的： (1).首先是”GET方式提交的数据最多只能是1024字节”，因为GET是通过URL提交数据，那么GET可提交的数据量就跟URL的长度有直接关系了。而实际上，URL不存在参数上限的问题，HTTP协议规范没有对URL长度进行限制。这个限制是特定的浏览器及服务器对它的限制。IE对URL长度的限制是2083字节(2K+35)。对于其他浏览器，如Netscape、FireFox等，理论上没有长度限制，其限制取决于操作系统的支持。 注意这是限制是整个URL长度，而不仅仅是你的参数值数据长度。[见参考资料5] (2).理论上讲，POST是没有大小限制的，HTTP协议规范也没有进行大小限制，说“POST数据量存在80K/100K的大小限制”是不准确的，POST数据是没有限制的，起限制作用的是服务器的处理程序的处理能力。 对于ASP程序，Request对象处理每个表单域时存在100K的数据长度限制。但如果使用Request.BinaryRead则没有这个限制。 由这个延伸出去，对于IIS 6.0，微软出于安全考虑，加大了限制。我们还需要注意： 1).IIS 6.0默认ASP POST数据量最大为200KB，每个表单域限制是100KB。2).IIS 6.0默认上传文件的最大大小是4MB。3).IIS 6.0默认最大请求头是16KB。IIS 6.0之前没有这些限制。[见参考资料5] 所以上面的80K，100K可能只是默认值而已(注：关于IIS4和IIS5的参数，我还没有确认)，但肯定是可以自己设置的。由于每个版本的IIS对这些参数的默认值都不一样，具体请参考相关的IIS配置文档。 3.在ASP中，服务端获取GET请求参数用Request.QueryString，获取POST请求参数用Request.Form。在JSP中，用request.getParameter(\”XXXX\”)来获取，虽然jsp中也有request.getQueryString()方法，但使用起来比较麻烦，比如：传一个test.jsp?name=hyddd&amp;password=hyddd，用request.getQueryString()得到的是：name=hyddd&amp;password=hyddd。在PHP中，可以用$_GET和$_POST分别获取GET和POST中的数据，而$_REQUEST则可以获取GET和POST两种请求中的数据。值得注意的是，JSP中使用request和PHP中使用$_REQUEST都会有隐患，这个下次再写个文章总结。 4.POST的安全性要比GET的安全性高。注意：这里所说的安全性和上面GET提到的“安全”不是同个概念。上面“安全”的含义仅仅是不作数据修改，而这里安全的含义是真正的Security的含义，比如：通过GET提交数据，用户名和密码将明文出现在URL上，因为(1)登录页面有可能被浏览器缓存，(2)其他人查看浏览器的历史纪录，那么别人就可以拿到你的账号和密码了，除此之外，使用GET提交数据还可能会造成Cross-site request forgery攻击。 总结一下，Get是向服务器发索取数据的一种请求，而Post是向服务器提交数据的一种请求，在FORM（表单）中，Method默认为”GET”，实质上，GET和POST只是发送机制不同，并不是一个取一个发！]]></content>
      <tags>
        <tag>http</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[正则表达式的使用]]></title>
    <url>%2F2018%2F12%2F12%2F%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%E7%9A%84%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[正则表达式正则表达式在爬虫中被广泛使用，正则和Xpath各有各的优点。虽然以前学习过正则表达式，但现在还总是迷迷糊糊的，今天有所顿悟。 re.search()和re.match()re.match决定RE是否在字符串刚开始的位置匹配。//注：这个方法并不是完全匹配。当pattern结束时若string还有剩余字符，仍然视为成功。想要完全匹配，可以在表达式末尾加上边界匹配符’$’ re.search函数会在字符串内查找模式匹配,只要找到第一个匹配然后返回，如果字符串没有匹配，则返回None。 match和search一旦匹配成功，就是一个match object对象，而match object对象有以下方法： group() 返回被RE匹配的字符串 start() 返回匹配开始的位置编号 end() 返回匹配结束的位置编号 span() 返回一个元组包含匹配（开始，结束）的位置编号 group() 返回re整体匹配的字符串，可以一次输入多个组号，对应组号匹配的字符串 re.search()后使用group()不加参数表示返回被匹配的整体字符串，group()加上一个参数1表示取出匹配的第一组字符，可以输入多个组号。 eg.: 12345import restr1 = '&lt;h1&gt;hello world&lt;/h1&gt;你好世界&lt;/h1&gt;'x = re.search('&lt;h1&gt;(.*?)&lt;/h1&gt;(.*?)&lt;/h1&gt;', str1).group(1,2)print(x)结果：('hello world', '你好世界') re.compile和re.findallre.compile是对正则表达式进行预编译，返回一个对象的模式，主要作用是把常用的正则表达式编译成正则表达式对象，这样可以提高一点效率。 格式：re.compile(pattern,flags=0) pattern：编译时用的表达式字符串 flags：编译标志位，用于修改正则表达式的匹配方式，模式修正符。 常用的flags模式修正符有： re.S：使.匹配包括换行符在内的所有字符 re.I：使匹配不区分大小写 re.L：做本地化识别匹配 re.M：多行匹配，影响^和$ re.X：该标志通过给予更灵活的格式一遍将正则表达式写的更易于理解 re.U：根据Unicode字符集解析字符，这个标志影响\w,\W,\b,\B re.findall遍历匹配，可以获取字符串中所有匹配的字符串，返回一个列表。 格式：re.findall(pattern, string, flags=0) pattern为表达式字符串， strings为要匹配的字符串 flags为模式修正符 所以可以看到： 在findall中包含了compile，为了简洁，一般我都不适用compile。 re.finditerre.finditer() 搜索string，返回一个顺序访问每一个匹配结果（Match对象）的迭代器。找到 RE 匹配的所有子串，并把它们作为一个迭代器返回。 格式和findall()一样，返回的是一个迭代器，要使用for循环迭代取值，由于他返回的是一个Match对象，所以还要使用.group()函数来取出字符串。 re.split按照能够匹配的子串将string分割后返回列表。 可以使用re.split来分割字符串，如：re.split(r’\s+’, text)；将字符串按空格分割成一个单词列表。 格式： re.split(pattern, string[, maxsplit]) maxsplit用于指定最大分割次数，不指定将全部分割。 eg. 123print(re.split('\d+','one1two2three3four4five5'))执行结果如下：['one', 'two', 'three', 'four', 'five', ''] re.supre.sup使用re替换string中每一个匹配的子串后返回替换后的字符串。 eg. 1re.sup(&apos;[\n ]&apos;, &apos;&apos;, str) 上面这个例子会吧str中所有的换行符和空格去除。 一些要注意的地方re.match与re.search与re.findall的区别： re.match只匹配字符串的开始，如果字符串开始不符合正则表达式，则匹配失败，函数返回None；而re.search匹配整个字符串，直到找到一个匹配。 12345678910a=re.search('[\d]',"abc33").group()print(a)p=re.match('[\d]',"abc33")print(p)b=re.findall('[\d]',"abc33")print(b)执行结果：3None['3', '3'] 贪婪匹配与非贪婪匹配 ?,+?,??,{m,n}? 前面的,+,?等都是贪婪匹配，也就是尽可能匹配，后面加?号使其变成惰性匹配 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889a = re.findall(r"a(\d+?)",'a23b')print(a)b = re.findall(r"a(\d+)",'a23b')print(b)执行结果：['2']['23']a = re.match('&lt;(.*)&gt;','&lt;H1&gt;title&lt;H1&gt;').group()print(a)b = re.match('&lt;(.*?)&gt;','&lt;H1&gt;title&lt;H1&gt;').group()print(b)执行结果：&lt;H1&gt;title&lt;H1&gt;&lt;H1&gt;a = re.findall(r"a(\d+)b",'a3333b')print(a)b = re.findall(r"a(\d+?)b",'a3333b')print(b)执行结果如下：['3333']['3333']#######################这里需要注意的是如果前后均有限定条件的时候，就不存在什么贪婪模式了，非匹配模式失效。@" 这两个字符都是匹配字符本身(.*?) 匹配任意长度的任意字符但是后面的?表示采用非贪婪模式也就是说在遇到/字符之前的位置上尽可能多的匹配而不是一直匹配到最后一个/字符([\w\d]) \w表示任意字母或数字 \d表示任意数字 所以这里的[\w\d]写的有些问题因为[]内的内容只匹配一个字符所以([\w\d])和(\w)的意义应该是一样的### 正则表达式贪婪与非贪婪模式之前做程序的时候看到过正则表达式的贪婪与非贪婪模式，今天用的时候就想不起来了，现在这里总结一下，以备自己以后用到注意。1.什么是正则表达式的贪婪与非贪婪匹配 如：String str="abcaxc"; Patter p="ab.*c"; 贪婪匹配:正则表达式一般趋向于最大长度匹配，也就是所谓的贪婪匹配。如上面使用模式p匹配字符串str，结果就是匹配到：abcaxc(ab.*c)。 非贪婪匹配：就是匹配到结果就好，就少的匹配字符。如上面使用模式p匹配字符串str，结果就是匹配到：abc(ab.*c)。2.编程中如何区分两种模式 默认是贪婪模式；在量词后面直接加上一个问号？就是非贪婪模式。 量词：&#123;m,n&#125;：m到n个 *：任意多个 +：一个到多个 ？：0或一个3.程序实例使用Snort的规则一条规则的一部分作为匹配文本，匹配出其中的content部分。复制代码 1 import java.util.regex.Matcher; 2 import java.util.regex.Pattern; 3 4 public class RegularTest &#123; 5 6 public static void main(String[] arg)&#123; 7 String text="(content:\"rcpt to root\";pcre:\"word\";)"; 8 String rule1="content:\".+\""; //贪婪模式 9 String rule2="content:\".+?\""; //非贪婪模式10 11 System.out.println("文本："+text);12 System.out.println("贪婪模式："+rule1);13 Pattern p1 =Pattern.compile(rule1);14 Matcher m1 = p1.matcher(text);15 while(m1.find())&#123;16 System.out.println("匹配结果："+m1.group(0));17 &#125;18 19 System.out.println("非贪婪模式："+rule2);20 Pattern p2 =Pattern.compile(rule2);21 Matcher m2 = p2.matcher(text);22 while(m2.find())&#123;23 System.out.println("匹配结果："+m2.group(0));24 &#125;25 &#125;26 &#125;复制代码执行结果：]]></content>
      <categories>
        <category>爬虫</category>
      </categories>
      <tags>
        <tag>爬虫</tag>
      </tags>
  </entry>
</search>
